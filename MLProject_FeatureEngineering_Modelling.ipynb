{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuation from previous notebook\n",
    "\n",
    "1. More feature engineering on merged dataset:\n",
    "   1. On top 15 / 20 / 30 importances\n",
    "   2. Extract top 300+ columns of top importances \n",
    "   3. Out of 1.A and 1.B, find a base and add on new features\n",
    "2. Run models: \n",
    "   1. Random Forest on point 1.A and 1.B above (compare with previous notebook)\n",
    "   2. KNN on point 1.B above\n",
    "   3. SVC on point 1.B above - failed\n",
    "   4. Logistic Regression on point 1.A and 1.B above and all \n",
    "   5. Decision tree on point 1.B above\n",
    "   6. AdaBoost with 6 on point 1.B above\n",
    "   7. Ensemble of ensembles on point 1.B above\n",
    "   8. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS ##\n",
    "\n",
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# File system manangement\n",
    "import os\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# garbage collector\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data fcn\n",
    "def load_credit_data(data_path):\n",
    "    csv_path = os.path.join(\"data\", data_path)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 509)\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "training_df = load_credit_data (\"training_merged_preprocessed.csv\")\n",
    "print (training_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48744, 509)\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "testing_df = load_credit_data (\"testing_merged_preprocessed.csv\")\n",
    "print (testing_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET\n",
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load labels data\n",
    "labels_df = load_credit_data (\"y_labels.csv\")\n",
    "print (labels_df.shape)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection (on top 15 / 20 / 30 important features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at just important features\n",
    "y_train = labels_df['TARGET'].copy()\n",
    "\n",
    "# Top 30\n",
    "X_train_important = training_df [['EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'EXT_SOURCE_1', 'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION', 'df_avg_bureau_full_DAYS_CREDIT', 'df_avg_bureau_full_DAYS_CREDIT_ENDDATE', 'AMT_PAYMENT_df_avg_install', 'AMT_ANNUITY', 'DAYS_EMPLOYED', 'df_avg_bureau_full_DAYS_CREDIT_UPDATE', 'df_avg_pos_cash_CNT_INSTALMENT_FUTURE', 'AMT_INSTALMENT_df_avg_install', 'DAYS_LAST_PHONE_CHANGE', 'AMT_CREDIT', 'DAYS_ENTRY_PAYMENT_df_avg_install', 'DAYS_INSTALMENT_df_avg_install', 'df_avg_previous_app_DAYS_FIRST_DUE', 'df_avg_previous_app_DAYS_DECISION', 'df_avg_previous_app_HOUR_APPR_PROCESS_START', 'df_avg_previous_app_AMT_ANNUITY', 'df_avg_previous_app_AMT_CREDIT', 'df_avg_previous_app_AMT_GOODS_PRICE', 'df_avg_previous_app_AMT_APPLICATION', 'df_avg_previous_app_SELLERPLACE_AREA', 'REGION_POPULATION_RELATIVE', 'df_avg_previous_app_DAYS_LAST_DUE_1ST_VERSION', 'df_avg_bureau_full_AMT_CREDIT_SUM', 'AMT_INCOME_TOTAL']]\n",
    "X_test_important = testing_df [['EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'EXT_SOURCE_1', 'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION', 'df_avg_bureau_full_DAYS_CREDIT', 'df_avg_bureau_full_DAYS_CREDIT_ENDDATE', 'AMT_PAYMENT_df_avg_install', 'AMT_ANNUITY', 'DAYS_EMPLOYED', 'df_avg_bureau_full_DAYS_CREDIT_UPDATE', 'df_avg_pos_cash_CNT_INSTALMENT_FUTURE', 'AMT_INSTALMENT_df_avg_install', 'DAYS_LAST_PHONE_CHANGE', 'AMT_CREDIT', 'DAYS_ENTRY_PAYMENT_df_avg_install', 'DAYS_INSTALMENT_df_avg_install', 'df_avg_previous_app_DAYS_FIRST_DUE', 'df_avg_previous_app_DAYS_DECISION', 'df_avg_previous_app_HOUR_APPR_PROCESS_START', 'df_avg_previous_app_AMT_ANNUITY', 'df_avg_previous_app_AMT_CREDIT', 'df_avg_previous_app_AMT_GOODS_PRICE', 'df_avg_previous_app_AMT_APPLICATION', 'df_avg_previous_app_SELLERPLACE_AREA', 'REGION_POPULATION_RELATIVE', 'df_avg_previous_app_DAYS_LAST_DUE_1ST_VERSION', 'df_avg_bureau_full_AMT_CREDIT_SUM', 'AMT_INCOME_TOTAL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>df_avg_bureau_full_DAYS_CREDIT</th>\n",
       "      <th>df_avg_bureau_full_DAYS_CREDIT_ENDDATE</th>\n",
       "      <th>AMT_PAYMENT_df_avg_install</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>df_avg_previous_app_HOUR_APPR_PROCESS_START</th>\n",
       "      <th>df_avg_previous_app_AMT_ANNUITY</th>\n",
       "      <th>df_avg_previous_app_AMT_CREDIT</th>\n",
       "      <th>df_avg_previous_app_AMT_GOODS_PRICE</th>\n",
       "      <th>df_avg_previous_app_AMT_APPLICATION</th>\n",
       "      <th>df_avg_previous_app_SELLERPLACE_AREA</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>df_avg_previous_app_DAYS_LAST_DUE_1ST_VERSION</th>\n",
       "      <th>df_avg_bureau_full_AMT_CREDIT_SUM</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.262949</td>\n",
       "      <td>0.139376</td>\n",
       "      <td>-9461</td>\n",
       "      <td>0.083037</td>\n",
       "      <td>-2120</td>\n",
       "      <td>-3648.0</td>\n",
       "      <td>-874.00</td>\n",
       "      <td>-344.25</td>\n",
       "      <td>11559.247105</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9251.775</td>\n",
       "      <td>179055.00</td>\n",
       "      <td>179055.00</td>\n",
       "      <td>179055.00</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>108131.945625</td>\n",
       "      <td>202500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.622246</td>\n",
       "      <td>0.535276</td>\n",
       "      <td>-16765</td>\n",
       "      <td>0.311267</td>\n",
       "      <td>-291</td>\n",
       "      <td>-1186.0</td>\n",
       "      <td>-1400.75</td>\n",
       "      <td>-544.50</td>\n",
       "      <td>64754.586000</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>56553.990</td>\n",
       "      <td>484191.00</td>\n",
       "      <td>435436.50</td>\n",
       "      <td>435436.50</td>\n",
       "      <td>533.000000</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-1004.333333</td>\n",
       "      <td>254350.125000</td>\n",
       "      <td>270000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.555912</td>\n",
       "      <td>0.729567</td>\n",
       "      <td>-19046</td>\n",
       "      <td>0.505998</td>\n",
       "      <td>-2531</td>\n",
       "      <td>-4260.0</td>\n",
       "      <td>-867.00</td>\n",
       "      <td>-488.50</td>\n",
       "      <td>7096.155000</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5357.250</td>\n",
       "      <td>20106.00</td>\n",
       "      <td>24282.00</td>\n",
       "      <td>24282.00</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-694.000000</td>\n",
       "      <td>94518.900000</td>\n",
       "      <td>67500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.650442</td>\n",
       "      <td>0.535276</td>\n",
       "      <td>-19005</td>\n",
       "      <td>0.505998</td>\n",
       "      <td>-2437</td>\n",
       "      <td>-9833.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62947.088438</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>19517.450</td>\n",
       "      <td>291695.50</td>\n",
       "      <td>309643.26</td>\n",
       "      <td>272203.26</td>\n",
       "      <td>894.222222</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>40503.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>135000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.322738</td>\n",
       "      <td>0.535276</td>\n",
       "      <td>-19932</td>\n",
       "      <td>0.505998</td>\n",
       "      <td>-3458</td>\n",
       "      <td>-4311.0</td>\n",
       "      <td>-1149.00</td>\n",
       "      <td>-783.00</td>\n",
       "      <td>12214.060227</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>12278.805</td>\n",
       "      <td>166638.75</td>\n",
       "      <td>150530.25</td>\n",
       "      <td>150530.25</td>\n",
       "      <td>409.166667</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-757.833333</td>\n",
       "      <td>146250.000000</td>\n",
       "      <td>121500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EXT_SOURCE_2  EXT_SOURCE_3  DAYS_BIRTH  EXT_SOURCE_1  DAYS_ID_PUBLISH  \\\n",
       "0      0.262949      0.139376       -9461      0.083037            -2120   \n",
       "1      0.622246      0.535276      -16765      0.311267             -291   \n",
       "2      0.555912      0.729567      -19046      0.505998            -2531   \n",
       "3      0.650442      0.535276      -19005      0.505998            -2437   \n",
       "4      0.322738      0.535276      -19932      0.505998            -3458   \n",
       "\n",
       "   DAYS_REGISTRATION  df_avg_bureau_full_DAYS_CREDIT  \\\n",
       "0            -3648.0                         -874.00   \n",
       "1            -1186.0                        -1400.75   \n",
       "2            -4260.0                         -867.00   \n",
       "3            -9833.0                            0.00   \n",
       "4            -4311.0                        -1149.00   \n",
       "\n",
       "   df_avg_bureau_full_DAYS_CREDIT_ENDDATE  AMT_PAYMENT_df_avg_install  \\\n",
       "0                                 -344.25                11559.247105   \n",
       "1                                 -544.50                64754.586000   \n",
       "2                                 -488.50                 7096.155000   \n",
       "3                                    0.00                62947.088438   \n",
       "4                                 -783.00                12214.060227   \n",
       "\n",
       "   AMT_ANNUITY        ...         df_avg_previous_app_HOUR_APPR_PROCESS_START  \\\n",
       "0      24700.5        ...                                            9.000000   \n",
       "1      35698.5        ...                                           14.666667   \n",
       "2       6750.0        ...                                            5.000000   \n",
       "3      29686.5        ...                                           14.666667   \n",
       "4      21865.5        ...                                           12.333333   \n",
       "\n",
       "   df_avg_previous_app_AMT_ANNUITY  df_avg_previous_app_AMT_CREDIT  \\\n",
       "0                         9251.775                       179055.00   \n",
       "1                        56553.990                       484191.00   \n",
       "2                         5357.250                        20106.00   \n",
       "3                        19517.450                       291695.50   \n",
       "4                        12278.805                       166638.75   \n",
       "\n",
       "   df_avg_previous_app_AMT_GOODS_PRICE  df_avg_previous_app_AMT_APPLICATION  \\\n",
       "0                            179055.00                            179055.00   \n",
       "1                            435436.50                            435436.50   \n",
       "2                             24282.00                             24282.00   \n",
       "3                            309643.26                            272203.26   \n",
       "4                            150530.25                            150530.25   \n",
       "\n",
       "   df_avg_previous_app_SELLERPLACE_AREA  REGION_POPULATION_RELATIVE  \\\n",
       "0                            500.000000                    0.018801   \n",
       "1                            533.000000                    0.003541   \n",
       "2                             30.000000                    0.010032   \n",
       "3                            894.222222                    0.008019   \n",
       "4                            409.166667                    0.028663   \n",
       "\n",
       "   df_avg_previous_app_DAYS_LAST_DUE_1ST_VERSION  \\\n",
       "0                                     125.000000   \n",
       "1                                   -1004.333333   \n",
       "2                                    -694.000000   \n",
       "3                                   40503.444444   \n",
       "4                                    -757.833333   \n",
       "\n",
       "   df_avg_bureau_full_AMT_CREDIT_SUM  AMT_INCOME_TOTAL  \n",
       "0                      108131.945625          202500.0  \n",
       "1                      254350.125000          270000.0  \n",
       "2                       94518.900000           67500.0  \n",
       "3                           0.000000          135000.0  \n",
       "4                      146250.000000          121500.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_important.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>df_avg_bureau_full_DAYS_CREDIT</th>\n",
       "      <th>df_avg_bureau_full_DAYS_CREDIT_ENDDATE</th>\n",
       "      <th>AMT_PAYMENT_df_avg_install</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>df_avg_previous_app_HOUR_APPR_PROCESS_START</th>\n",
       "      <th>df_avg_previous_app_AMT_ANNUITY</th>\n",
       "      <th>df_avg_previous_app_AMT_CREDIT</th>\n",
       "      <th>df_avg_previous_app_AMT_GOODS_PRICE</th>\n",
       "      <th>df_avg_previous_app_AMT_APPLICATION</th>\n",
       "      <th>df_avg_previous_app_SELLERPLACE_AREA</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>df_avg_previous_app_DAYS_LAST_DUE_1ST_VERSION</th>\n",
       "      <th>df_avg_bureau_full_AMT_CREDIT_SUM</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.789654</td>\n",
       "      <td>0.159520</td>\n",
       "      <td>-19241</td>\n",
       "      <td>0.752614</td>\n",
       "      <td>-812</td>\n",
       "      <td>-5170.0</td>\n",
       "      <td>-735.000000</td>\n",
       "      <td>82.428571</td>\n",
       "      <td>5885.132143</td>\n",
       "      <td>20560.5</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3951.00000</td>\n",
       "      <td>23787.000</td>\n",
       "      <td>24835.50</td>\n",
       "      <td>24835.50</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>-1499.0</td>\n",
       "      <td>207623.571429</td>\n",
       "      <td>135000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.291656</td>\n",
       "      <td>0.432962</td>\n",
       "      <td>-18064</td>\n",
       "      <td>0.564990</td>\n",
       "      <td>-1623</td>\n",
       "      <td>-9118.0</td>\n",
       "      <td>-190.666667</td>\n",
       "      <td>439.333333</td>\n",
       "      <td>6240.205000</td>\n",
       "      <td>17370.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.5</td>\n",
       "      <td>8031.60000</td>\n",
       "      <td>20076.750</td>\n",
       "      <td>78468.75</td>\n",
       "      <td>22308.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>-368.5</td>\n",
       "      <td>219042.000000</td>\n",
       "      <td>99000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.699787</td>\n",
       "      <td>0.610991</td>\n",
       "      <td>-20038</td>\n",
       "      <td>0.506771</td>\n",
       "      <td>-3503</td>\n",
       "      <td>-2175.0</td>\n",
       "      <td>-1737.500000</td>\n",
       "      <td>-1068.000000</td>\n",
       "      <td>9740.235774</td>\n",
       "      <td>69777.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>11421.14625</td>\n",
       "      <td>146134.125</td>\n",
       "      <td>158951.25</td>\n",
       "      <td>130871.25</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.019101</td>\n",
       "      <td>-477.0</td>\n",
       "      <td>518070.015000</td>\n",
       "      <td>202500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.509677</td>\n",
       "      <td>0.612704</td>\n",
       "      <td>-13976</td>\n",
       "      <td>0.525734</td>\n",
       "      <td>-4208</td>\n",
       "      <td>-2000.0</td>\n",
       "      <td>-1401.750000</td>\n",
       "      <td>1934.750000</td>\n",
       "      <td>4356.731549</td>\n",
       "      <td>49018.5</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8</td>\n",
       "      <td>9354.95100</td>\n",
       "      <td>92920.500</td>\n",
       "      <td>94135.50</td>\n",
       "      <td>49207.50</td>\n",
       "      <td>1409.6</td>\n",
       "      <td>0.026392</td>\n",
       "      <td>72588.4</td>\n",
       "      <td>126739.590000</td>\n",
       "      <td>315000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.425687</td>\n",
       "      <td>0.519097</td>\n",
       "      <td>-13040</td>\n",
       "      <td>0.202145</td>\n",
       "      <td>-4262</td>\n",
       "      <td>-4000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11100.337500</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>17782.15500</td>\n",
       "      <td>300550.500</td>\n",
       "      <td>267727.50</td>\n",
       "      <td>267727.50</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EXT_SOURCE_2  EXT_SOURCE_3  DAYS_BIRTH  EXT_SOURCE_1  DAYS_ID_PUBLISH  \\\n",
       "0      0.789654      0.159520      -19241      0.752614             -812   \n",
       "1      0.291656      0.432962      -18064      0.564990            -1623   \n",
       "2      0.699787      0.610991      -20038      0.506771            -3503   \n",
       "3      0.509677      0.612704      -13976      0.525734            -4208   \n",
       "4      0.425687      0.519097      -13040      0.202145            -4262   \n",
       "\n",
       "   DAYS_REGISTRATION  df_avg_bureau_full_DAYS_CREDIT  \\\n",
       "0            -5170.0                     -735.000000   \n",
       "1            -9118.0                     -190.666667   \n",
       "2            -2175.0                    -1737.500000   \n",
       "3            -2000.0                    -1401.750000   \n",
       "4            -4000.0                        0.000000   \n",
       "\n",
       "   df_avg_bureau_full_DAYS_CREDIT_ENDDATE  AMT_PAYMENT_df_avg_install  \\\n",
       "0                               82.428571                 5885.132143   \n",
       "1                              439.333333                 6240.205000   \n",
       "2                            -1068.000000                 9740.235774   \n",
       "3                             1934.750000                 4356.731549   \n",
       "4                                0.000000                11100.337500   \n",
       "\n",
       "   AMT_ANNUITY        ...         df_avg_previous_app_HOUR_APPR_PROCESS_START  \\\n",
       "0      20560.5        ...                                                13.0   \n",
       "1      17370.0        ...                                                10.5   \n",
       "2      69777.0        ...                                                14.5   \n",
       "3      49018.5        ...                                                10.8   \n",
       "4      32067.0        ...                                                 5.5   \n",
       "\n",
       "   df_avg_previous_app_AMT_ANNUITY  df_avg_previous_app_AMT_CREDIT  \\\n",
       "0                       3951.00000                       23787.000   \n",
       "1                       8031.60000                       20076.750   \n",
       "2                      11421.14625                      146134.125   \n",
       "3                       9354.95100                       92920.500   \n",
       "4                      17782.15500                      300550.500   \n",
       "\n",
       "   df_avg_previous_app_AMT_GOODS_PRICE  df_avg_previous_app_AMT_APPLICATION  \\\n",
       "0                             24835.50                             24835.50   \n",
       "1                             78468.75                             22308.75   \n",
       "2                            158951.25                            130871.25   \n",
       "3                             94135.50                             49207.50   \n",
       "4                            267727.50                            267727.50   \n",
       "\n",
       "   df_avg_previous_app_SELLERPLACE_AREA  REGION_POPULATION_RELATIVE  \\\n",
       "0                                  23.0                    0.018850   \n",
       "1                                  18.0                    0.035792   \n",
       "2                                  82.0                    0.019101   \n",
       "3                                1409.6                    0.026392   \n",
       "4                                  13.0                    0.010032   \n",
       "\n",
       "   df_avg_previous_app_DAYS_LAST_DUE_1ST_VERSION  \\\n",
       "0                                        -1499.0   \n",
       "1                                         -368.5   \n",
       "2                                         -477.0   \n",
       "3                                        72588.4   \n",
       "4                                         -409.0   \n",
       "\n",
       "   df_avg_bureau_full_AMT_CREDIT_SUM  AMT_INCOME_TOTAL  \n",
       "0                      207623.571429          135000.0  \n",
       "1                      219042.000000           99000.0  \n",
       "2                      518070.015000          202500.0  \n",
       "3                      126739.590000          315000.0  \n",
       "4                           0.000000          180000.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_important.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 on Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] n_estimators=20 .................................................\n",
      "[CV] ........ n_estimators=20, score=0.6765167707557205, total=  24.7s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   26.0s remaining:    0.0s\n",
      "[CV] n_estimators=20 .................................................\n",
      "[CV] ........ n_estimators=20, score=0.6723283346583926, total=  25.5s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   52.8s remaining:    0.0s\n",
      "[CV] n_estimators=20 .................................................\n",
      "[CV] ........ n_estimators=20, score=0.6752317513078454, total=  25.4s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....... n_estimators=250, score=0.7274349578206645, total= 5.1min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  6.7min remaining:    0.0s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....... n_estimators=250, score=0.7210943860202498, total= 5.2min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.1min remaining:    0.0s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....... n_estimators=250, score=0.7240136619194658, total= 5.2min\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 17.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 17.5min finished\n",
      "0.6746922838196888 {'n_estimators': 20}\n",
      "0.7241810024643024 {'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "# Run GridSearch cross validation with Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_rf = RandomForestClassifier(random_state=123)\n",
    "\n",
    "# Random forest (similar to before with 250 + much smaller 20) \n",
    "param_grid = {'n_estimators': [20, 250]}\n",
    "\n",
    "# CV = 3 to cut short computational time\n",
    "grid_search_train_rf = GridSearchCV(estimator=model_rf, param_grid=param_grid , cv=3, scoring='roc_auc', verbose=100)\n",
    "\n",
    "grid_search_train_rf.fit(X_train_important, y_train)\n",
    "\n",
    "# Results of the grid search in general\n",
    "cvres = grid_search_train_rf.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7241656994488614\n"
     ]
    }
   ],
   "source": [
    "# Find BEST model\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "forest_merge_clf = grid_search_train_rf.best_estimator_\n",
    "y_probas_merge_forest = cross_val_predict(forest_merge_clf, X_train_important, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_merge_forest = y_probas_merge_forest[:, 1] \n",
    "fpr_merge_forest, tpr_merge_forest, thresholds_merge_forest = roc_curve(y_train, y_scores_merge_forest)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_merge_forest, tpr_merge_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = forest_merge_clf.predict_proba(X_test_important)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('random_forest_30_importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 15 / 20 (with Polynomial Features) on Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, top 15 only\n",
    "X_train_important = training_df [['EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'EXT_SOURCE_1', 'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION', 'df_avg_bureau_full_DAYS_CREDIT', 'df_avg_bureau_full_DAYS_CREDIT_ENDDATE', 'AMT_PAYMENT_df_avg_install', 'AMT_ANNUITY', 'DAYS_EMPLOYED', 'df_avg_bureau_full_DAYS_CREDIT_UPDATE', 'df_avg_pos_cash_CNT_INSTALMENT_FUTURE', 'AMT_INSTALMENT_df_avg_install', 'DAYS_LAST_PHONE_CHANGE']]\n",
    "X_test_important = testing_df [['EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'EXT_SOURCE_1', 'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION', 'df_avg_bureau_full_DAYS_CREDIT', 'df_avg_bureau_full_DAYS_CREDIT_ENDDATE', 'AMT_PAYMENT_df_avg_install', 'AMT_ANNUITY', 'DAYS_EMPLOYED', 'df_avg_bureau_full_DAYS_CREDIT_UPDATE', 'df_avg_pos_cash_CNT_INSTALMENT_FUTURE', 'AMT_INSTALMENT_df_avg_install', 'DAYS_LAST_PHONE_CHANGE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Polynomial Features (of 2) on the top 15 important features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree = 2, interaction_only = True, include_bias = False)\n",
    "p = poly.fit(X_train_important)\n",
    "\n",
    "X_tr = poly.transform (X_train_important) \n",
    "X_te = poly.transform (X_test_important) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 120)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "\n",
    "X_tr = scaler.transform(X_tr)\n",
    "X_te = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....... n_estimators=250, score=0.7135574204886669, total=12.8min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 13.0min remaining:    0.0s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....... n_estimators=250, score=0.7077648470899089, total=12.8min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 26.0min remaining:    0.0s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....... n_estimators=250, score=0.7147837622623122, total=17.7min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 44.0min remaining:    0.0s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ........ n_estimators=300, score=0.714585641286114, total=15.9min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 60.2min remaining:    0.0s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ....... n_estimators=300, score=0.7083235438612476, total=15.5min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 76.0min remaining:    0.0s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ....... n_estimators=300, score=0.7155326490339623, total=15.5min\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 91.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 91.8min finished\n",
      "0.7120353343426677 {'n_estimators': 250}\n",
      "0.7128139358861093 {'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Run GridSearch cross validation with Random Forest\n",
    "\n",
    "poly_rf = RandomForestClassifier(random_state=123)\n",
    "\n",
    "# Random forest (similar to before with 250 + a bit bigger 300) \n",
    "param_grid = {'n_estimators': [250, 300]}\n",
    "\n",
    "# CV = 3 to cut short computational time\n",
    "grid_search_poly_rf = GridSearchCV(estimator=poly_rf, param_grid=param_grid , cv=3, scoring='roc_auc', verbose=100)\n",
    "\n",
    "grid_search_poly_rf.fit(X_tr, y_train)\n",
    "\n",
    "# Results of the grid search in general\n",
    "cvres = grid_search_poly_rf.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7127933335004827\n"
     ]
    }
   ],
   "source": [
    "forest_polymerge_clf = grid_search_poly_rf.best_estimator_\n",
    "y_probas_poly_forest = cross_val_predict(forest_polymerge_clf, X_tr, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_poly_forest = y_probas_poly_forest[:, 1] \n",
    "fpr_poly_forest, tpr_poly_forest, thresholds_poly_forest = roc_curve(y_train, y_scores_poly_forest)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_poly_forest, tpr_poly_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = forest_polymerge_clf.predict_proba(X_te)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('random_forest_15_importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] .... C=0.001, penalty=l1, score=0.7242571047027268, total=   2.9s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.0s remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] .... C=0.001, penalty=l1, score=0.7205894953026147, total=   3.6s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.7s remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] .... C=0.001, penalty=l1, score=0.7281903852928815, total=   3.4s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   10.2s remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] .... C=0.001, penalty=l2, score=0.7307548048001207, total=   7.3s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   17.6s remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] .... C=0.001, penalty=l2, score=0.7268739231054359, total=   8.8s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   26.5s remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] .... C=0.001, penalty=l2, score=0.7356548511824569, total=   7.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   33.7s remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l1, score=0.7295166576738761, total=   7.1s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   40.9s remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l1, score=0.7260844560107617, total=   9.6s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   50.6s remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l1, score=0.7344774101308813, total=   7.8s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   58.5s remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l2, score=0.7318733358942133, total=  11.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l2, score=0.7279680180048611, total=  11.7s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:  1.4min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l2, score=0.7368863258584596, total=  11.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  1.5min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l1, score=0.7323600142469657, total= 1.3min\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:  2.9min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l1, score=0.7284252187710476, total= 1.9min\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  4.8min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l1, score=0.7371685095750912, total= 1.2min\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  5.9min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l2, score=0.7323415492353766, total=  24.5s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  6.3min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l2, score=0.7282993417174635, total=  24.5s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  6.7min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ....... C=0.1, penalty=l2, score=0.737056914212195, total=  21.9s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  7.1min remaining:    0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ........ C=1, penalty=l1, score=0.7324813552020646, total= 3.7min\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed: 10.8min remaining:    0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ........ C=1, penalty=l1, score=0.7284504039285409, total= 7.1min\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 17.9min remaining:    0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ........ C=1, penalty=l1, score=0.7371142130414023, total= 5.3min\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed: 23.2min remaining:    0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ........ C=1, penalty=l2, score=0.7324123736738413, total=  31.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed: 23.7min remaining:    0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ......... C=1, penalty=l2, score=0.728409385389114, total=  37.5s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed: 24.3min remaining:    0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ........ C=1, penalty=l2, score=0.7370670997017327, total=  27.5s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 24.8min remaining:    0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ....... C=10, penalty=l1, score=0.7324221730316378, total= 5.6min\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed: 30.4min remaining:    0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ....... C=10, penalty=l1, score=0.7284260690490503, total= 9.5min\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed: 39.9min remaining:    0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ....... C=10, penalty=l1, score=0.7370693402016347, total= 8.9min\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 48.9min remaining:    0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ....... C=10, penalty=l2, score=0.7324122069526642, total=  29.8s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed: 49.4min remaining:    0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ....... C=10, penalty=l2, score=0.7284157130990168, total=  37.8s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed: 50.0min remaining:    0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ....... C=10, penalty=l2, score=0.7370561690888733, total=  36.2s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 50.6min remaining:    0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ...... C=100, penalty=l1, score=0.7324164070438542, total= 8.9min\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed: 59.5min remaining:    0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ...... C=100, penalty=l1, score=0.7284230321586875, total=10.3min\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed: 69.8min remaining:    0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ...... C=100, penalty=l1, score=0.7370608745234128, total=10.4min\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed: 80.2min remaining:    0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ...... C=100, penalty=l2, score=0.7324128597301957, total=  32.5s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed: 80.8min remaining:    0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ...... C=100, penalty=l2, score=0.7284167390754906, total=  42.1s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed: 81.5min remaining:    0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ...... C=100, penalty=l2, score=0.7370544326052627, total=  39.7s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed: 82.1min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l1 ..............................................\n",
      "[CV] ..... C=1000, penalty=l1, score=0.7324162390402066, total= 9.0min\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed: 91.1min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l1 ..............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=1000, penalty=l1, score=0.7284226281804509, total= 9.1min\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed: 100.2min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l1 ..............................................\n",
      "[CV] ..... C=1000, penalty=l1, score=0.7370599549822395, total=10.1min\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed: 110.3min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l2 ..............................................\n",
      "[CV] ..... C=1000, penalty=l2, score=0.7324131867601968, total=  32.7s\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 110.9min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l2 ..............................................\n",
      "[CV] ..... C=1000, penalty=l2, score=0.7284159298365469, total=  41.7s\n",
      "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed: 111.6min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l2 ..............................................\n",
      "[CV] ..... C=1000, penalty=l2, score=0.7370539683459815, total=  42.2s\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed: 112.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed: 112.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Late add-on. Try with log reg.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "log_rf = LogisticRegression(random_state=123)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],'penalty': ['l1', 'l2']}\n",
    "\n",
    "# CV = 3 to cut short computational time\n",
    "grid_search_log_rf = GridSearchCV(estimator=log_rf, param_grid=param_grid , cv=3, scoring='roc_auc', verbose=100)\n",
    "\n",
    "grid_search_log_rf.fit(X_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7326402918958993\n"
     ]
    }
   ],
   "source": [
    "# Find BEST model\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "log_final_clf = grid_search_log_rf.best_estimator_\n",
    "y_probas_log_final = cross_val_predict(log_final_clf, X_tr, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_log_final = y_probas_log_final[:, 1] \n",
    "fpr_log_final, tpr_log_final, thresholds_log_final = roc_curve(y_train, y_scores_log_final)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_log_final, tpr_log_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = log_final_clf.predict_proba(X_te)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('poly_log_final_importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More tweaking with Poly Features\n",
    "\n",
    "#### Poly-2 with top 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, top 20 only\n",
    "X_20train_important = training_df [['EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'EXT_SOURCE_1', 'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION', 'df_avg_bureau_full_DAYS_CREDIT', 'df_avg_bureau_full_DAYS_CREDIT_ENDDATE', 'AMT_PAYMENT_df_avg_install', 'AMT_ANNUITY', 'DAYS_EMPLOYED', 'df_avg_bureau_full_DAYS_CREDIT_UPDATE', 'df_avg_pos_cash_CNT_INSTALMENT_FUTURE', 'AMT_INSTALMENT_df_avg_install', 'DAYS_LAST_PHONE_CHANGE', 'AMT_CREDIT', 'DAYS_ENTRY_PAYMENT_df_avg_install', 'DAYS_INSTALMENT_df_avg_install', 'df_avg_previous_app_DAYS_FIRST_DUE', 'df_avg_previous_app_DAYS_DECISION']]\n",
    "X_20test_important = testing_df [['EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'EXT_SOURCE_1', 'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION', 'df_avg_bureau_full_DAYS_CREDIT', 'df_avg_bureau_full_DAYS_CREDIT_ENDDATE', 'AMT_PAYMENT_df_avg_install', 'AMT_ANNUITY', 'DAYS_EMPLOYED', 'df_avg_bureau_full_DAYS_CREDIT_UPDATE', 'df_avg_pos_cash_CNT_INSTALMENT_FUTURE', 'AMT_INSTALMENT_df_avg_install', 'DAYS_LAST_PHONE_CHANGE', 'AMT_CREDIT', 'DAYS_ENTRY_PAYMENT_df_avg_install', 'DAYS_INSTALMENT_df_avg_install', 'df_avg_previous_app_DAYS_FIRST_DUE', 'df_avg_previous_app_DAYS_DECISION']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Polynomial Features (of 2) on the top 20 important features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree = 2, interaction_only = True, include_bias = False)\n",
    "p = poly.fit(X_20train_important)\n",
    "\n",
    "X_20tr = poly.transform (X_20train_important) \n",
    "X_20te = poly.transform (X_20test_important) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 210)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_20tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_20tr)\n",
    "\n",
    "X_20tr = scaler.transform(X_20tr)\n",
    "X_20te = scaler.transform(X_20te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "[CV] n_estimators=20 .................................................\n",
      "[CV] ........ n_estimators=20, score=0.6692410435341052, total= 1.2min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] n_estimators=20 .................................................\n",
      "[CV] ......... n_estimators=20, score=0.666434328293146, total= 1.1min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV] n_estimators=275 ................................................\n",
      "[CV] ....... n_estimators=275, score=0.7106483517618999, total=25.7min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 28.2min remaining:    0.0s\n",
      "[CV] n_estimators=275 ................................................\n",
      "[CV] ....... n_estimators=275, score=0.7102088470275894, total=15.1min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 43.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 43.4min finished\n",
      "0.6678376904772269 {'n_estimators': 20}\n",
      "0.7104286001093609 {'n_estimators': 275}\n"
     ]
    }
   ],
   "source": [
    "# Run GridSearch cross validation with Random Forest\n",
    "\n",
    "poly20_rf = RandomForestClassifier(random_state=123)\n",
    "\n",
    "# Random forest  \n",
    "param_grid = {'n_estimators': [20, 275]}\n",
    "\n",
    "# CV = 2 to cut short computational time\n",
    "grid_search_poly20_rf = GridSearchCV(estimator=poly20_rf, param_grid=param_grid , cv=2, scoring='roc_auc', verbose=100)\n",
    "\n",
    "grid_search_poly20_rf.fit(X_20tr, y_train)\n",
    "\n",
    "# Results of the grid search in general\n",
    "cvres = grid_search_poly20_rf.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid_search_poly20_rf.best_estimator_.predict_proba(X_20te)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('random_forest_20_importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poly-3 with top 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Polynomial Features (of 3) on the top 15 important features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree = 3, interaction_only = True, include_bias = False)\n",
    "p = poly.fit(X_train_important)\n",
    "\n",
    "X_3tr = poly.transform (X_train_important) \n",
    "X_3te = poly.transform (X_test_important) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_3tr)\n",
    "\n",
    "X_3tr = scaler.transform(X_3tr)\n",
    "X_3te = scaler.transform(X_3te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 575)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_3tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "[CV] n_estimators=20 .................................................\n",
      "[CV] ........ n_estimators=20, score=0.6634079110249627, total= 1.9min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.9min remaining:    0.0s\n",
      "[CV] n_estimators=20 .................................................\n",
      "[CV] ........ n_estimators=20, score=0.6630187553822376, total= 1.9min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.8min remaining:    0.0s\n",
      "[CV] n_estimators=275 ................................................\n",
      "[CV] ....... n_estimators=275, score=0.7041909731250383, total=26.4min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 30.5min remaining:    0.0s\n",
      "[CV] n_estimators=275 ................................................\n",
      "[CV] ....... n_estimators=275, score=0.7051535376777838, total=26.6min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 57.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 57.4min finished\n",
      "0.663213333836351 {'n_estimators': 20}\n",
      "0.7046722538363214 {'n_estimators': 275}\n"
     ]
    }
   ],
   "source": [
    "# Run GridSearch cross validation with Random Forest\n",
    "\n",
    "poly3_rf = RandomForestClassifier(random_state=123)\n",
    "\n",
    "# Random forest \n",
    "param_grid = {'n_estimators': [20, 275]}\n",
    "\n",
    "# CV = 2 to cut short computational time\n",
    "grid_search_poly3_rf = GridSearchCV(estimator=poly3_rf, param_grid=param_grid , cv=2, scoring='roc_auc', verbose=100)\n",
    "\n",
    "grid_search_poly3_rf.fit(X_3tr, y_train)\n",
    "\n",
    "# Results of the grid search in general\n",
    "cvres = grid_search_poly3_rf.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid_search_poly3_rf.best_estimator_.predict_proba(X_3te)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('random_forest_3_importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 300 (without high correlation) on Random Forest\n",
    "#### First drop columns with importance less 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 175 features with less 0.0005 importance\n"
     ]
    }
   ],
   "source": [
    "# Load importance data\n",
    "feature_importances = load_credit_data (\"feature_importances_merged_sorted.csv\")\n",
    "\n",
    "# Find poor features (arbitrary threshold 0.0005)\n",
    "poor_features = list(feature_importances[feature_importances['importance'] < 0.0005]['feature'])\n",
    "print('There are %d features with less 0.0005 importance' % len(poor_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OCCUPATION_TYPE_Cleaning staff',\n",
       " 'NAME_EDUCATION_TYPE_Incomplete higher',\n",
       " 'ORGANIZATION_TYPE_Business Entity Type 1',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Medicine',\n",
       " 'df_avg_previous_app_NAME_GOODS_CATEGORY_Office Appliances',\n",
       " 'ORGANIZATION_TYPE_Medicine',\n",
       " 'df_avg_previous_app_NAME_TYPE_SUITE_Group of people',\n",
       " 'df_avg_previous_app_NAME_GOODS_CATEGORY_Sport and Leisure',\n",
       " 'ORGANIZATION_TYPE_Transport: type 3',\n",
       " 'ORGANIZATION_TYPE_Trade: type 3',\n",
       " 'df_avg_bureau_full_df_sum_bureau_bal_STATUS__4',\n",
       " 'df_avg_previous_app_CODE_REJECT_REASON_VERIF',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Payments on other loans',\n",
       " 'NAME_TYPE_SUITE_Children',\n",
       " 'OCCUPATION_TYPE_High skill tech staff',\n",
       " 'ORGANIZATION_TYPE_Agriculture',\n",
       " 'ORGANIZATION_TYPE_Kindergarten',\n",
       " 'ORGANIZATION_TYPE_Security',\n",
       " 'OCCUPATION_TYPE_Medicine staff',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Everyday expenses',\n",
       " 'ORGANIZATION_TYPE_School',\n",
       " 'FLAG_DOCUMENT_5',\n",
       " 'df_avg_previous_app_NAME_GOODS_CATEGORY_Gardening',\n",
       " 'REG_REGION_NOT_LIVE_REGION',\n",
       " 'df_avg_previous_app_NAME_SELLER_INDUSTRY_Jewelry',\n",
       " 'ORGANIZATION_TYPE_Restaurant',\n",
       " 'df_avg_previous_app_NAME_GOODS_CATEGORY_Other',\n",
       " 'NAME_TYPE_SUITE_Other_B',\n",
       " 'ORGANIZATION_TYPE_Industry: type 11',\n",
       " 'WALLSMATERIAL_MODE_Block',\n",
       " 'AMT_REQ_CREDIT_BUREAU_DAY',\n",
       " 'FONDKAPREMONT_MODE_reg oper spec account',\n",
       " 'ORGANIZATION_TYPE_Housing',\n",
       " 'df_avg_previous_app_NAME_GOODS_CATEGORY_Medical Supplies',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Car repairs',\n",
       " 'df_avg_previous_app_NAME_CLIENT_TYPE_XNA',\n",
       " 'df_avg_previous_app_PRODUCT_COMBINATION_POS others without interest',\n",
       " 'ORGANIZATION_TYPE_Postal',\n",
       " 'OCCUPATION_TYPE_Waiters/barmen staff',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Education',\n",
       " 'OCCUPATION_TYPE_Accountants',\n",
       " 'ORGANIZATION_TYPE_Transport: type 2',\n",
       " 'df_avg_bureau_full_CREDIT_TYPE__Loan for business development',\n",
       " 'ORGANIZATION_TYPE_Industry: type 1',\n",
       " 'df_avg_previous_app_NAME_GOODS_CATEGORY_Medicine',\n",
       " 'ORGANIZATION_TYPE_Industry: type 9',\n",
       " 'NAME_HOUSING_TYPE_Office apartment',\n",
       " 'WALLSMATERIAL_MODE_Wooden',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Wedding / gift / holiday',\n",
       " 'FONDKAPREMONT_MODE_org spec account',\n",
       " 'HOUSETYPE_MODE_specific housing',\n",
       " 'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
       " 'OCCUPATION_TYPE_Private service staff',\n",
       " 'df_avg_previous_app_NAME_PAYMENT_TYPE_Cashless from the account of the employer',\n",
       " 'df_avg_pos_cash_NAME_CONTRACT_STATUS__Demand',\n",
       " 'ORGANIZATION_TYPE_Industry: type 4',\n",
       " 'WALLSMATERIAL_MODE_Others',\n",
       " 'ORGANIZATION_TYPE_Industry: type 7',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Purchase of electronic equipment',\n",
       " 'EMERGENCYSTATE_MODE_Yes',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Journey',\n",
       " 'WALLSMATERIAL_MODE_Mixed',\n",
       " 'NAME_TYPE_SUITE_Other_A',\n",
       " 'df_avg_bureau_full_CREDIT_TYPE__Another type of loan',\n",
       " 'NAME_HOUSING_TYPE_Co-op apartment',\n",
       " 'OCCUPATION_TYPE_Secretaries',\n",
       " 'ORGANIZATION_TYPE_Services',\n",
       " 'ORGANIZATION_TYPE_Military',\n",
       " 'FLAG_DOCUMENT_18',\n",
       " 'FLAG_DOCUMENT_16',\n",
       " 'OCCUPATION_TYPE_Realty agents',\n",
       " 'ORGANIZATION_TYPE_Trade: type 2',\n",
       " 'ORGANIZATION_TYPE_Police',\n",
       " 'df_avg_previous_app_CHANNEL_TYPE_Channel of corporate sales',\n",
       " 'df_avg_previous_app_PRODUCT_COMBINATION_Unspecified',\n",
       " 'ORGANIZATION_TYPE_Realtor',\n",
       " 'ORGANIZATION_TYPE_Bank',\n",
       " 'ORGANIZATION_TYPE_Telecom',\n",
       " 'NAME_TYPE_SUITE_Unspecified',\n",
       " 'ORGANIZATION_TYPE_Electricity',\n",
       " 'df_avg_bureau_full_CREDIT_TYPE__Loan for working capital replenishment',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Furniture',\n",
       " 'FLAG_DOCUMENT_9',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Buying a new car',\n",
       " 'df_avg_previous_app_NAME_CONTRACT_TYPE_XNA',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Buying a home',\n",
       " 'ORGANIZATION_TYPE_Security Ministries',\n",
       " 'df_avg_previous_app_NAME_SELLER_INDUSTRY_MLM partners',\n",
       " 'df_avg_bureau_full_CREDIT_CURRENCY__currency 2',\n",
       " 'ORGANIZATION_TYPE_University',\n",
       " 'df_avg_previous_app_NAME_GOODS_CATEGORY_Direct Sales',\n",
       " 'df_avg_previous_app_NAME_GOODS_CATEGORY_Tourism',\n",
       " 'ORGANIZATION_TYPE_Hotel',\n",
       " 'df_avg_bureau_full_CREDIT_TYPE__Unknown type of loan',\n",
       " 'HOUSETYPE_MODE_terraced house',\n",
       " 'ORGANIZATION_TYPE_Advertising',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Gasification / water supply',\n",
       " 'ORGANIZATION_TYPE_Mobile',\n",
       " 'ORGANIZATION_TYPE_Emergency',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Business development',\n",
       " 'ORGANIZATION_TYPE_Industry: type 5',\n",
       " 'FLAG_CONT_MOBILE',\n",
       " 'ORGANIZATION_TYPE_Trade: type 1',\n",
       " 'df_avg_previous_app_CODE_REJECT_REASON_SYSTEM',\n",
       " 'ORGANIZATION_TYPE_Industry: type 2',\n",
       " 'ORGANIZATION_TYPE_Cleaning',\n",
       " 'OCCUPATION_TYPE_HR staff',\n",
       " 'FLAG_DOCUMENT_11',\n",
       " 'ORGANIZATION_TYPE_Insurance',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Buying a holiday home / land',\n",
       " 'ORGANIZATION_TYPE_Legal Services',\n",
       " 'OCCUPATION_TYPE_IT staff',\n",
       " 'NAME_TYPE_SUITE_Group of people',\n",
       " 'WALLSMATERIAL_MODE_Monolithic',\n",
       " 'ORGANIZATION_TYPE_Culture',\n",
       " 'df_avg_bureau_full_CREDIT_CURRENCY__currency 3',\n",
       " 'ORGANIZATION_TYPE_Trade: type 6',\n",
       " 'df_avg_credit_card_NAME_CONTRACT_STATUS__Sent proposal',\n",
       " 'ORGANIZATION_TYPE_Industry: type 12',\n",
       " 'FLAG_DOCUMENT_21',\n",
       " 'FLAG_DOCUMENT_14',\n",
       " 'FLAG_DOCUMENT_19',\n",
       " 'FLAG_DOCUMENT_13',\n",
       " 'df_avg_previous_app_NAME_GOODS_CATEGORY_Insurance',\n",
       " 'df_avg_previous_app_NAME_GOODS_CATEGORY_Additional Service',\n",
       " 'df_avg_previous_app_NAME_SELLER_INDUSTRY_Tourism',\n",
       " 'df_avg_previous_app_CHANNEL_TYPE_Car dealer',\n",
       " 'df_avg_previous_app_NAME_GOODS_CATEGORY_Fitness',\n",
       " 'FLAG_DOCUMENT_20',\n",
       " 'ORGANIZATION_TYPE_Industry: type 6',\n",
       " 'df_avg_previous_app_NAME_PORTFOLIO_Cars',\n",
       " 'ORGANIZATION_TYPE_Industry: type 13',\n",
       " 'ORGANIZATION_TYPE_Transport: type 1',\n",
       " 'ORGANIZATION_TYPE_Industry: type 10',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Buying a garage',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Hobby',\n",
       " 'FLAG_DOCUMENT_15',\n",
       " 'NAME_INCOME_TYPE_Unemployed',\n",
       " 'ORGANIZATION_TYPE_Religion',\n",
       " 'ORGANIZATION_TYPE_Trade: type 5',\n",
       " 'df_avg_bureau_full_CREDIT_TYPE__Cash loan (non-earmarked)',\n",
       " 'df_avg_previous_app_NAME_GOODS_CATEGORY_Education',\n",
       " 'df_avg_bureau_full_CREDIT_TYPE__Loan for the purchase of equipment',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Money for a third person',\n",
       " 'NAME_EDUCATION_TYPE_Academic degree',\n",
       " 'FLAG_DOCUMENT_2',\n",
       " 'df_avg_bureau_full_CREDIT_ACTIVE__Bad debt',\n",
       " 'df_avg_previous_app_NAME_GOODS_CATEGORY_Weapon',\n",
       " 'FLAG_DOCUMENT_7',\n",
       " 'df_avg_pos_cash_NAME_CONTRACT_STATUS__Amortized debt',\n",
       " 'FLAG_DOCUMENT_17',\n",
       " 'df_avg_credit_card_NAME_CONTRACT_STATUS__Demand',\n",
       " 'ORGANIZATION_TYPE_Trade: type 4',\n",
       " 'ORGANIZATION_TYPE_Industry: type 8',\n",
       " 'df_avg_credit_card_NAME_CONTRACT_STATUS__Refused',\n",
       " 'NAME_INCOME_TYPE_Maternity leave',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_Refusal to name the goal',\n",
       " 'df_avg_pos_cash_NAME_CONTRACT_STATUS__Canceled',\n",
       " 'FLAG_DOCUMENT_10',\n",
       " 'df_avg_bureau_full_CREDIT_CURRENCY__currency 4',\n",
       " 'df_avg_bureau_full_CREDIT_TYPE__Mobile operator loan',\n",
       " 'FLAG_DOCUMENT_4',\n",
       " 'NAME_INCOME_TYPE_Student',\n",
       " 'CODE_GENDER_XNA',\n",
       " 'NAME_INCOME_TYPE_Businessman',\n",
       " 'df_avg_bureau_full_CREDIT_TYPE__Real estate loan',\n",
       " 'df_avg_previous_app_NAME_GOODS_CATEGORY_Animals',\n",
       " 'df_avg_previous_app_NAME_GOODS_CATEGORY_House Construction',\n",
       " 'FLAG_MOBIL',\n",
       " 'df_avg_bureau_full_CREDIT_TYPE__Loan for purchase of shares (margin lending)',\n",
       " 'df_avg_bureau_full_CREDIT_TYPE__Interbank credit',\n",
       " 'FLAG_DOCUMENT_12',\n",
       " 'df_avg_pos_cash_NAME_CONTRACT_STATUS__XNA',\n",
       " 'NAME_FAMILY_STATUS_Unknown',\n",
       " 'df_avg_credit_card_NAME_CONTRACT_STATUS__Approved']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poor_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (307511, 334)\n",
      "Testing shape:  (48744, 334)\n"
     ]
    }
   ],
   "source": [
    "# Remove those features\n",
    "top_training_df = training_df.drop(columns = poor_features)\n",
    "top_testing_df = testing_df.drop(columns = poor_features)\n",
    "\n",
    "print('Training shape: ', top_training_df.shape)\n",
    "print('Testing shape: ', top_testing_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second drop columns with correlation > 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>df_avg_pos_cash_NAME_CONTRACT_STATUS__Completed</th>\n",
       "      <th>df_avg_pos_cash_NAME_CONTRACT_STATUS__Returned to the store</th>\n",
       "      <th>df_avg_pos_cash_NAME_CONTRACT_STATUS__Signed</th>\n",
       "      <th>SK_ID_PREV_df_avg_install</th>\n",
       "      <th>NUM_INSTALMENT_VERSION_df_avg_install</th>\n",
       "      <th>NUM_INSTALMENT_NUMBER_df_avg_install</th>\n",
       "      <th>DAYS_INSTALMENT_df_avg_install</th>\n",
       "      <th>DAYS_ENTRY_PAYMENT_df_avg_install</th>\n",
       "      <th>AMT_INSTALMENT_df_avg_install</th>\n",
       "      <th>AMT_PAYMENT_df_avg_install</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012882</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.021377</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.025573</td>\n",
       "      <td>0.330938</td>\n",
       "      <td>0.239818</td>\n",
       "      <td>0.183395</td>\n",
       "      <td>0.028019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032172</td>\n",
       "      <td>0.007098</td>\n",
       "      <td>0.018951</td>\n",
       "      <td>0.027959</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.018372</td>\n",
       "      <td>0.016923</td>\n",
       "      <td>0.016894</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.017802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <td>0.012882</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.156870</td>\n",
       "      <td>0.191657</td>\n",
       "      <td>0.159632</td>\n",
       "      <td>0.074796</td>\n",
       "      <td>0.027261</td>\n",
       "      <td>0.064223</td>\n",
       "      <td>0.027805</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.018304</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.008114</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>0.072202</td>\n",
       "      <td>0.071600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.156870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.770127</td>\n",
       "      <td>0.986734</td>\n",
       "      <td>0.099738</td>\n",
       "      <td>0.055436</td>\n",
       "      <td>0.066838</td>\n",
       "      <td>0.009621</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015925</td>\n",
       "      <td>0.008273</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>0.043097</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.053916</td>\n",
       "      <td>0.046025</td>\n",
       "      <td>0.045590</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.134209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <td>0.021377</td>\n",
       "      <td>0.191657</td>\n",
       "      <td>0.770127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.774837</td>\n",
       "      <td>0.118418</td>\n",
       "      <td>0.009443</td>\n",
       "      <td>0.104329</td>\n",
       "      <td>0.038514</td>\n",
       "      <td>0.011267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042013</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.012460</td>\n",
       "      <td>0.022048</td>\n",
       "      <td>0.009907</td>\n",
       "      <td>0.036663</td>\n",
       "      <td>0.034275</td>\n",
       "      <td>0.034038</td>\n",
       "      <td>0.160239</td>\n",
       "      <td>0.157750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.159632</td>\n",
       "      <td>0.986734</td>\n",
       "      <td>0.774837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.103519</td>\n",
       "      <td>0.053510</td>\n",
       "      <td>0.064767</td>\n",
       "      <td>0.011546</td>\n",
       "      <td>0.009289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016597</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>0.019433</td>\n",
       "      <td>0.036975</td>\n",
       "      <td>0.020915</td>\n",
       "      <td>0.046563</td>\n",
       "      <td>0.044585</td>\n",
       "      <td>0.044182</td>\n",
       "      <td>0.133820</td>\n",
       "      <td>0.137636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "CNT_CHILDREN          1.000000          0.012882    0.002145     0.021377   \n",
       "AMT_INCOME_TOTAL      0.012882          1.000000    0.156870     0.191657   \n",
       "AMT_CREDIT            0.002145          0.156870    1.000000     0.770127   \n",
       "AMT_ANNUITY           0.021377          0.191657    0.770127     1.000000   \n",
       "AMT_GOODS_PRICE       0.001856          0.159632    0.986734     0.774837   \n",
       "\n",
       "                  AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "CNT_CHILDREN             0.001856                    0.025573    0.330938   \n",
       "AMT_INCOME_TOTAL         0.159632                    0.074796    0.027261   \n",
       "AMT_CREDIT               0.986734                    0.099738    0.055436   \n",
       "AMT_ANNUITY              0.774837                    0.118418    0.009443   \n",
       "AMT_GOODS_PRICE          1.000000                    0.103519    0.053510   \n",
       "\n",
       "                  DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  \\\n",
       "CNT_CHILDREN           0.239818           0.183395         0.028019   \n",
       "AMT_INCOME_TOTAL       0.064223           0.027805         0.008506   \n",
       "AMT_CREDIT             0.066838           0.009621         0.006575   \n",
       "AMT_ANNUITY            0.104329           0.038514         0.011267   \n",
       "AMT_GOODS_PRICE        0.064767           0.011546         0.009289   \n",
       "\n",
       "                             ...              \\\n",
       "CNT_CHILDREN                 ...               \n",
       "AMT_INCOME_TOTAL             ...               \n",
       "AMT_CREDIT                   ...               \n",
       "AMT_ANNUITY                  ...               \n",
       "AMT_GOODS_PRICE              ...               \n",
       "\n",
       "                  df_avg_pos_cash_NAME_CONTRACT_STATUS__Completed  \\\n",
       "CNT_CHILDREN                                             0.032172   \n",
       "AMT_INCOME_TOTAL                                         0.001148   \n",
       "AMT_CREDIT                                               0.015925   \n",
       "AMT_ANNUITY                                              0.042013   \n",
       "AMT_GOODS_PRICE                                          0.016597   \n",
       "\n",
       "                  df_avg_pos_cash_NAME_CONTRACT_STATUS__Returned to the store  \\\n",
       "CNT_CHILDREN                                               0.007098             \n",
       "AMT_INCOME_TOTAL                                           0.001847             \n",
       "AMT_CREDIT                                                 0.008273             \n",
       "AMT_ANNUITY                                                0.003109             \n",
       "AMT_GOODS_PRICE                                            0.008120             \n",
       "\n",
       "                  df_avg_pos_cash_NAME_CONTRACT_STATUS__Signed  \\\n",
       "CNT_CHILDREN                                          0.018951   \n",
       "AMT_INCOME_TOTAL                                      0.003613   \n",
       "AMT_CREDIT                                            0.019757   \n",
       "AMT_ANNUITY                                           0.012460   \n",
       "AMT_GOODS_PRICE                                       0.019433   \n",
       "\n",
       "                  SK_ID_PREV_df_avg_install  \\\n",
       "CNT_CHILDREN                       0.027959   \n",
       "AMT_INCOME_TOTAL                   0.018304   \n",
       "AMT_CREDIT                         0.043097   \n",
       "AMT_ANNUITY                        0.022048   \n",
       "AMT_GOODS_PRICE                    0.036975   \n",
       "\n",
       "                  NUM_INSTALMENT_VERSION_df_avg_install  \\\n",
       "CNT_CHILDREN                                   0.000395   \n",
       "AMT_INCOME_TOTAL                               0.006702   \n",
       "AMT_CREDIT                                     0.025003   \n",
       "AMT_ANNUITY                                    0.009907   \n",
       "AMT_GOODS_PRICE                                0.020915   \n",
       "\n",
       "                  NUM_INSTALMENT_NUMBER_df_avg_install  \\\n",
       "CNT_CHILDREN                                  0.018372   \n",
       "AMT_INCOME_TOTAL                              0.015066   \n",
       "AMT_CREDIT                                    0.053916   \n",
       "AMT_ANNUITY                                   0.036663   \n",
       "AMT_GOODS_PRICE                               0.046563   \n",
       "\n",
       "                  DAYS_INSTALMENT_df_avg_install  \\\n",
       "CNT_CHILDREN                            0.016923   \n",
       "AMT_INCOME_TOTAL                        0.008114   \n",
       "AMT_CREDIT                              0.046025   \n",
       "AMT_ANNUITY                             0.034275   \n",
       "AMT_GOODS_PRICE                         0.044585   \n",
       "\n",
       "                  DAYS_ENTRY_PAYMENT_df_avg_install  \\\n",
       "CNT_CHILDREN                               0.016894   \n",
       "AMT_INCOME_TOTAL                           0.008436   \n",
       "AMT_CREDIT                                 0.045590   \n",
       "AMT_ANNUITY                                0.034038   \n",
       "AMT_GOODS_PRICE                            0.044182   \n",
       "\n",
       "                  AMT_INSTALMENT_df_avg_install  AMT_PAYMENT_df_avg_install  \n",
       "CNT_CHILDREN                           0.016069                    0.017802  \n",
       "AMT_INCOME_TOTAL                       0.072202                    0.071600  \n",
       "AMT_CREDIT                             0.130859                    0.134209  \n",
       "AMT_ANNUITY                            0.160239                    0.157750  \n",
       "AMT_GOODS_PRICE                        0.133820                    0.137636  \n",
       "\n",
       "[5 rows x 334 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threshold for removing correlated variables\n",
    "threshold = 0.9\n",
    "\n",
    "# Absolute value correlation matrix\n",
    "corr_matrix = top_training_df.corr().abs()\n",
    "corr_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>df_avg_pos_cash_NAME_CONTRACT_STATUS__Completed</th>\n",
       "      <th>df_avg_pos_cash_NAME_CONTRACT_STATUS__Returned to the store</th>\n",
       "      <th>df_avg_pos_cash_NAME_CONTRACT_STATUS__Signed</th>\n",
       "      <th>SK_ID_PREV_df_avg_install</th>\n",
       "      <th>NUM_INSTALMENT_VERSION_df_avg_install</th>\n",
       "      <th>NUM_INSTALMENT_NUMBER_df_avg_install</th>\n",
       "      <th>DAYS_INSTALMENT_df_avg_install</th>\n",
       "      <th>DAYS_ENTRY_PAYMENT_df_avg_install</th>\n",
       "      <th>AMT_INSTALMENT_df_avg_install</th>\n",
       "      <th>AMT_PAYMENT_df_avg_install</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012882</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.021377</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.025573</td>\n",
       "      <td>0.330938</td>\n",
       "      <td>0.239818</td>\n",
       "      <td>0.183395</td>\n",
       "      <td>0.028019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032172</td>\n",
       "      <td>0.007098</td>\n",
       "      <td>0.018951</td>\n",
       "      <td>0.027959</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.018372</td>\n",
       "      <td>0.016923</td>\n",
       "      <td>0.016894</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.017802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156870</td>\n",
       "      <td>0.191657</td>\n",
       "      <td>0.159632</td>\n",
       "      <td>0.074796</td>\n",
       "      <td>0.027261</td>\n",
       "      <td>0.064223</td>\n",
       "      <td>0.027805</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.018304</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.008114</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>0.072202</td>\n",
       "      <td>0.071600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.770127</td>\n",
       "      <td>0.986734</td>\n",
       "      <td>0.099738</td>\n",
       "      <td>0.055436</td>\n",
       "      <td>0.066838</td>\n",
       "      <td>0.009621</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015925</td>\n",
       "      <td>0.008273</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>0.043097</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.053916</td>\n",
       "      <td>0.046025</td>\n",
       "      <td>0.045590</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.134209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774837</td>\n",
       "      <td>0.118418</td>\n",
       "      <td>0.009443</td>\n",
       "      <td>0.104329</td>\n",
       "      <td>0.038514</td>\n",
       "      <td>0.011267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042013</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.012460</td>\n",
       "      <td>0.022048</td>\n",
       "      <td>0.009907</td>\n",
       "      <td>0.036663</td>\n",
       "      <td>0.034275</td>\n",
       "      <td>0.034038</td>\n",
       "      <td>0.160239</td>\n",
       "      <td>0.157750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103519</td>\n",
       "      <td>0.053510</td>\n",
       "      <td>0.064767</td>\n",
       "      <td>0.011546</td>\n",
       "      <td>0.009289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016597</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>0.019433</td>\n",
       "      <td>0.036975</td>\n",
       "      <td>0.020915</td>\n",
       "      <td>0.046563</td>\n",
       "      <td>0.044585</td>\n",
       "      <td>0.044182</td>\n",
       "      <td>0.133820</td>\n",
       "      <td>0.137636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "CNT_CHILDREN               NaN          0.012882    0.002145     0.021377   \n",
       "AMT_INCOME_TOTAL           NaN               NaN    0.156870     0.191657   \n",
       "AMT_CREDIT                 NaN               NaN         NaN     0.770127   \n",
       "AMT_ANNUITY                NaN               NaN         NaN          NaN   \n",
       "AMT_GOODS_PRICE            NaN               NaN         NaN          NaN   \n",
       "\n",
       "                  AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "CNT_CHILDREN             0.001856                    0.025573    0.330938   \n",
       "AMT_INCOME_TOTAL         0.159632                    0.074796    0.027261   \n",
       "AMT_CREDIT               0.986734                    0.099738    0.055436   \n",
       "AMT_ANNUITY              0.774837                    0.118418    0.009443   \n",
       "AMT_GOODS_PRICE               NaN                    0.103519    0.053510   \n",
       "\n",
       "                  DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  \\\n",
       "CNT_CHILDREN           0.239818           0.183395         0.028019   \n",
       "AMT_INCOME_TOTAL       0.064223           0.027805         0.008506   \n",
       "AMT_CREDIT             0.066838           0.009621         0.006575   \n",
       "AMT_ANNUITY            0.104329           0.038514         0.011267   \n",
       "AMT_GOODS_PRICE        0.064767           0.011546         0.009289   \n",
       "\n",
       "                             ...              \\\n",
       "CNT_CHILDREN                 ...               \n",
       "AMT_INCOME_TOTAL             ...               \n",
       "AMT_CREDIT                   ...               \n",
       "AMT_ANNUITY                  ...               \n",
       "AMT_GOODS_PRICE              ...               \n",
       "\n",
       "                  df_avg_pos_cash_NAME_CONTRACT_STATUS__Completed  \\\n",
       "CNT_CHILDREN                                             0.032172   \n",
       "AMT_INCOME_TOTAL                                         0.001148   \n",
       "AMT_CREDIT                                               0.015925   \n",
       "AMT_ANNUITY                                              0.042013   \n",
       "AMT_GOODS_PRICE                                          0.016597   \n",
       "\n",
       "                  df_avg_pos_cash_NAME_CONTRACT_STATUS__Returned to the store  \\\n",
       "CNT_CHILDREN                                               0.007098             \n",
       "AMT_INCOME_TOTAL                                           0.001847             \n",
       "AMT_CREDIT                                                 0.008273             \n",
       "AMT_ANNUITY                                                0.003109             \n",
       "AMT_GOODS_PRICE                                            0.008120             \n",
       "\n",
       "                  df_avg_pos_cash_NAME_CONTRACT_STATUS__Signed  \\\n",
       "CNT_CHILDREN                                          0.018951   \n",
       "AMT_INCOME_TOTAL                                      0.003613   \n",
       "AMT_CREDIT                                            0.019757   \n",
       "AMT_ANNUITY                                           0.012460   \n",
       "AMT_GOODS_PRICE                                       0.019433   \n",
       "\n",
       "                  SK_ID_PREV_df_avg_install  \\\n",
       "CNT_CHILDREN                       0.027959   \n",
       "AMT_INCOME_TOTAL                   0.018304   \n",
       "AMT_CREDIT                         0.043097   \n",
       "AMT_ANNUITY                        0.022048   \n",
       "AMT_GOODS_PRICE                    0.036975   \n",
       "\n",
       "                  NUM_INSTALMENT_VERSION_df_avg_install  \\\n",
       "CNT_CHILDREN                                   0.000395   \n",
       "AMT_INCOME_TOTAL                               0.006702   \n",
       "AMT_CREDIT                                     0.025003   \n",
       "AMT_ANNUITY                                    0.009907   \n",
       "AMT_GOODS_PRICE                                0.020915   \n",
       "\n",
       "                  NUM_INSTALMENT_NUMBER_df_avg_install  \\\n",
       "CNT_CHILDREN                                  0.018372   \n",
       "AMT_INCOME_TOTAL                              0.015066   \n",
       "AMT_CREDIT                                    0.053916   \n",
       "AMT_ANNUITY                                   0.036663   \n",
       "AMT_GOODS_PRICE                               0.046563   \n",
       "\n",
       "                  DAYS_INSTALMENT_df_avg_install  \\\n",
       "CNT_CHILDREN                            0.016923   \n",
       "AMT_INCOME_TOTAL                        0.008114   \n",
       "AMT_CREDIT                              0.046025   \n",
       "AMT_ANNUITY                             0.034275   \n",
       "AMT_GOODS_PRICE                         0.044585   \n",
       "\n",
       "                  DAYS_ENTRY_PAYMENT_df_avg_install  \\\n",
       "CNT_CHILDREN                               0.016894   \n",
       "AMT_INCOME_TOTAL                           0.008436   \n",
       "AMT_CREDIT                                 0.045590   \n",
       "AMT_ANNUITY                                0.034038   \n",
       "AMT_GOODS_PRICE                            0.044182   \n",
       "\n",
       "                  AMT_INSTALMENT_df_avg_install  AMT_PAYMENT_df_avg_install  \n",
       "CNT_CHILDREN                           0.016069                    0.017802  \n",
       "AMT_INCOME_TOTAL                       0.072202                    0.071600  \n",
       "AMT_CREDIT                             0.130859                    0.134209  \n",
       "AMT_ANNUITY                            0.160239                    0.157750  \n",
       "AMT_GOODS_PRICE                        0.133820                    0.137636  \n",
       "\n",
       "[5 rows x 334 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upper triangle of correlations\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "upper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 67 columns to remove.\n"
     ]
    }
   ],
   "source": [
    "# Select columns with correlations above threshold\n",
    "corr_columns = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "print('There are %d columns to remove.' % (len(corr_columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMT_GOODS_PRICE',\n",
       " 'FLAG_EMP_PHONE',\n",
       " 'REGION_RATING_CLIENT_W_CITY',\n",
       " 'APARTMENTS_MODE',\n",
       " 'BASEMENTAREA_MODE',\n",
       " 'YEARS_BEGINEXPLUATATION_MODE',\n",
       " 'YEARS_BUILD_MODE',\n",
       " 'COMMONAREA_MODE',\n",
       " 'ELEVATORS_MODE',\n",
       " 'ENTRANCES_MODE',\n",
       " 'FLOORSMAX_MODE',\n",
       " 'FLOORSMIN_MODE',\n",
       " 'LANDAREA_MODE',\n",
       " 'LIVINGAPARTMENTS_MODE',\n",
       " 'LIVINGAREA_MODE',\n",
       " 'NONLIVINGAPARTMENTS_MODE',\n",
       " 'NONLIVINGAREA_MODE',\n",
       " 'APARTMENTS_MEDI',\n",
       " 'BASEMENTAREA_MEDI',\n",
       " 'YEARS_BEGINEXPLUATATION_MEDI',\n",
       " 'YEARS_BUILD_MEDI',\n",
       " 'COMMONAREA_MEDI',\n",
       " 'ELEVATORS_MEDI',\n",
       " 'ENTRANCES_MEDI',\n",
       " 'FLOORSMAX_MEDI',\n",
       " 'FLOORSMIN_MEDI',\n",
       " 'LANDAREA_MEDI',\n",
       " 'LIVINGAPARTMENTS_MEDI',\n",
       " 'LIVINGAREA_MEDI',\n",
       " 'NONLIVINGAPARTMENTS_MEDI',\n",
       " 'NONLIVINGAREA_MEDI',\n",
       " 'TOTALAREA_MODE',\n",
       " 'OBS_60_CNT_SOCIAL_CIRCLE',\n",
       " 'NAME_CONTRACT_TYPE_Revolving loans',\n",
       " 'CODE_GENDER_M',\n",
       " 'FLAG_OWN_CAR_Y',\n",
       " 'FLAG_OWN_REALTY_Y',\n",
       " 'NAME_INCOME_TYPE_Pensioner',\n",
       " 'ORGANIZATION_TYPE_XNA',\n",
       " 'HOUSETYPE_MODE_block of flats',\n",
       " 'WALLSMATERIAL_MODE_Unspecified',\n",
       " 'EMERGENCYSTATE_MODE_No',\n",
       " 'EMERGENCYSTATE_MODE_Unspecified',\n",
       " 'df_avg_previous_app_AMT_CREDIT',\n",
       " 'df_avg_previous_app_AMT_GOODS_PRICE',\n",
       " 'df_avg_previous_app_RATE_INTEREST_PRIMARY',\n",
       " 'df_avg_previous_app_RATE_INTEREST_PRIVILEGED',\n",
       " 'df_avg_previous_app_DAYS_TERMINATION',\n",
       " 'df_avg_previous_app_FLAG_LAST_APPL_PER_CONTRACT_Y',\n",
       " 'df_avg_previous_app_NAME_CASH_LOAN_PURPOSE_XNA',\n",
       " 'df_avg_previous_app_CODE_REJECT_REASON_CLIENT',\n",
       " 'df_avg_previous_app_NAME_PORTFOLIO_Cards',\n",
       " 'df_avg_previous_app_NAME_PORTFOLIO_POS',\n",
       " 'df_avg_previous_app_NAME_SELLER_INDUSTRY_Clothing',\n",
       " 'df_avg_previous_app_NAME_SELLER_INDUSTRY_XNA',\n",
       " 'df_avg_credit_card_MONTHS_BALANCE',\n",
       " 'df_avg_credit_card_AMT_INST_MIN_REGULARITY',\n",
       " 'df_avg_credit_card_AMT_PAYMENT_CURRENT',\n",
       " 'df_avg_credit_card_AMT_PAYMENT_TOTAL_CURRENT',\n",
       " 'df_avg_credit_card_AMT_RECEIVABLE_PRINCIPAL',\n",
       " 'df_avg_credit_card_AMT_RECIVABLE',\n",
       " 'df_avg_credit_card_AMT_TOTAL_RECEIVABLE',\n",
       " 'df_avg_credit_card_CNT_DRAWINGS_POS_CURRENT',\n",
       " 'df_avg_pos_cash_CNT_INSTALMENT_FUTURE',\n",
       " 'DAYS_INSTALMENT_df_avg_install',\n",
       " 'DAYS_ENTRY_PAYMENT_df_avg_install',\n",
       " 'AMT_PAYMENT_df_avg_install']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (307511, 267)\n",
      "Testing shape:  (48744, 267)\n"
     ]
    }
   ],
   "source": [
    "top_training_df = top_training_df.drop(columns = corr_columns)\n",
    "top_testing_df = top_testing_df.drop(columns = corr_columns)\n",
    "\n",
    "print('Training shape: ', top_training_df.shape)\n",
    "print('Testing shape: ', top_testing_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] n_estimators=20 .................................................\n",
      "[CV] ........ n_estimators=20, score=0.6765903326276645, total=  32.2s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   34.6s remaining:    0.0s\n",
      "[CV] n_estimators=20 .................................................\n",
      "[CV] ........ n_estimators=20, score=0.6715615422850272, total=  32.4s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] n_estimators=20 .................................................\n",
      "[CV] ........ n_estimators=20, score=0.6786658849070462, total=  32.5s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.7min remaining:    0.0s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ........ n_estimators=250, score=0.735539944326028, total= 6.5min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.6min remaining:    0.0s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....... n_estimators=250, score=0.7317545868121816, total= 6.5min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 15.4min remaining:    0.0s\n",
      "[CV] n_estimators=250 ................................................\n",
      "[CV] ....... n_estimators=250, score=0.7342893479298845, total= 6.5min\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 22.3min remaining:    0.0s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ........ n_estimators=300, score=0.737683600333558, total= 7.8min\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 30.6min remaining:    0.0s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ....... n_estimators=300, score=0.7329646593746884, total= 7.8min\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 38.8min remaining:    0.0s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ....... n_estimators=300, score=0.7359320851513081, total=26.1min\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 65.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 65.3min finished\n",
      "0.675605909989163 {'n_estimators': 20}\n",
      "0.7338612916306995 {'n_estimators': 250}\n",
      "0.7355267803018384 {'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Run GridSearch cross validation with Random Forest\n",
    "\n",
    "final_rf = RandomForestClassifier(random_state=123)\n",
    "\n",
    "# Random forest (similar to before with 250 + a bit bigger 300) \n",
    "param_grid = {'n_estimators': [20, 250, 300]}\n",
    "\n",
    "# CV = 3 to cut short computational time\n",
    "grid_search_final_rf = GridSearchCV(estimator=final_rf, param_grid=param_grid , cv=3, scoring='roc_auc', verbose=100)\n",
    "\n",
    "grid_search_final_rf.fit(top_training_df, y_train)\n",
    "\n",
    "# Results of the grid search in general\n",
    "cvres = grid_search_final_rf.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7355215039409143\n"
     ]
    }
   ],
   "source": [
    "# Find BEST model\n",
    "\n",
    "forest_final_clf = grid_search_final_rf.best_estimator_\n",
    "y_probas_final_forest = cross_val_predict(forest_final_clf, top_training_df, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_final_forest = y_probas_final_forest[:, 1] \n",
    "fpr_final_forest, tpr_final_forest, thresholds_final_forest = roc_curve(y_train, y_scores_final_forest)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_final_forest, tpr_final_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = forest_final_clf.predict_proba(top_testing_df)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('random_forest_final_importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a10c2aa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plot_roc_curve(fpr_merge_forest, tpr_merge_forest, \"Training (top 30) n = 250\")\n",
    "plot_roc_curve(fpr_poly_forest, tpr_poly_forest, \"Training w/ Poly-2 (top 15) n = 300\")\n",
    "plot_roc_curve(fpr_final_forest, tpr_final_forest, \"Training w/out correlated (top 300+) n = 300\")\n",
    "plt.legend(loc=\"lower right\", fontsize=16)\n",
    "plt.title(\"Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Scores\n",
    "1. Top 30 only RF : 0.710\n",
    "2. Top 15 with poly-2 RF : 0.697\n",
    "3. Top 20 with poly-2 RF : 0.693\n",
    "4. Top 20 with poly-3 RF : --- DID NOT SUBMIT ---\n",
    "5. Top 300+ with drop correlation RF : 0.718 **\n",
    "6. Top 15 with poly-2 LOG (late add-on): 0.725 **\n",
    "\n",
    "** Try final engineered dataset on "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate models\n",
    "Using 5 as the base, try this subset with other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_training_df.to_csv('training_top.csv', index = False)\n",
    "top_testing_df.to_csv('testing_top.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV] n_neighbors=277 .................................................\n",
      "[CV] ........ n_neighbors=277, score=0.6253542253826272, total=19.8min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 46.2min remaining:    0.0s\n",
      "[CV] n_neighbors=277 .................................................\n",
      "[CV] ....... n_neighbors=277, score=0.6241971530486236, total=179.7min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 243.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 243.2min finished\n",
      "{'n_neighbors': 277}\n",
      "------------\n",
      "0.6247756910969765 {'n_neighbors': 277}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# General rule of thumb in choosing the value of k is k = sqrt(N)/2, N = size of training set\n",
    "model_knn = Lo()\n",
    "param_grid = {'n_neighbors': [277]}\n",
    "\n",
    "grid_search_knn = GridSearchCV(estimator=model_knn, param_grid=param_grid , cv=2, scoring='roc_auc', verbose=100)\n",
    "grid_search_knn.fit(top_training_df, y_train)\n",
    "    \n",
    "# Results of the grid search for best n_estimator\n",
    "print(grid_search_knn.best_params_)\n",
    "print (\"------------\")\n",
    "\n",
    "# Results of the grid search in general\n",
    "cvres = grid_search_knn.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "(as opposed to Linear SVC)\n",
    "\n",
    "#### On top 300+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] .... C=0.001, penalty=l1, score=0.6999272948184115, total=  10.5s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.9s remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] .... C=0.001, penalty=l1, score=0.6995874837154289, total=   9.9s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   21.3s remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] .... C=0.001, penalty=l1, score=0.7034268721736452, total=  10.5s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   32.4s remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] .... C=0.001, penalty=l2, score=0.6063904586239879, total=  42.6s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] .... C=0.001, penalty=l2, score=0.6344807198020097, total= 1.1min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.4min remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] .... C=0.001, penalty=l2, score=0.6098751078408904, total=  42.3s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  3.1min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l1, score=0.7569399571956201, total=  18.5s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  3.4min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l1, score=0.7529192079756589, total=  18.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  3.8min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l1, score=0.7600287327760769, total=  22.9s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  4.1min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l2, score=0.6201259148864666, total=  46.1s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  4.9min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l2, score=0.6294953167219833, total=  54.1s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:  5.8min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l2, score=0.6166550426573484, total=  46.5s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  6.6min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l1, score=0.7615277764374179, total= 1.1min\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:  7.7min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l1, score=0.7579644395912908, total= 1.4min\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  9.1min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l1, score=0.7648311423586962, total= 1.5min\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 10.6min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l2, score=0.6160458154924306, total=  46.5s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 11.4min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ....... C=0.1, penalty=l2, score=0.637463285992962, total= 1.1min\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed: 12.5min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l2, score=0.6137126186313918, total=  44.1s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 13.3min remaining:    0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ........ C=1, penalty=l1, score=0.7616084194707379, total= 2.2min\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed: 15.5min remaining:    0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ........ C=1, penalty=l1, score=0.7584434141431947, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 17.5min remaining:    0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ........ C=1, penalty=l1, score=0.7647905953381443, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed: 20.0min remaining:    0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ........ C=1, penalty=l2, score=0.6102854872517774, total=  46.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed: 20.8min remaining:    0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ........ C=1, penalty=l2, score=0.6360892893218068, total= 1.2min\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed: 22.0min remaining:    0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ........ C=1, penalty=l2, score=0.6133882322071027, total=  45.1s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 22.8min remaining:    0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ....... C=10, penalty=l1, score=0.7615298014584833, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed: 25.2min remaining:    0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ....... C=10, penalty=l1, score=0.7583512147673668, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed: 27.5min remaining:    0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ....... C=10, penalty=l1, score=0.7646037809942767, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 30.1min remaining:    0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ....... C=10, penalty=l2, score=0.6063518434344511, total=  44.6s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed: 30.9min remaining:    0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ....... C=10, penalty=l2, score=0.6323748248586021, total= 1.1min\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed: 31.9min remaining:    0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ....... C=10, penalty=l2, score=0.6150360653795056, total=  46.8s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 32.7min remaining:    0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ...... C=100, penalty=l1, score=0.7615226221881071, total= 2.7min\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed: 35.4min remaining:    0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ...... C=100, penalty=l1, score=0.7583257243818725, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed: 37.8min remaining:    0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ...... C=100, penalty=l1, score=0.7645760536858146, total= 2.7min\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed: 40.6min remaining:    0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ...... C=100, penalty=l2, score=0.6063030146491165, total=  45.0s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed: 41.3min remaining:    0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ....... C=100, penalty=l2, score=0.643460091551087, total= 1.4min\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed: 42.7min remaining:    0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ...... C=100, penalty=l2, score=0.6135328528207022, total=  45.4s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed: 43.5min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l1 ..............................................\n",
      "[CV] ..... C=1000, penalty=l1, score=0.7615217706276338, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed: 46.0min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l1 ..............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=1000, penalty=l1, score=0.7583222424742141, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed: 48.3min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l1 ..............................................\n",
      "[CV] ..... C=1000, penalty=l1, score=0.7645737234120186, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed: 50.9min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l2 ..............................................\n",
      "[CV] ..... C=1000, penalty=l2, score=0.6107739161768885, total=  45.9s\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 51.7min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l2 ..............................................\n",
      "[CV] ..... C=1000, penalty=l2, score=0.6408905950307664, total= 1.2min\n",
      "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed: 52.9min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l2 ..............................................\n",
      "[CV] ..... C=1000, penalty=l2, score=0.6173307066346884, total=  47.4s\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed: 53.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed: 53.7min finished\n",
      "0.7009805422805946 {'C': 0.001, 'penalty': 'l1'}\n",
      "0.6169154516501629 {'C': 0.001, 'penalty': 'l2'}\n",
      "0.7566292882611125 {'C': 0.01, 'penalty': 'l1'}\n",
      "0.6220921091027597 {'C': 0.01, 'penalty': 'l2'}\n",
      "0.761441108438398 {'C': 0.1, 'penalty': 'l1'}\n",
      "0.6224072683131082 {'C': 0.1, 'penalty': 'l2'}\n",
      "0.7616141326544688 {'C': 1, 'penalty': 'l1'}\n",
      "0.6199210241709185 {'C': 1, 'penalty': 'l2'}\n",
      "0.7614949222969939 {'C': 10, 'penalty': 'l1'}\n",
      "0.6179209206054631 {'C': 10, 'penalty': 'l2'}\n",
      "0.7614747900002479 {'C': 100, 'penalty': 'l1'}\n",
      "0.6210986776103167 {'C': 100, 'penalty': 'l2'}\n",
      "0.7614725687532933 {'C': 1000, 'penalty': 'l1'}\n",
      "0.6229984243783309 {'C': 1000, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "log_rf = LogisticRegression(random_state=123)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],'penalty': ['l1', 'l2']}\n",
    "\n",
    "# CV = 3 to cut short computational time\n",
    "grid_search_log_rf = GridSearchCV(estimator=log_rf, param_grid=param_grid , cv=3, scoring='roc_auc', verbose=100)\n",
    "\n",
    "grid_search_log_rf.fit(top_training_df, y_train)\n",
    "\n",
    "# Results of the grid search in general\n",
    "cvres = grid_search_log_rf.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7615959320002902\n"
     ]
    }
   ],
   "source": [
    "# Find BEST model\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "log_final_clf = grid_search_log_rf.best_estimator_\n",
    "y_probas_log_final = cross_val_predict(log_final_clf, top_training_df, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_log_final = y_probas_log_final[:, 1] \n",
    "fpr_log_final, tpr_log_final, thresholds_log_final = roc_curve(y_train, y_scores_log_final)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_log_final, tpr_log_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = log_final_clf.predict_proba(top_testing_df)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('log_final_importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAGICAYAAACgFIL5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xd4VNXWx/HvSgdSaYFAQuhIkQARQQUVlIsoxQYBG0pRuKCIBSt6LSiiqFyRJr42VBBp0uyNTui9t1DSIYGQOvv9YwZuBBIGyORMkvV5Hp47c86ZmR+5mDW7nL3FGINSSimlygYPqwMopZRSqvho4VdKKaXKEC38SimlVBmihV8ppZQqQ7TwK6WUUmWIFn6llFKqDNHCr5QqkIjcJyI/WZ3DWSISKSJGRLycuLaviCwpjlxKuRMt/EoVAxHpIyKxInJSRI6KyCIRucHqXBdjjJlmjOnkivcWkf0iki0ilc85vt5RvCNd8blKlXVa+JVyMREZDnwAjAJCgQjgY6C7lbkuxplWcxHYB/TO95nNgHLF8LlKlVla+JVyIREJAl4D/m2MmWWMOWWMyTHG/GCMecZxja+IfCAiRxx/PhARX8e5m0QkTkSeFZEER29BDxHpIiI7RSRFRF7I93mvishMEZkuIukislZEmuc7/5yI7HGc2yoid+Y711dElorI+yKSArx6bne4oyX+mIjsEpFUERkvIuI45yki74lIkojsE5EhTnS7fwk8mO/5Q8AX5/4MReQLEUkUkQMi8pKIeOT7zHcdn7kXuP0Cr53q+LkdFpE3RMTzAv8/iePvnSAiJ0Rko4g0LSS3UiWWFn6lXKst4AfMLuSaF4E2QBTQHGgNvJTvfDXHe9QARgJTgPuBVkA7YKSI1Ml3fXfgO6Ai8DUwR0S8Hef2OF4TBPwH+EpEqud77bXAXqAq8GYBee8ArnFk7Qn8y3F8AHCb4+/REuhRyN/5jBVAoIhc5SjIvYCvzrnmv468dYAbsX9ReDjfZ94BtACigXvOee3nQC5Qz3FNJ6D/BXJ0AtoDDYBgR45kJ/IrVeJo4VfKtSoBScaY3EKuuQ94zRiTYIxJxF6QH8h3Pgd40xiTA3wLVAY+NMakG2O2AFuAq/Ndv8YYM9Nx/VjsXxraABhjvjPGHDHG2Iwx04Fd2L9onHHEGPNfY0yuMeZ0AXnfNsYcN8YcBH7HXujB/iXgQ2NMnDEmFXj7Ij+bM860+m8FtgOHz5zI92Xgecffdz/wXr6fT0/gA2PMIWNMCvBWvteGYv8iMszR05IAvA/EXCBDDhAANALEGLPNGHPUyfxKlSjFMYanVFmWDFQWEa9Cin8YcCDf8wOOY2ffwxiT53h8phjH5zt/GvDP9/zQmQfGGJuIxJ15PxF5EBgORDou8cf+ReK81xbiWL7HGfk+O+yc1zvzXmAv/H8BtTmnm9+RzYfzfz41CvjM/NfVAryBo47RCLA3ds7LZYz5TUQ+AsYDESIyG3jaGJPm5N9BqRJDW/xKudZyIJPCu72PYC9SZ0Q4jl2u8DMPHGPhNYEjIlIL+zDBEKCSMSYY2AxIvtdeyXadRx2fdV6OwhhjDmCf5NcFmHXO6STsrfFzfz5negWOnvM5EfkeHwKygMrGmGDHn0BjTJMCcowzxrQCmmDv8n/GmfxKlTRa+JVyIWPMCezj8uMdk/LKi4i3iNwmIu84LvsGeElEqjhubRvJ+ePcl6KViNzlmFQ3DHvxWwFUwF7YEwFE5GGgKCewzQCeEJEaIhIMjLiE1/YDOhhjTuU/6OjpmAG8KSIBji8vw/nfz2cG8LiI1BSREOC5fK89CvwEvCcigSLiISJ1ReTGcz9cRK4RkWsdcyFOYf+ylnfudUqVBlr4lXIxY8xY7MXqJexF9xD2VvccxyVvALHARmATsNZx7HLNxT4unop9LPwux50EW7GPjy/HPlTQDFh6BZ9zrinYC+1GYB2wEPvEuosWUGPMHmNMbAGnh2IvxnuBJdgnLH6a7zN/BDZg/7md22PwIPahgq3Yfx4zgeqcL9DxXqnYhwuSgXcvllupkkiMuZKePaWUOxGRV4F6xpj73SDLbcBEY0yti16slCo22uJXShUJESnnWF/AS0RqAK9Q+G2MSikLFGvhF5FPHQtkbC7gvIjIOBHZ7VhAo2Vx5lNKXRHBfitiKvau/m3Y5ysopdxIsXb1i0h74CTwhTHmvElFItIF+3heF+wLiXxojLm22AIqpZRSpVyxtviNMX8BKYVc0h37lwJjjFkBBJ+zqphSSimlroC7jfHX4J+La8Txv4U6lFJKKXWF3G3lPrnAsQuORYjIQGAgQIUKFVo1atTIlbmUUkoppxkD2Xk2snNtZOfZyM2zkWczZOXa/9cAmTnOLxXhIYItJ4uc48cwudlgXwq8yuVkc7fCH8c/V+GqSQErmBljJgOTAaKjo01sbEG3ACullFJFw2YzpGZkczAlgy1H0tiXdIo9iSeJSz2Npwg74tMJ8PMiPfOfK3R7Ov74FPC+Pp4eVAnwpeNVValbxZ9K/j4E+HnTqFoAIeV92LRhHe3btycoJIjPP/+cLl26HCjgrS7K3Qr/PGCIiHyLfXLfCd0oQymlVHHKys0jLvU0W4+ksfnICdIzc9mTcJJdCSdJOZV90defKfqhgb4E+HnTMiKY0EA/gsp5E1LeB19vD0ID/age5EeVAF98vc7bKfosYwwiQvPmzRk8eDDDhw+nevUrm/pWrIVfRL4BbsK+aUkc9vt8vQGMMROxr/TVBdiNffOPhy/8TkoppdTly7MZDiSf4pCjwP+1M5GcPBt7Ek+SmpFz0dc3qhZAzZDy+Hl7UNnfl/CK5alX1Z8aweUIKe9NcHkfPD0uNHrtvJUrVzJ8+HBmz55N1apVGTNmzBW93xnFWviNMb0vct4A/y6mOEoppUopYwyHUk6z7Vgah1IyiEs9zdqDqZzMymVv4ilE7OPwF+IhUC3Qj9pVKlCrUgWCynkTXSuEelX9CQ30w8+74BZ6UbDZbLzzzju8/PLL1KhRg2PHjlG1atUie3936+pXSimlnGKMITE9i61H0/hxyzFOZuURn5bJ8YxsjhzP5GRWQTth24t+aKAvERXL4+XhQcerqlIzpBxX1wymepAf+bZyLlbHjh3jgQce4JdffuHee+9l8uTJBAcHF+lnaOFXSinl1vJshvi0TA6lZPDT1ngS07NIzcjm711Jhb4upLw34RXLUzXAl9a1K1I9qBxVAnypGVKOyv6+Lm+5X47nnnuOpUuXMnnyZPr37++SLyClYpMendWvlFIlW3pmDgeS7V3y6w6lknoqm2V7ksnKtZGYnlXoaxuE+tOufhUq+/vSrEYQweW9qR7kR8UKPpa13C9FdnY2x48fp2rVqiQlJZGQkEDjxo0LfY2IrDHGRF/O52mLXymlVLGx2Qz7kk+x41g6s9bGsenwCbw9PTh8/HSBY+4AgX5eZOXa6B4VRnkfLxpXD6RFRDD1QwOKL7wL7Nmzh969e+Pp6cnSpUupXLkylStXdulnauFXSilV5FJPZbPtWBp7Ek+xP+kUCelZHEw+xYa4EwW+pkGoP9WDylEzpBxB5by5JrIi4RXLUyO4HOV83K9b/kp9/fXXPPbYY3h6evLJJ5/g4VE8i+lq4VdKKXVF0jJz+GNHIvuTTvHXzkRiD6Re9DUh5b2JaR1BpQo+RIUH07RGkFuOubvCqVOnGDJkCJ999hnXX38906ZNo1atWsX2+Vr4lVJKOe1kVi6x+1NYujuJzYfTWHMglew82wWvbVw9kIbVAqhbpQLVg8pRI6Qc9av6U8nft5hTuxdjDCtXruTll19m5MiReHkVbynWwq+UUuqCTmXlsu1oGgeSM9gRn86muBMFFvqQ8t60b1CFq6oH0jIihKjwYHy83G0fOOsYY/jss8/o1asX/v7+rF27Fj8/P0uyaOFXSilFQlomaw8eZ8uRExw+fpofNx/jVPb5m8iIQLMaQVxbuyLX1qlEZKXyhFcsX2a66S9HUlISjzzyCD/88AMZGRn8+9//tqzogxZ+pZQqc05n57FiXzLLdieRdDKbeRuOkGe78JR6Xy8PalUqT+em1WlULYDoyBCqBlhXtEqaP/74g/vuu4+kpCQ+/PBDBg8ebHUkLfxKKVWa5dkMO+PT2XT4BFuPpLFqXwo749PJvUChr1OlAq0jK1I1wJc2dSrRslaItuSvwNSpUxkwYAD169dn/vz5tGjRwupIgBZ+pZQqNWw2w474dHYcS2dP4knWHTzO2oOpZFygy75haAB+3h40qRHEva1q0rRGEN6eOiZflG688UYGDhzIu+++i7+/v9VxztLCr5RSJdSR46dZtieZXQnprD94nK1H087bBx7sG840Dw+iaVgQURHBRIUHE+DnbUHi0m/27NksWLCAKVOmUK9ePSZOnGh1pPNo4VdKqRIiPTOHGbFxbD+axpqDqexNPHXeNTWCy9EkLJD6of40CA2gbd1KOiZfDE6fPs1TTz3FhAkTiI6O5sSJE0W+uU5R0cKvlFJuKifPxvaj6fy89RhL9ySzKe7EP26l8/QQWoQHExroR/eoMJrWCCIsuJyFicumrVu3EhMTw6ZNm3jqqacYNWoUPj4+VscqkBZ+pZRyE9m5NpbvTWbz4ROs2pfCir32TWryaxkRzNU1g+naPIyra+q4vNVycnK4/fbbOXXqFAsXLuS2226zOtJFaeFXSikLJaRn8vPWeKb+vY9DqRnk5P1ztn31ID/a1q1Ep8ahXBNZscyveucu0tLSqFChAt7e3nz99ddERkZSvXp1q2M5RQu/UkoVk+xcG2sOpDJ3/WG2H0vnVFYuuxNP/mNXukoVfKgf6k/P6HCuq1uZakE6Pu9uVqxYQe/evenXrx8vvfQSbdu2tTrSJdHCr5RSLmKMYX9yBsv2JPHbtgSW7kkiM+efXfc+nh5cV68StzYO5dralahbpUKJ2EO+LLLZbLzzzju89NJLhIeHc8stt1gd6bJo4VdKqSJ07EQm36+NY3fCSWavO3ze+bpVKnBDvcpUDfSjec1gWtUKKZVbzpY2R48e5YEHHuDXX3+lZ8+eTJo0yW1n7V+MFn6llLoCxhgOpZzmz50JLNh0lFX7Ujh3Ubz2Dapw61VV6XhVqM66L6EOHDjA6tWrmTJlCv369SvRvTJa+JVS6hLl5Nn4LjaO33cksO7gcZJOZp095yHQrn5lGoYG0C0qjKZhQXh4lNwiUZZlZ2ezaNEiunfvTps2bThw4ECJbeXnp4VfKaUuIjMnj53x6fy9K4mFm46y5UjaP84H+HrRslYItzerTqcmoQSXd997uJVzdu/eTe/evYmNjWXjxo00a9asVBR90MKvlFLnObOxTeyBVH7cfIyV+5LPu83OQ+COq8PoHhVGh0ZVS3TXr/qnadOm8dhjj+Ht7c2sWbNo1qyZ1ZGKlBZ+pZQCTmTk8NuOeP7elcSstedPyqsRXI5ra1ekfYMqtK5dUcfqS6l///vffPzxx9xwww1MmzaNiIgIqyMVOS38SqkyyxjD0t3JjP15B5sPp/1jOVyAfzUJ5Yb6VejUOJTQQL2fvixo2bIlI0eO5OWXX8bLq3SWyNL5t1JKqUKknMrm29UH+WHDUbYd/d94fWSl8vRuHcGNDavQMDRAu+/LAGMM48aNo1KlStx///3069fP6kgup4VfKVUmxKVmsGjTMSb9tYfkU9lnV8sLKudN3+siuatlDWpVqmBtSFWskpKSePjhh5k/fz69e/fm/vvvtzpSsdDCr5QqtY6eOM2CjUeZve7weTPxG1ULYEiHetxyVSh+3rqATlnzxx9/cN9995GUlMS4ceMYMmSI1ZGKjRZ+pVSpsuZACv/9bTc7j6Vz5ETm2ePlvD25oX5lujUP48aGVQj087YwpbLS9u3b6dixI/Xr12fBggVERUVZHalYaeFXSpVoeTZD7P4UFm0+xsJNR0lIz/rH+Y6NqtItKox/NammLfsy7vTp05QrV45GjRrx+eef06NHD/z9/a2OVey08CulSqS41AwWbjrK58sOcPj46bPHQ8p70z2qBrc1rUbz8GAt9gqAWbNmMXjwYBYsWECrVq3KzHj+hWjhV0qVCDabYUPccX7eGs/izcfYm3Tq7LmqAb50ahLKHVeH0Tqyoi6Rq846ffo0Tz31FBMmTCA6OrrUrL53JbTwK6XcWvLJLCb/tZcZsYdIzcg5e9zHy4M6lSvw6I116Na8Bp5a7NU5tmzZQkxMDJs3b+bpp5/mzTffxMdHl1PWwq+Uckt7E0/y9cqDfLHiANm59oV1QgN9ubVxKDc2qEqbOhUJ0Al6qhDfffcd8fHxLFq0iM6dO1sdx22IMebiV7m56OhoExsba3UMpdQVOpSSwQe/7GLJ7kTi0/43Sa9tnUo8cUt9rq1dURfVUYU6fvw4+/bto0WLFuTm5pKcnExoaKjVsYqciKwxxkRfzmu1xa+UslROno1Fm4/x7aqDLNuTfPa4l4cQFlyOD2OiaBERYmFCVVIsX76c3r17Y7PZ2L17Nz4+PqWy6F8pLfxKKUvk5tn4dXsCY37cwe6Ek4B9x7ubGlbl2toVeei6SJ2Rr5xis9kYPXo0L7/8MuHh4Xz33Xc6ll8ILfxKqWJ15Phppvy9l3nrj5B8Khuw73zXv11tujUPo5K/r8UJVUmSnp7OXXfdxS+//EKvXr2YNGkSQUFBVsdya1r4lVIuZ4xhye4kvouN44eNR86uk1+rUnlirongoetqUd5Hfx2pS+fv70/FihX55JNPeOSRR3QOiBP0vzSllMukZ+bw1YqDfL827h/d+Z2ahNK/XR2ia4XoL2p1ybKzs3n11VcZOHAgkZGRTJ8+3epIJYoWfqVUkTLGEHsglV+3JfDNqoOcOG2/9z7Qz4uY1hHcd22E7oKnLtvu3buJiYlhzZo1VKtWjccff9zqSCWOFn6lVJHIsxk+W7afaSsO/GNVvUbVAnj0xjrc1rS6TtZTV+Srr75i0KBBeHt7M3v2bHr06GF1pBJJC79S6orEp2Xy1YoDTF996B8b5DzUtha3NA7lhnqVtTtfXbGpU6fSv39/2rVrx7Rp0wgPD7c6UomlhV8pdVm2HDnBF8sOMHvdYbLz7CvrVQv0o+/1kfTVW/FUEcnLy8PT05NevXqRnp7OkCFD8PLS0nUl9KenlHKaMYbfticwffUhftoaf/Z4h0ZVub9NBO3rV8HL08PChKq0MMYwbtw4vvjiC/7++2/8/f0ZNmyY1bFKBS38SqmLys2zsWDTUT75ex+bDp8AwNND6NykGo/cEEmrWhUtTqhKk8TERB5++GEWLFhA165dycrKonz58lbHKjW08CulCpSZk8eEP/YwffUhjqVlAlAlwJdHrq/NnS1qUC3Iz+KEqrT5/fffue+++0hOTmbcuHEMGTJE54gUMS38Sqnz2GyGH7cc482F24hLPQ2ACAztUJ8B7WrrrnjKJYwxPPfccwQGBrJw4UKioqKsjlQqaeFXSp2VmZPH7HWHmfDHHg6mZABQPciP57tcRafGoTphT7nEgQMHCAwMJCQkhO+//56QkBAqVNC1HlxFC79SikMpGcxcE8e0lQdJOmm/Ja9SBR8Gtq/D/W1qUcFXf1Uo1/j+++/p378/Xbt25YsvvqBmzZpWRyr19L9mpcqoPJvh9+0JzN94hHkbjmBzrJ9/VfVA7rs2gl7XhOOtM/SVi5w+fZonn3ySSZMmER0dzSuvvGJ1pDJDC79SZczxjGymrTzIN6sOnh2/9/QQbm9WjZ7R4bSvrwvuKNfatWsXd911F5s3b+bpp5/mzTff1G10i5EWfqXKiD2JJ/ly+QFmxB4iIzsPsC+4c9+1EdzRPIzalXVMVRUPf39/ABYtWkTnzp0tTlP2aOFXqhTLybPx185EZsQe4sct/1twp3VkRR6+PpJbG4fqgjuqWBw/fpyPPvqI559/nurVq7NhwwY8PPTfnhW08CtVCp3OzmP66oN89Pues5P1fDw9uLVxKAPb16F5eLDFCVVZsnz5cnr37s3hw4fp2LEjbdu21aJvoWIv/CLSGfgQ8AQ+Mca8fc75COBzINhxzXPGmIXFnVOpkmh/0ik+W7af2esOn90Ot1IFH+5vU4verSN0wR1VrPLy8hg9ejQjR44kIiKCJUuWcO2111odq8wr1sIvIp7AeOBWIA5YLSLzjDFb8132EjDDGDNBRBoDC4HI4sypVElisxkWbj7Kp0v2sfbg8bPHr64ZxIB2dejctJrOzleWGDBgAP/3f/9HTEwMEydOJCgoyOpIiuJv8bcGdhtj9gKIyLdAdyB/4TdAoONxEHCkWBMqVUJk5eYxY/UhPlu2nz2JpwDw8/bgtqbV6d+uNk3C9JessoYxBhFhwIAB3HDDDTz88MN6p4gbKe7CXwM4lO95HHBuv8+rwE8iMhSoANxSPNGUKhkyc/L4bk0c7/20g+MZ9u780EBfBt1Yl7tb1dTldJVlsrKyeP755wEYO3Ysbdu2pW3bthanUucq7sJ/oa985pznvYHPjDHviUhb4EsRaWqMsf3jjUQGAgMBIiIiXBJWKXczd/1hRs7dcnb8PrJSeR7vWJ87rg7Dx0u785V1du3aRUxMDGvXrmXIkCFnW/3K/RR34Y8DwvM9r8n5Xfn9gM4AxpjlIuIHVAYS8l9kjJkMTAaIjo4+98uDUqWGMYa/diXx5fID/LLNfkteg1B/BrSrw10ta+Lpob9clbW+/PJLBg8ejLe3N7Nnz6ZHjx5WR1KFKO7CvxqoLyK1gcNADNDnnGsOAh2Bz0TkKsAPSCzWlEq5AWMMK/el8Oq8LWw/lg6Al4fwbOeGDGhXR1tTyi3ExcXx6KOPEh0dzbRp0wgPD7/4i5SlirXwG2NyRWQI8CP2W/U+NcZsEZHXgFhjzDzgKWCKiDyJfRigrzFGW/SqTFm2O4kh36wj5VQ2AJX9fXigTST3RNekRnA5i9MpBfv27aN27drUrFmTv/76i6ioKLy8dGmYkkBKQ02Njo42sbGxVsdQ6ooYY1h7MJWPf9/Dr9vtI1venkL3qBq80rWxTtpTbsEYwwcffMCIESP4/PPP6d27t9WRyiQRWWOMib6c1+rXM6XcwK/b4hm9eDs7408C9tvy+l5Xm3/fXFcLvnIbiYmJ9O3bl4ULF9K1a1c6depkdSR1GbTwK2URYwzL9ybzwc+7WLU/BYCKFXy4t1VNHrmhNqGBusqech9//PEHffr0ITk5mXHjxjFkyBCdZ1JCaeFXygI7jqXz0pxNrN6fCoC/rxeDbqpL/3a18fXytDidUudLSUkhMDCQhQsXEhUVZXUcdQV0jF+pYpSZk8dHv+1mwp97yLMZQsp70+uaCB5tX4eQCrofuXIvBw4cYOXKlfTs2ROA7OxsfHz036k70DF+pdycMYaZa+IYtXAbqY7V9ro2D2PkHY2pEuBrcTqlzvf999/Tv39/vLy8uO222wgICNCiX0po4VfKxbYfS+PF2ZtZc8Derd+oWgCvdmtCmzqVLE6m1PlOnz7Nk08+yaRJk2jdujXffPMNAQEBVsdSRUgLv1IuYoxhRuwhRs7dQlaujYoVfHi6U0N6tw7XSVHKLWVlZdGmTRs2btzIs88+y+uvv66t/FJIC79SLrDh0HFGfL/x7Ip7XZpV4627riaonN6ap9yXr68vDz74IM2aNdNb9UoxLfxKFaHkk1n854etzNtg34KiUgUfhnaox0PXRWorX7ml1NRUHnvsMQYOHEjHjh156qmnrI6kXEwLv1JFwBjD4s3HeHHO5rPL7Pa9LpIRnRtRzkdvz1PuadmyZfTu3ZsjR47QoUMHOnbsaHUkVQy08Ct1hQ4mZ/DKvM38vsO+l1Tr2hV5o0dTGoTqhCjlnvLy8hg9ejQjR46kVq1aLF26lNatW1sdSxUTLfxKXSZjDON/3837v+wiz2bw9/Xi8Y716H9DHTx0q1zlxmbNmsWLL75ITEwMEydOJCgoyOpIqhhp4VfqMqScyuaFWZtYvOUYAN2ah/F8l0ZUD9Kd85T7SkxMpEqVKtxzzz0sWrSIf/3rXzr3pAzysDqAUiWJMYZ5G47wrw/+YvGWY5Tz9mTi/a0Y17uFFn3ltrKyshg2bBgNGzbk4MGDiAidO3fWol9GaYtfKSfFp2Xy2vytLNh4FIB6Vf2Z/EAr6lTxtziZUgXbuXMnMTExrFu3jiFDhlC1alWrIymLaeFXygk/b43nqRnrScvMxdfLgxGdG/Fg21p4eWqnmXJfX375JYMGDcLX15c5c+bQvXt3qyMpN6CFX6lCbIo7wX9+2EKsY7nda2tXZNRdzairrXxVAvzyyy+0atWKr776ivDwcKvjKDehhV+pCziRkcPIeZuZu/7I2WO9W4fzRo9meOqMfeXG1qxZg5+fH02aNGHixIl4e3vj5aW/6tX/6L8Gpc7x2/Z4Xpi1mWNpmfh4ehDTOpzBN9WjWpCf1dGUKpDNZuODDz7gueeeo0OHDixevJhy5XTCqTqfFn6lHI6dyGT4jPUs25MMwFXVA3m/V3MaVQu0OJlShUtISODhhx9m4cKFdO/enalTp1odSbkxLfyqzDPG8OWKA4z5cQfpmbmU8/Zk0E11Gdi+Dn7eutyucm/bt2+nQ4cOpKSk8NFHHzF48GC9TU8V6pIKv4g0BNoBlYDPjDHxIhIOJBtjMlwRUClXSkjP5OnvNvLXTvtyu+3qV+a9e5tTNVC79VXJUKdOHW6++WaeffZZmjdvbnUcVQI4VfhFxBv4FOgDCGCAn4F44CNgC/CCizIqVeSMMXy18iBjf9pBakYOAb5evHD7VcRcE66tJeX29u/fz4gRI5g4cSIhISFMmzbN6kiqBHH2JuTXgW7AAKAW9uJ/xkLgX0WcSymXScvMod/nsbw8ZzOpGTm0jAhm4RPt6N06Qou+cnszZ84kKiqKxYsXs3nzZqvjqBLI2a7++4CXjTGfisi5g557gdpFG0sp19hxLJ0hX69lV8JJ/H29eL1HE3pE1dCCr9xeRkYGTz75JJMnT6Z169Z888031KlTx+pYqgRytvBXAQr7aqkDosrtzVl3mJfmbOZkVi7Vg/z4sl9r6lXVrXNVyTAfjsXjAAAgAElEQVR8+HAmT57MiBEjeP311/H29rY6kiqhnC38B4BrgN8ucC4a2FVkiZQqYkeOn+aNBVtZuMm+k17nJtUYfc/VBJXTX5zKvRljOHXqFP7+/rzyyivcfffd3HrrrVbHUiWcs4X/K+BFEdkN/OA4ZkSkLTAcGOWKcEpdCZvN8MmSvbz7006yc234enkw/NYGDGxfR7v2ldtLTU1lwIABpKSk8PPPP1O9enWqV69udSxVCjhb+N8CWgLfAScdx34HAoDZwAdFH02py3c8I5tBX61l+V77YjwdG1Xl1W5NCK9Y3uJkSl3c0qVL6dOnD0eOHGHUqFH6RVUVKacKvzEmF7hTRG7FPoO/KpAMLDbG/OjCfEpdsqSTWdw3ZSU74tMJLu/Nmz2acfvV2lJS7i8vL4+33nqLV199lVq1arF06VJat25tdSxVyjh7H39V7Iv0/Iz9/v385zyAysaYBBfkU+qSLN+TzJPT13MsLZPQQF++HtBGd9JTJcbJkyf55JNP6NmzJxMnTiQwUJeLVkXP2a7+o0BbYNUFzrVwHNe1TZVl8myGMT/uYOKfewC4umYQnzwYrSvwqRLht99+4/rrrycoKIhVq1ZRpUoV7d5XLuPsAj6F/Qv0AmxFkEWpy5JyKpv7P1l5tujfd20E3w+6Tou+cntZWVkMGzaMjh078uGHHwJQtWpVLfrKpQps8YuIP5C/n6myiISdc1k57Mv4xrsgm1IXdSglgwc/XcW+pFME+HoxtlcUtzYOtTqWUhe1c+dOYmJiWLduHUOHDuXxxx+3OpIqIwrr6n8KGOl4bPjfbXznEuDNogyllDOW7Epi2PT1JJ3MIrJSeb7qfy01Q3TWvnJ/c+fO5b777sPX15e5c+fSrVs3qyOpMqSwwj8fOIa9sH8MvAPsO+eaLGCrMeZCY/9KuUROno3X52/li+UHALgmMoRJD0RTsYKPxcmUck69evVo164dU6ZMoWbNmlbHUWVMgYXfGLMGWAMgIgb43hiTVFzBlLqQI8dPM+zb9azan4KnhzDk5noM6VAPb09np6soZY01a9Ywe/Zs3njjDZo0acKiRYusjqTKKKd+WxpjJmnRV1ZbuTeZeycuZ9X+FILLezN9YBuevLWBFn3l1mw2G2PHjqVt27Z8/vnnJCYmWh1JlXHO3s6HiDQAHgYacv6mPMYYc3tRBlPqjKzcPF6avZnv1sQB0Dw8mCkPtNJZ+8rtJSQk0LdvXxYtWkSPHj2YOnUqFStWtDqWKuOcXcCnFfA39tn7EcAOoCL2FfyOAAddFVCVbSezchny9Vr+2GFvJf375ro83rE+vl66bIRyb3l5edx8883s2bOH8ePHM2jQIL1NT7kFZ1v8bwMLgN5ANnC/MWatiHQBPgFGuCifKsMOpWTw0P+tYm/iKQL8vPjikda0iAixOpZShcrJycHT0xNPT0/ee+89wsLCuPrqq62OpdRZzg6ONgc+438L9XgCGGMWYt+Z750iT6bKtGW7k7h7wjL2Jp6iRnA5Zg26Tou+cnv79++nffv2jBs3DoDOnTtr0Vdux9kWvy+QboyxiUgKkH+FlK2A/stWRcIYw9Ql+3hr0XbybIao8GCmPhRNJX9fq6MpVajvvvuOAQMGYIwhLOzctc6Uch/Otvj3Amf+JW8B+uY7dz+gG/SoK2azGV6dt4U3Fmwjz2Z4tH0dvnusrRZ95dYyMjIYOHAgPXv2pFGjRqxfv56ePXtaHUupAjnb4l8E3Ap8C7wF/OBo+ecClYCnXRNPlRVZuXk8891G5m04ggi83zOKHi1qWB1LqYtau3Ytn376KSNGjOD111/H29vb6khKFcqpwm+MeSHf48Ui0g64BygPLDbGzHNRPlUGxKdl8uDUVeyIT6eCjycfxLTQ9faVWzPGsHr1alq3bs0NN9zAzp07qVOnjtWxlHKK0/fx52eMWQGsKOIsqgxaezCV4dPXsz85g+pBfnx8X0udxKfcWkpKCv3792fOnDmsXr2aVq1aadFXJcplFf78RKQx8LIxpncR5FFlyKJNR3li+nqyc200qhbAF/1aUzVAF+VR7mvJkiX06dOHo0ePMmbMGFq0aGF1JKUuWaGFX+yrTTTDvmjPHmPMtnznmmHfve9O4LQrQ6rSxWYzvL5gK/+3dD8AtzYOZVxMC8r56KI8yn2NHj2aF154gcjISJYtW8Y111xjdSSlLkuBhV9EqgGzgGvzHfsK6Ad8ADwG5GDfuU+35VVOOZmVyxPfrOPX7Ql4eghPd2rIo+3r4OGhK5op9+br60tMTAwTJkwgMDDQ6jhKXbbCWvxvA1HYi/paoDbwLPAn0BaYDjxjjIlzdUhVOhw9cZqHPl3FzviTeHkIE+9vxS06iU+5sfnz52Oz2ejWrRtPPPEEgC67q0q8wgr/rcBrxpi3zxwQkc3Aj8BEY8xgV4dTpceqfSkMnraGpJPZhAX5MeH+VjQPD7Y6llIXlJWVxYgRI/jwww+56aab6Nq1qxZ8VWoUVvirAkvPOXbm+TeuiaNKoxV7k+n7f6vIzLHRIiKYKQ9GU1kX5VFuaufOncTExLBu3Toef/xxRo8erUVflSqFFX5PIOucY2een3JNHFWa2GyGj37fzdifdwLQPSqMsT2j8NTxfOWm9u/fT8uWLfHz82PevHl07drV6khKFbmL3c7XSUTq5XvuARigs4g0yn+hMebrog6nSi6bzfD8rE1Mjz0EQK/ocF7v0VSLvnJLNpsNDw8PIiMjeeWVV+jTpw81aujKkap0EmPMhU+I2C544sKMMcaye7Gio6NNbGysVR+vzmGM4T8/bOWzZfvx9BDeurMZPa8JtzqWUhcUGxvLI488wjfffEOTJk2sjqOUU0RkjTEm+nJeW1iL/6rLzKPKuLcXbeezZfvx9hQ+eegabmxQxepISp3HZrPx/vvv8/zzz1OtWjVOnjxpdSSlikWBhd8Ys8MVHyginYEPsc8h+CT/XQP5rukJvIp9WGGDMaaPK7KoomWM4bX5/1uY57+9W2jRV24pISGBhx56iMWLF9OjRw+mTp1KxYoVrY6lVLG44iV7L4WIeALjsd8qGAesFpF5xpit+a6pDzwPXG+MSRWRqsWZUV2+j37bzf8ttXfvj777ajo3rW51JKUu6KOPPuL3339n/PjxDBo0SGftqzLFo5g/rzWw2xiz1xiTjX2b3+7nXDMAGG+MSQUwxiQUc0Z1iYwxjPt1F+/9vBMR+Kh3C+5pVdPqWEr9Q05ODnv37gXgxRdfZO3atQwePFiLvipzirvw1wAO5Xse5ziWXwOggYgsFZEVjqGB84jIQBGJFZHYxMREF8VVF2OzGUYt3Hb2lr1X7mjMbc20pa/cy759+2jfvj0dOnQgIyMDX19fGjdubHUspSxRrF39wIW+Wp97W4EXUB+4CagJ/C0iTY0xx//xImMmA5PBPqu/6KMqZ7yxYBufLt2HCIy5p7m29JXbmTFjBgMGDABgypQplC9f3uJESlmruFv8cUD++7pqAkcucM1cY0yOMWYfsAP7FwHlZib9ueds0Z/6ULQWfeVWMjMzGTBgAL169aJx48asX7+enj17Wh1LKctdcuEXkXoicq2IXM7X5tVAfRGpLSI+QAww75xr5gA3Oz6rMvau/72X8VnKhaYu2cdbi7YD8PZdzejQSDfbUe7F29ub/fv38/zzz/PXX39Ru3ZtqyMp5RacLvwi0k9E4rC3wJcBjRzHZ4rIY868hzEmFxiCfaOfbcAMY8wWEXlNRLo5LvsRSBaRrcDv2HcATHb6b6RcbsIfe3h9vv1GjFe7NqbXNREWJ1LKzhjDlClTOHLkCJ6enixatIhRo0bh7e1tdTSl3IZThV9E+mIfT/8NeIh/jtWvBHo5+4HGmIXGmAbGmLrGmDcdx0YaY+Y5HhtjzHBjTGNjTDNjzLfOvrdyLWMM//11F6MX21v6r3VvQt/rtRWl3ENKSgp33303AwcOZMKECQB4eRX3NCal3J+zLf5ngA+NMQ9y/s5823C0/lXp9t5PO3nPMXv/te5NeLBtpLWBlHJYsmQJUVFRzJ8/n3fffZf//Oc/VkdSym05+3W4LrCggHPpQEjRxFHuau76w3z0+24APoyJonuUbmCi3MOsWbO49957qV27NsuWLSM6+rKWL1eqzHC2xZ/CP2fj59cAOFo0cZQ72nDoOM/P2gTAS7dfpUVfuZWbb76Zxx9/nLVr12rRV8oJzhb+BcBLIpK/+BsRCQaGAXOLPJlyCydO5zDgi1gysvO45aqq9LtBx/SV9X744Qc6d+5MdnY2ISEhvP/++wQGBlodS6kSwdnC/6Lj2q3AfOyL7rzreO4N6IBaKfXaD1tJSM+iTuUKfNSnpS5vqiyVlZXFE088Qbdu3YiPjycpKcnqSEqVOE4Vfsd6+S2BcUAV4DBQEfgcuPbMuvqqdPnk7718vzYOLw9hwv2t8PP2tDqSKsN27NhBmzZtGDduHE888QQrVqwgLCzM6lhKlThO3+viWDL3RccfVcrNiD3Emwu3ATDqrmY0rBZgcSJVlhlj6Nu3L4cOHeKHH37gjjvusDqSUiWWU4VfREYBXxhjtrs4j3IDf+5M5NmZGwF4vEM9ekYXNK9TKddKS0vDw8MDf39/PvvsM/z9/alRQyeXKnUlnB3jHwpsceyGN1REqrgylLLO/qRTPPHtOgD6XhfJ8E4NLU6kyqrVq1fTsmVLhg4dCkDDhg216CtVBJwt/FWBB4FEYCxwWETmi8i9IuLrsnSqWB0+fpr7p67keEYO19WtxEu3X2V1JFUG2Ww23n33Xa677jpycnLo37+/1ZGUKlWcndx32hgzzRhzG/Yd9Z4DqgPTgXgRmeLCjKoYHDuRSa9Jy4lLPU3j6oFMuK8VXp7FvXmjKusSEhLo0qULzzzzDN26dWP9+vVcf/31VsdSqlS55N/sxph4Y8xYY0wroCP2lfseKfJkqtiknsqm95QVxKWepkGoP18PuJag8rqpiSp+GRkZbNy4kQkTJjBz5kxCQnRRUKWK2iXvYOHo2u8B3A90wr5hT0HL+So3Z7MZ+n8Ry76kU9SpXIGvB7QhuLyP1bFUGZKTk8O0adN46KGHiIyMZM+ePZQrV87qWEqVWpeyLe9NIjIViMe+UU8o8DQQZozpVuiLlVsyxvDKvC2sOZBKZX8fvujXmsr+OmVDFZ99+/bRrl07Hn74YX799VcALfpKuZizt/MdBGoAh4Dx2G/t2+HKYMr1Pvl7H1+uOIAIjLqzGTVDylsdSZUh06dPZ+DAgYgI06dP55ZbbrE6klJlgrNd/T9jL/Z/ujKMKj4bDh1nzE/2727v94yiU5NqFidSZckLL7zAW2+9RZs2bfjmm2+IjIy0OpJSZYZThd8Y08/VQVTxOXriNP0+jyU710bv1hH0aKH3RqvidaZ1/5///Advb51IqlRxKrDwi0hrYLMxJsPxuFDGmFVFmky5RFpmDvdNWUnSySxaR1bk1W6NrY6kygBjDB9//DGpqam89NJLdOjQgQ4dOlgdS6kyqbAW/wqgDbDK8dgUcJ04zukOLm4uMyePgV/Estcxg//j+1vi66X/tynXSklJoV+/fsyZM4fbb7+dvLw8PD31351SVims8N8GbHM87kLBhV+VAMYYXpi1iRV7U6hUwYf/e/gancGvXG7JkiX06dOHY8eO8d577zFs2DA8PHRhKKWsVGDhN8b8mO/x4uKJo1xl2sqDzFp3GF8vD6b2vYZalSpYHUmVcomJiXTq1ImwsDCWLVtGdHS01ZGUUjh5H7+IbBWRZgWcaywiW4s2lipKO46l89oP9v+LXu/RlKjwYIsTqdLsxIkTAFSpUoVZs2axdu1aLfpKuRFn+9waAQWtqlEe0C3c3FRmTh5PTl9Pdp6NXtHhusWucql58+ZRt25dvv/+ewA6d+5MYGCgxamUUvldymBbQWP8VwMniiCLKmLGGIbPWM/Wo2nUCC7HiNsaWR1JlVKZmZk8/vjjdO/enYiICJo1u2AHoVLKDRR2O99QYKjjqQFmikjWOZeVA8KAma6Jp67E1CX7WLjpGOW8PZn0QCsqVtA1+FXR2759OzExMWzYsIFhw4bx9ttv4+urE0eVcleFzeo/AqxxPK4H7ACSz7kmC9gKTCj6aOpK/L0rkbcXbQfg3Xub07RGkMWJVGm1evVqDh8+zPz587n99tutjqOUuojCZvV/D3wPICIALxpj9hZTLnUF0jNzGPbtenJthofa1uL2q6tbHUmVMmlpacTGxtKhQwceeOAB7rjjDt1CV6kSwtkle3u7OogqGnk2wxPfrif5VDZNawQysmsTqyOpUmb16tXExMSQmJjIgQMHCAkJ0aKvVAlS2Bj/s9g35jnmeFwYY4wZU7TR1KUyxvDy3M38tj2BoHLefNArCk8PsTqWKiVsNhvvvfceL7zwAmFhYSxatEgLvlIlUGEt/reBP4BjjseFMYAWfot9/Mcevl55EBF4v1dz6lUNsDqSKiVyc3Pp2rUrixcv5q677uKTTz7Roq9UCVVY4S9njDkzi7+ge/iVm1i8+ShjftyBCIy5pzkdGoVaHUmVIl5eXrRo0YLu3bvz6KOPnpn3o5QqgQqb3Jd1ocfK/exNPMmw6esBeLpTQ+5pVdPiRKo0yMnJ4eWXX6Z79+60bduWUaNGWR1JKVUEnJrcJyJ1gEBjzHrHc1/gOaAp8KMx5hPXRVSFsdkMw2dsIDPHRpdm1Rh8U12rI6lSYO/evfTu3ZtVq1bh6+tL27ZtrY6klCoiThV+4GPs9+uvdzx/HXgS2AncKSKexphJLsinLmL877tZf+g4lf19GXVnM+2CVVds+vTpDBw4EBFhxowZ3HvvvVZHUkoVIWeX7I0C/gIQe2XpC7xgjGmCfeLfYy5Jpwq1+fAJPvx1FwCvdG1McHldmU9dmfnz5xMTE0OTJk1Yv369Fn2lSiFnC38wkOR4HAVUAmY4nv8MaP9yMYtPy+TRL9eQazPc3yaCrs3DrI6kSrDMzEwAbrvtNiZPnsyff/5JZGSktaGUUi7hbOFPAOo4Ht8K7DPGHHA8rwDkFXUwVbDcPBuPfbWGw8dP07RGIC/d3tjqSKqEMsYwfvx4GjRowNGjR/H09GTAgAF4e3tbHU0p5SLOjvHPB94UkQbAQODTfOeaAPuKOpgq2KS/9rLu4HEqVfBh8gPR+Hl7Wh1JlUApKSn069ePOXPm0KVLF7y8nP11oJQqyZz9L/05IADoBfwCvJHvXE/gtyLOpQqw4dBxxv68E4DRd19NWLAusaAu3d9//02fPn2Ij49n7NixPPHEE3h4XMou3UqpksrZtfrTgAcKOHdNkSZSBTqZlcvgaWvJc4zr39JYF+lRl2f8+PH4+fmxfPlyWrVqZXUcpVQxuqS+PREJAFoDFbFv0bvaGJPuimDqn4wxjJyzmcPHT9OoWgAv36Hj+urSxMXFkZOTQ+3atZk0aRIeHh4EBOiyzkqVNU737YnIS8BR4CdgOvYu/6Mi8qKLsql8vlp5kFnrDuPn7cH7vaLw9dJxfeW8uXPn0rx5cx555BEAgoKCtOgrVUY5VfhF5N/Aa8BsoAvQArjN8fw1ERnksoSKhLRMxizeDsCrXZtwVfVAixOpkiIzM5OhQ4fSo0cPatWqxaRJus6WUmWds139Q4CPjTFD8h3bAPwoIieAocCEog6nIDvXfuteWmYu7epXptc14VZHUiXEoUOH6Nq1Kxs2bGDYsGG8/fbb+Pr6Wh1LKWUxZwt/HeDxAs7NBfoXTRx1rv/+tou1B49TJcCXd+9trkvyKqdVqlSJkJAQ5s+fz+233251HKWUm3B2jD8FaFjAuYaO86qI/botnv/+thuAsT2bExroZ3Ei5e7S0tJ45plnOHnyJOXLl+e3337Toq+U+gdnC/8c7Av43Cv5mpwicif2DXvmuCJcWbYrPp3Hv1kHwKCb6tKufhWLEyl3t2rVKlq0aMH777/P77//DqA9REqp8zhb+J8DtmOfzZ8hIgdEJAOYCexwnFdFJDvXxuPfrudUdh5dmlXjmU4FdbYoBTabjTFjxnD99deTm5vLX3/9RdeuXa2OpZRyU84u4HNCRK4D7gTaYb+PPwX4E5hrjNG1+ovQqIXb2HY0jZoh5Rh999V4eGirTRXs+eef55133uHuu+9mypQphISEWB1JKeXGnF7Ax1HcZzr+KBf5fUcCny3bj7en8GFMCwL8dLMUdWF5eXl4enoyaNAg6tWrR//+/bVrXyl1UYV29YtIjIisEJEkEdktIm+KiO7k4SKnsnJ55ruNADzRsT6tamnLTZ0vOzubESNGcOedd2KMITIykgEDBmjRV0o5pcDCLyL3Al8D1YClQAb2sfw3CnqNujIf/rqLpJNZNKsRxKCb6lkdR7mhvXv30q5dO9555x3CwsLIycmxOpJSqoQprMU/HFgA1DfGdDfGXA2MBoaKiG7jVcQ2Hz7B1CX7EIFXujbGU8f11Tm+/fZbWrRowc6dO5k5cyYTJ07Ex8fH6lhKqRKmsALeEJhgjMnfpBgHlANquTRVGZOda+Pp7zaQZzM80KYW0ZEVrY6k3Ex6ejrDhw+nadOmrF+/nrvvvtvqSEqpEqqw8fpgIOmcY4mO/w0B9rkkURn0wS872X4snYiK5RnRuZHVcZQb2b59O/Xq1SMgIIA///yT2rVr4+Wl02yUUpfvYl325hKPq0u0N/Ekk//aC8CYe66mgq/+Ulf2bZg/+ugjoqKiGDNmDAD169fXoq+UumIXK/xLRST7zB/gtOP4yvzHRSTL2Q8Ukc4issNxl0CBC/+IyD0iYkQk2tn3LoneXLCNXJuhR1QY19apZHUc5QaSk5O58847GTp0KB07dqR/f90KQylVdAprPowu6g8TEU9gPHArEAesFpF5xpit51wXgH1ToJVFncGdrN6fwq/bE/Dx9GDEbdrFr2D58uX07NmT+Ph4xo4dy7Bhw/Q2PaVUkSqw8BtjnnfB57UGdhtj9gKIyLdAd2DrOde9DrwDPO2CDG4hz2YYOXcLAP3b1aZ6UDmLEyl34OPjQ1BQEHPmzKFVq1ZWx1FKlULFfVteDeBQvudxjmNniUgLINwYM7+wNxKRgSISKyKxiYmJhV3qlr6LPcS2o2lU9vfl3zfrPftlWVxcHP/9738BaNWqFRs3btSir5RymeIu/Bfqszw7UdCxPsD7wFMXeyNjzGRjTLQxJrpKlZK1c92JjBxGLdwGwLOdG+qEvjJs7ty5NG/enBdeeIHDhw8D4OGhy2QopVynuH/DxAHh+Z7XBI7kex4ANAX+EJH9QBtgXmmb4PfKvM2kZebSOrIi97aqaXUcZYHMzEyGDh1Kjx49iIyMZO3atdSoUePiL1RKqStU3E3N1UB9EakNHAZigD5nThpjTgCVzzwXkT+Ap40xscWc02UWbz7GnPVH8PP24K27m+nErTLIGMMtt9zC0qVLGTZsGG+//Ta+vr5Wx1JKlRHF2uI3xuQCQ4AfgW3ADGPMFhF5TUS6FWcWK5zMyuWVeZsBGHZLA+pW8bc4kSpOxhiMMYgIQ4cOZf78+bz//vta9JVSxarYB5eNMQuBheccG1nAtTcVR6bi8s7i7cSnZdG4eiD9b6htdRxVjE6cOMGjjz5Kx44dGTBgAL169bI6klKqjHK6xS8ioSIySkSWiMhWEWnsOD64tI3Bu8KR46f5euVBROC9ns3x8tQJXGXFypUradGiBTNnziQtLc3qOEqpMs6p6iMijYBNwCDs2/M2BPwcpxsCw1ySrhQZ8+MOcm2GLk2rc1X1QKvjqGJgs9kYPXo0N9xwAzabjb///punnrroDStKKeVSzjY738W+KU9toAv/vC1vKdC2iHOVKrvi0/lhwxFE4Dldoa/MWLFiBc899xx33nkn69evp21b/c9EKWU9Z8f4bwTuN8Ycdyy7m98xoHrRxipd3v9lJ7k2Q+/WEYRXLG91HOViBw8eJCIiguuuu45ly5bRpk0bvXtDKeU2LmWgOa+A45X43+Y96hyHUjL4cUs8HgJPdKxvdRzlQtnZ2Tz77LPUq1eP2Fj7Haht27bVoq+UcivOtvhjgQeACy2jezewosgSlTKfL9tPns3QrXkY1YL8Lv4CVSLt3buXmJgYVq9ezWOPPUaTJk2sjqSUUhfkbOF/E1gsIj8A07Avs9teRB4FegI3uyhfiXYiI4dvV9u3JujfTm/fK62+/fZbBg4ciKenJzNnzuTuu++2OpJSShXIqcJvjPlFRHoCHwC3Ow6Pxb7cbk9jzFIX5SvRPvh1JyezcmlTpyJX1wy2Oo5ykd27d9OsWTO+/vpratWqZXUcpZQqlBhjLn7VmYvtg5VNgKpAMrDJGGNzUTanRUdHmzNjqu4iLjWDG8f8gc0YZg26jhYRIVZHUkVow4YNpKamctNNN5GXl4cxBi8v3WxJKVU8RGSNMeay1tC5pN9Uxv4tYfPlfFBZ895PO8mzGW5rWk2LfilijGH8+PE89dRTNG7cmLVr1+Lpee6NLkop5b6cKvyObv5CGWNmXHmc0mHVvhRmrzuMr5cHT3VqaHUcVUSSk5N55JFHmDfv/9u78/Aoquzh49+TkLBE9hD2RXYBIUAEZNURUdEBIwgEcARFUcBlBFd+OsD4KiL7CDMwI+Oggyh7RAEdZRBkUTAJAiMa1kiAsK+BbPf9owpsYgid0N2V7j6f56knSdXtqpPbeXL63rp1bzzdu3fnvffe0xH7Sim/426Lf/5V9rveJ9DEj9UifHPF/wAY2qUe9aN0IZ5AkJqaSps2bUhLS2PKlCk888wzmvSVUn7J3cR/Ux77KgL3Ab2Bhz0WkZ9bvTONhP0nibwhnMd0JH/AqFq1Kn379mXAgAG0atXK6XCUUqrQ3B3Vv/Mqh9aLSDbWHP4bPBaVH5uzbi8AQzrVpXSJMGeDUdclJSWFJ554gmnTplG/ftLBCGMAACAASURBVH0mTZrkdEhKKXXdPLFE3GqghwfO4/eWb01lXfJRSoaF8mDrGk6Ho67D0qVLadGiBV9//TU7d17tc69SSvkfTyT+GKwV+4JaTo5h0uc/ATCyW0Mq3lDc4YhUYVy4cIHhw4cTGxtL3bp1+f7777n33nuv/UKllPIT7o7qfyGP3eFAMyAW+Lsng/JH8Ump7Dl6jurlSvJw+zpOh6MKacKECcycOZPnnnuON998k/DwcKdDUkopj3J3cN/4PPZlAweAKcBYj0XkhzKycnh7ldUdPPz2+oSFeqIjRfmKMYbjx49TsWJFRo0aRYcOHbjjjjucDksppbzC3cRfMo99mUVh1r6i4NMfUjlwMp3aFUvRJ0bv7fuTU6dOMXToUBISEvj++++JiIjQpK+UCmjXbJqKSDgwBmhmjLnosmnSx2rtT/niZwCe7FKPYtra9xubNm2iZcuWLFy4kEGDBlGihK6eqJQKfNfMUsaYDOAZIML74fifT5JS2X/8PDUrlCS2VXWnw1FuyMnJ4a233qJjx47k5OSwdu1aXn75ZZ16VykVFNxtniYBTbwZiD+6mJXNO6uTARhxe32KF9PE4Q+ys7NZtmwZsbGxJCYmcuuttzodklJK+Yy79/hfAOaKSLIx5j/eDMiffPxdCnuOnuPGyAgeaKX39ou6L774gpYtWxIZGcnKlSspXbq0TrurlAo67rb45wDlgFUickZEfhaRn1y2oJvhJCs7h5n/3QXAs10b6Ej+IiwjI4Pnn3+ebt268frrrwNQpkwZTfpKqaDkbot/C1cuyBP0Pv3hIAdPXSDyhuJ0v7mq0+Goq9i1axdxcXF89913PPHEE7z55ptOh6SUUo5yd67+ft4OxJ/k5Bj+tX4vAMNuq6et/SLqq6++4v777yc0NJSFCxfSq1cvp0NSSinHXTVjichuEWnhy2D8RXxSKt/bK/D11uf2i6xmzZpx5513kpiYqElfKaVs+TVV6wA64XwuOTmGv62x7u2P6taIMroCX5GSmJjI4MGDycrKIioqikWLFlG7dm2nw1JKqSJD+6gL6N/f7ufHQ2eoXKa4PrdfhBhjmD59Om3btuXzzz9n7969ToeklFJF0rUSvw7oc2GMYfbXVmv/xbsb63P7RcTRo0fp2bMnzzzzDN26dSMpKYn69es7HZZSShVJ1xrcN1ZEjrpxHmOMedgTARVl65KPknI8naplS3B/tLb2i4revXuzYcMGpk2bxlNPPaWP6SmlVD6ulfijgYtunCcoegbmbdoPQJ+YmoSEaHJxUlZWFtnZ2RQvXpwpU6YA0LJlS4ejUkqpou9aif9+Y8y3PomkiDt8+gKf7zhMiECfW2o6HU5QS0lJoX///jRv3pwZM2ZowldKqQLQwX1umrdpP9k5hq43VaZ6ubxWKVa+sHTpUlq0aEFiYiLt27d3OhyllPI7mvjdkJ6RzdwNewEY1KGOk6EErfT0dIYPH05sbCx169YlISGBAQMGOB2WUkr5HU38bohPOsCJ85k0rVaGW+tWdDqcoHTgwAHmzp3LyJEjWb9+vY7aV0qpQrrqPX5jjH4owFp699JiPI92vFFHjPuQMYYvv/ySO+64g/r165OcnEzlypWdDksppfyaJvdr+Hz7YfYdO8+NkRHc17ya0+EEjVOnThEXF8edd97J8uXLATTpK6WUB7i7Ol9QMsYw55s9APzh1tqEF9PPSb6wceNG4uLiSElJ4Y033uDee+91OiSllAoYmsny8eX/0kjYf5JypcLoE6OP8PnCjBkz6NSpE8YY1q5dy8svv0xIiP6ZKqWUp+h/1HzM/no3AE92qUdEce0c8YXatWvzwAMPkJiYyK233up0OEopFXA08V/Fln3H+XbvcUqFhxLXtpbT4QS0lStXMmPGDADuu+8+PvroI8qVK+dwVEopFZg08V/FnHV7AYhrU0uX3vWSjIwMRo0axT333MO7775LZmam0yEppVTA08SfhyNnLvL5jkOIWI/wKc9LTk6mQ4cOTJo0iWHDhvHNN98QFqYfsJRSytv0xnUePvvhIJnZhtsaVaKaTs/rcSdPnqRNmzYYY1i8eDGxsbFOh6SUUkFDE38uxhg+/NZahe+BVjUcjiawZGVlUaxYMcqVK8f06dPp3LkztWrp+AmllPIl7erP5ZvkY/x46AwVI8Lp1kQnjPGUxMREbr75ZlauXAnAwIEDNekrpZQDNPHncqm1H9emFiXCQh2Oxv8ZY5g+fTpt27bl9OnTlCpVyumQlFIqqGnid3H2YhZf7DiMCPS9RSfsuV5Hjx6lZ8+ePPPMM9x1110kJSXRuXNnp8NSSqmgponfxcpth8jIzqF1rfLUrKAt0+sVHx/PqlWrmDZtGsuWLSMyMtLpkJRSKujp4D4XnySlAtAjWhfjKaysrCy2b99OixYtGDx4MJ07d9YldJVSqgjRFr8tKeUka346QvFiIboKXyHt37+f22+/nU6dOpGWloaIaNJXSqkiRhO/7R/rfl2Fr0JEuMPR+J8lS5YQHR1NUlISf/3rX4mKinI6JKWUUnnQxA+knkznsx8OAjCwXW2Ho/EvOTk5DBs2jAceeIB69eqRkJDAgAEDnA5LKaXUVWjiBz76LoXsHEO3JpWpXTHC6XD8SkhICFlZWYwcOZJvvvmGevXqOR2SUkqpfAT94L7sHMM8+9n9h9vXcTYYP2GM4R//+AcxMTG0bNmSWbNmISJOh6WUUsoNPm/xi8jdIrJTRJJF5KU8jj8nIjtEZKuIfCkiXu17/+HAKY6cuUj1ciVpX6+iNy8VEE6ePEnfvn15/PHHmTVrFoAmfaWU8iM+TfwiEgrMAO4BmgBxItIkV7EEIMYY0xxYCEzwZkyfbz8EwO8aR2kCu4YNGzYQHR3NkiVLGD9+PDNnznQ6JKWUUgXk667+NkCyMWY3gIjMB3oCOy4VMMasdim/ERjorWCycwyf2oP67m5WxVuXCQj//e9/6dq1KzVr1mTt2rW0a9fO6ZCUUkoVgq+7+qsDKS4//2Lvu5pHgRXeCmbj7mPsO3aeamVL0PbGCt66jF8zxgDQoUMHRo8eTUJCgiZ9pZTyY75O/Hn1pZs8C4oMBGKAt69y/HER2Swim48cOVKoYJZvtVr7PVtWp1ioPuCQ24oVK2jdujXHjh0jLCyMsWPHUq5cOafDUkopdR18ne1+AVxXv6kBpOYuJCJdgdFAD2PMxbxOZIyZbYyJMcbEVKpUqcCBZGbnsHKblfh7tNCZ+lxlZGQwcuRIunfvTlZWFidPnnQ6JKWUUh7i68T/HdBARG4UkXCgHxDvWkBEWgKzsJJ+mrcCWbPzCCfOZ1I/6gZuqlrGW5fxO8nJyXTo0IHJkyczbNgwNm3apM/mK6VUAPHp4D5jTJaIjABWAaHAHGPMdhEZB2w2xsRjde3fACywR9nvN8b08HQsn9mt/diW+Q0xCD6vvPIKu3btYvHixcTGxjodjlJKKQ/z+QQ+xpjPgM9y7XvN5fuu3o4hJ8ew9uejgPUYX7A7e/YsZ8+epUqVKrzzzjtcuHCBWrVqOR2WUkopLwjKEW2b9hznyJmLVCtbgsZVSjsdjqMSEhJo3bo1/fr1wxhDVFSUJn2llApgQZn445Os8YQ9W1YP2kl7jDFMmzaNdu3ace7cOcaOHRu0daGUUsEk6Obqz8jKuTxb3703V3U4GmccP36cQYMG8cknn/D73/+eOXPmEBkZ6XRYSimlfCDoWvxf/XiYY+cyqB91A02rBedo/mLFirFr1y6mT5/OsmXLNOkrpVQQCboW/9IEq5u/b0zNoOrazsrKYsaMGQwdOpQyZcqQmJhIWFiY02EppZTysaBq8Z+5kMnXP1uz/HVvHjzd/Pv27aNLly48++yzLFy4EECTvlJKBamgSvzzv03hfEY2MbXLU71cSafD8YlFixYRHR3NDz/8wLx58xg40GtrHimllPIDQZX4V9iT9gzqUMfZQHzk7bffpnfv3jRo0ICEhATi4uKcDkkppZTDguYe//FzGSSmnCQsVOjSsOBz+/ujHj16cOLECcaMGUN4eLjT4SillCoCgqbF/03yUXIM3FKnAqVLBOb9bWMMs2fP5pFHHsEYQ6NGjXjjjTc06SullLosaBL/5zsOAwRsa//kyZP07duXoUOHkpKSQnp6utMhKaWUKoKCIvFn5xjW7LQW+ruraRWHo/G8DRs2EB0dzZIlSxg/fjyrVq2iVKlSToellFKqCAqKe/zf7z/B6QtZ1KxQkjqREU6H41Hp6enExsZSqlQp1q1bR9u2bZ0OSSmlVBEWFIn/063WaP57mgXOs/tHjhyhYsWKlCxZkvj4eBo1akTZsmWdDksppVQRF/Bd/Tk55vLc/Hc1rexwNJ6xYsUKmjZtyqRJkwBo06aNJn2llFJuCfjEvz31NKmnLlC1bAla1izvdDjXJSMjg5EjR9K9e3eqVq3Kfffd53RISiml/EzAd/Vv2nMMgPb1IgkJ8d+5+ZOTk+nXrx9btmxh+PDhTJw4kRIlSjgdllJKKT8T8Il/894TALS9sYLDkVyfgwcPsn//fpYsWcL999/vdDhKKaX8VEB39Wdm57DWXpTn1noVHY6m4M6ePcvHH38MQKdOndizZ48mfaWUUtcloBP/1l9OcS4jmxsjI6hZwb+ea//+++9p1aoV/fv3Z/fu3QBERATWo4hKKaV8L6AT/8bd1v39DvX9p7VvjGHq1Km0a9eO8+fP8+WXX1K3bl2nw1JKKRUgAvoe/6Y9xwFoVcs/RvMbY+jTpw8LFy6kR48ezJkzh4oV/edDi1JKqaIvYBP/hcxsNu46hgh0bBDpdDhuERG6detGly5dGD58OCL++xSCUkqpoilgE//3+06QkZ3DTVXLEFW66D72lpWVxZgxY2jatClxcXE89thjToeklFIqgAVs4t9g39+/pU7R7ebft28f/fv3Z/369Tz99NPExcU5HZJSyg+cPn2atLQ0MjMznQ5FeVhYWBhRUVGUKVPGa9cI2MT/1Y/Wany3N4pyOJK8LVq0iCFDhpCdnc28efM06Sul3HL69GkOHz5M9erVKVmypN4SDCDGGNLT0zlw4ACA15J/QI7qP3k+gx0HTxMeGlIkn9/fsmULvXv3pkGDBiQkJGjSV0q5LS0tjerVq1OqVClN+gFGRChVqhTVq1cnLS3Na9cJyMT/7Z7jGAPRtcpRIizU6XAuO3PmDACtW7dmwYIFrFu3jnr16jkclVLKn2RmZlKyZEmnw1BeVLJkSa/exgnIxL/1l1NA0XmMzxjD7NmzqV27NklJSQD07t2b8PBwhyNTSvkjbekHNm+/vwGZ+L+1n9+PrlnO4Ujg5MmT9OnTh6FDhxITE0PlyoGxNLBSSin/FHCJ/9zFLDbvO06xEKG9wzP2bdiwgejoaJYuXcpbb73FypUrqVKliqMxKaWUCm4Bl/i3HThFjoGGlUtTpkSYo7HEx8cTEhLCunXreOGFFwgJCbjqVkqp6/Lee+8hIiQnJxeJOC5t4eHh1KtXj1deeYULFy44GpunBdzjfJfu77dwqJs/NTWVgwcP0rp1a8aNG8dLL71E2bJlHYlFKaVUwSxYsIAaNWpw5swZlixZwptvvsmZM2f4y1/+4nRoHhN4if+Anfhr+D7ZfvrppwwaNIgKFSqwY8cOwsLCNOkrpZQfiY6Opn79+gDceeed/Pzzz7z77rtMmzYtYHptA+O3cLEj1Ur8Tav5LuFevHiRP/7xj9x3331Uq1aNZcuWERpadB4jVEopf/fBBx/QokULSpQoQWRkJA899BAHDx68osz58+d58sknqVixIqVLlyY2Npb169cjIrz33nuFum6rVq1IT0/n6NGjV+zfs2cPAwYMoFKlShQvXpzo6GiWLFnym9d/+OGHNG7cmBIlSnDzzTcTHx/Pbbfdxm233VaoeDwhoBL/hcxs9h47T4hAg8o3+OSax44do3379kydOpWnnnqKTZs20bhxY59cWymlgsHs2bN56KGHuOmmm1i8eDHjx49n1apVdOnShbNnz14u9/jjjzNnzhxGjRrF4sWLadSoEQMGDLiua+/du5eyZctesVJqSkoKbdu2JSkpiSlTphAfH0+rVq3o1asX8fHxl8t98cUXDBgwgMaNG7No0SJGjRrFs88+y08//XRdMV2vgOrq/+HAKbJzDI2rlPbZxD3ly5fnpptu4rXXXqNnz54+uaZSSrmq89KnTocAwN7x93r8nNnZ2bz66qvcdtttzJ8///L+xo0b06lTJ+bMmcPTTz/Nzp07mTdvHuPHj+eFF14ArK768+fPF+j+fHZ2NllZWZfv8S9atIipU6de0Ys7ZswYjDGsWbPm8geCu+66i5SUFF577TV69OgBwJ/+9CeaNGnCkiVLLj+bf/PNN9O6dWsaNmx43XVTWAHV4v/x4GkAbq7u3W7+M2fOMGzYMFJSUggJCeGDDz7QpK+UUl6wc+dO0tLSftNy79ixI7Vr12bNmjUAbNq0CWMMDz744BXlevfuXaDrNW7cmLCwMCpUqMCjjz7K0KFDGTFixBVlVq5cSffu3SlbtixZWVmXt7vuuoukpCROnz5NdnY2mzdvplevXldMyNOqVStuvPHGAsXkaQHV4k+yR/Q3qea9VY22bNlCv3792L17N+3ateMPf/iD166llFLu8EZLu6g4ftyakK1q1aq/OValSpXLxy/d74+KunJhtoJOmrZkyRJq1KjBkSNHmDx5MjNnzqRt27ZX/K9PS0tj7ty5zJ07N89zHDt2jPT0dDIzM38TT2Fi8rSASvz/82KL3xjD1KlTefHFF4mKimL16tV07tzZ49dRSin1qwoVKgBw6NCh3xw7dOgQMTExwK8fDNLS0q5oUR8+fLhA12vWrNnlUf2/+93vaN68Oc8//zy9evUiIiICgIoVK9KpUydefPHFPM9RrVo1ihUrRlhYWJ6L7Rw+fJhatWoVKC5PCpiu/oysHH5OswZ5NKpS2uPnnzx5Ms899xzdu3cnKSlJk75SSvlAo0aNqFy58hX39wHWr1/Pvn376NKlCwBt27ZFRFiwYMEV5XL/XBDFixfn7bffJi0tjZkzZ17ef/fdd7N161aaNm1KTEzMb7bixYsTGhpKTEwMixYtwhhz+bVbtmxhz549hY7JEwKmxb899RQZWTnUqxRBaQ/O2JeRkUF4eDiPPfYY5cuXZ/DgwbpAhlJKeVheU5qXLVuWO++8k3HjxjF06FAGDhzIwIEDOXDgAKNHj6ZBgwYMHjwYsD4g9O/fn1dffZWcnBxat27NV199xSeffAJQ6Gfwe/TowS233MLEiRMZMWIEJUuWZNy4cbRp04bOnTszYsQI6tSpw4kTJ9i2bRu7d+9mzpw5AIwdO5Zu3boRGxvL448/ztGjRxkzZgxVqlRxdk4AY4zfb61btzYfbNxrar+43Dw7P8F4QmZmpnnllVdMy5YtTXp6ukfOqZRS12vHjh1Oh+BR//znPw2Q59a0adPL5d5//33TvHlzEx4ebipUqGAGDhxoUlNTrzjXuXPnzBNPPGHKly9vIiIizO9//3uzfPlyA5ilS5e6FcfPP//8m2OrVq0ygJk8efLlfSkpKebRRx811apVM2FhYaZKlSqma9eu5v3337/itf/+979Nw4YNTXh4uGnSpIlZvHixiY6ONvfff3++8VzrfQY2m0LmTMeTtie21q1bm9FLtpraLy43s9Yk51tZ7ti7d69p3769Acwjjzxizp07d93nVEopTwi0xO9tEyZMMCJi9u3b53QoxhjrA0Px4sXNuHHj8i3nzcQfMF39Ow+dAeCmqtc3on/RokUMGTKE7Oxs5s2bR1xcnCfCU0op5WXLly9n27ZtREdHExISwtq1a5k4cSJ9+vRxZDBdeno6zz33HF27diUyMpLdu3czYcIESpUqxZAhQ3wezyUBk/h/tBN/o8qFH9iXlZXF66+/TsOGDfnwww+pW7eup8JTSinlZaVLl2bp0qWMHz+ec+fOUb16dZ5++mnGjh3rSDyhoaEcOnSIESNGcOzYMSIiIujUqRMLFizI8/FEXwmIxJ+RlcOZC1lE3hBOpdLFC/z67du3U6NGDcqWLcunn35KpUqVCAtzdklfpZRSBdOlSxc2btzodBiXhYeH5zl/v9MC4nG+C1nZgPUYX0FG3BtjmDVrFjExMbz00kuA9fylJn2llFKBKiASf3qGlfgbV3H//v6JEyd48MEHeeKJJ+jcuTNjxozxUnRKKaVU0REQif9CZg4A0TXLuVU+ISGB6Oholi1bxoQJE1ixYoXjUygqpZS7rEHdKlB5+/0NiHv8F7OyiQDqVopwq3ylSpWoUqUKCxYsoE2bNt4NTimlPCgsLIz09HRKlSrldCjKS9LT0716yzkgWvwZWVaLv27kDVctk5qayujRo8nJyaFGjRps3LhRk75Syu9ERUVx4MABzp8/ry3/AGOM4fz58xw4cCDPxX08JSBa/AaIvKE4JcND8zy+fPlyBg0aRHp6On379qV58+Y67a5Syi+VKWONZUpNTSUzM9PhaJSnhYWFUbly5cvvszcEROIHqFG+5G/2Xbx4kRdffJFp06bRokUL5s+fT+PGjR2ITimlPKdMmTJeTQwqsAVM4q9Z4bf3u/r27cuyZct46qmnmDBhAiVKlHAgMqWUUqroCJjEX6vCry3+nJwcQkJCGDVqFIMHD6Znz54ORqaUUkoVHT4f3Ccid4vIThFJFpGX8jheXEQ+so9vEpE67py3RvlSnDlzhoceeoiXX34ZgI4dO2rSV0oppVz4NPGLSCgwA7gHaALEiUiTXMUeBU4YY+oDU4C33Dn32V9+olWrVsybN4+ICPce61NKKaWCja+7+tsAycaY3QAiMh/oCexwKdMTGGN/vxB4R0TE5PPcSva5kwzv153KlSuzevVqOnfu7J3olVJKKT/n667+6kCKy8+/2PvyLGOMyQJOARXzO2n2mWPc0e0uEhMTNekrpZRS+fB1iz+vh+dzt+TdKYOIPA48bv94ceWny7dFRkZeZ3gqH5HAUaeDCAJaz96ndex9Wsfe16iwL/R14v8FqOnycw0g9SplfhGRYkBZ4HjuExljZgOzAURkszEmxisRK0Dr2Fe0nr1P69j7tI69T0Q2F/a1vu7q/w5oICI3ikg40A+Iz1UmHnjY/r438FV+9/eVUkop5T6ftviNMVkiMgJYBYQCc4wx20VkHLDZGBMPvAu8LyLJWC39fr6MUSmllApkPp/AxxjzGfBZrn2vuXx/AXiwgKed7YHQVP60jn1D69n7tI69T+vY+wpdx6K96EoppVTwCIhleZVSSinlHr9K/N6a7lf9yo06fk5EdojIVhH5UkRqOxGnP7tWHbuU6y0iRkR0dHQhuFPPItLH/nveLiLzfB2jv3Pj/0UtEVktIgn2/4zuTsTpz0Rkjoikici2qxwXEZluvwdbRaTVNU9qjPGLDWsw4C6gLhAOJAFNcpUZBvzN/r4f8JHTcfvT5mYd3w6Usr9/UuvY83VslysNfA1sBGKcjtvfNjf/lhsACUB5++cop+P2p83NOp4NPGl/3wTY63Tc/rYBnYFWwLarHO8OrMCaA6cdsOla5/SnFv/l6X6NMRnApel+XfUE/mV/vxC4Q0TymhBI5e2adWyMWW2MOW//uBFrLgblPnf+jgH+DEwALvgyuADiTj0/BswwxpwAMMak+ThGf+dOHRugjP19WX47b4u6BmPM1+Qxl42LnsBcY9kIlBORqvmd058Sv1em+1VXcKeOXT2K9UlTue+adSwiLYGaxpjlvgwswLjzt9wQaCgi34jIRhG522fRBQZ36ngMMFBEfsF6musp34QWVAr6f9v3j/NdB49N96uuyu36E5GBQAzQxasRBZ5861hEQrBWpRzkq4AClDt/y8Wwuvtvw+q5WisizYwxJ70cW6Bwp47jgPeMMZNE5FasOVqaGWNyvB9e0Chw3vOnFn9Bpvslv+l+1VW5U8eISFdgNNDDGHPRR7EFimvVcWmgGfBfEdmLdc8uXgf4FZi7/y+WGWMyjTF7gJ1YHwSUe9yp40eBjwGMMRuAEljz+CvPcev/tit/Svw63a/3XbOO7W7oWVhJX++JFly+dWyMOWWMiTTG1DHG1MEaR9HDGFPoebmDlDv/L5ZiDVZFRCKxuv53+zRK/+ZOHe8H7gAQkZuwEv8Rn0YZ+OKBP9ij+9sBp4wxB/N7gd909Rud7tfr3Kzjt4EbgAX2uMn9xpgejgXtZ9ysY3Wd3KznVUA3EdkBZAPPG2OOORe1f3GzjkcCfxeRP2J1Pw/SxljBiMiHWLejIu2xEn8CwgCMMX/DGjvRHUgGzgODr3lOfQ+UUkqp4OFPXf1KKaWUuk6a+JVSSqkgoolfKaWUCiKa+JVSSqkgoolfKaWUCiKa+JXKg4gMslfGy2vrWsBzDbFf55N1DUTk9VzxnrBXq/T4460iUsy+xv+57HtARJ7No2xXu2xHT8eRT3z1c9VFtogcFJH3RSTfaU3zOWcrERkjIuU8Ha9SvuA3z/Er5ZAHsWbGcrXDiUAK4Vb7a0VgKPChiIQbY+Z66gL2s9y3cuVc4Q8AHYGpuYp/a8e03VPXL4DXgU+B4nYMrwGNReRWe12PgmiF9Sz1e4BO76v8jiZ+pfKXaIxJdjqIwrBX6gJARD7HmpL2WcBjiT/3da5R7jTWTIRO2OUS5xoRKY61gEw0oLMiqqCiXf1KFZKIlBSRaSKyXUTO2V3I8SLSyI3XPiQiifbrTonIVhEZkqvM7SLylYictbcVItKkMLEaYzKBRKC+y/nLishMO+4MEdkpIs/kiqGMiLwjIikiclFEDovIFyLS0D5+RVe/iHwADABqu3SvJ9vHrujqF5HZIpIqIqG5rlnCrpOJLvuiRGSWXT5DRP4nIo8Wpi5s39tfa+W69usikiAip0XkqIh8KSJtXI4PYQjOggAABklJREFUAf5u/7jH5Xes4VIfo+26vCgiB0TkbfuDhlJFgrb4lcpfqFgLPl1ijDHZ9vcl7W0ccAirS304sEFEGl9tLQMR6QL8C6srfCTWdKdNgPIuZXoCi7Dm4e6P9SH9JawV5JobYw4U4ne5Ebtr2k62K4DmwKtY3e89gKkiUtEY85r9mmnA3ViLMiVjLbDSEWsBrLz8yS7TAoi19124Stm5wGNYc7l/7rK/J9Ya7u/bsZYDvsGapvQ1YC/WFKV/t29d/NWt3/5Kdeyvu3LtrwZMwrq9cwPW2h9rRaSVMWY7sAyoC7yMdUvj0pzol97rD4F7gPFYvRtNsf4+agF9CxGnUp5njNFNN91ybVjL4po8tnX5vCYUiMCaL/spl/1D7NfWsH9+CUjL5zyCldxW5dpfDmsNionXiP11+3rF7K0y8Gd730S7zP32zwNzvfY9rERdwf75R2BCPtcqZp/n/1z2fQDszaNsV7tsR5ffczfwfq5yy4GtLj+PBdKBernK/RM4DITmE199+5qP2LFGYH3QSAXmX6MeQ7E+bOwCJuXxftbJVf52e3//XPsftvff7PTftW66GWO0q1+pa4gFbnHZruheFpF+IvKtiJwCsoCzWL0A+XX3fwdUEpG5InKviORuPTcGagP/truOi9m9DmeBTUBnN2PPtLdDwPPAZKyWO/Y5soD5uV7zAdYAuLYusT4qIi+JSGsR8dj/DGOMsa8XKyIRACJSCbiLK8ch3A2sB/blqo9VQBT51/Ul72LVxVngP1gt+odzFxKRbiLyXxE5hlU/GVgtfHeucTfWh6YlueK81JvRyY1zKOV1mviVyt82Y8xml23npQMiEovVtbsNiMNKlrdgtcpLXO2Expgvsbp962AtDXtURD4XkWZ2kSj767/4NXlf2u7GuqXgjksfVuoDpY0xI40xF+1jFYCj5rcj2g+5HAcYhnVP+zGsQXBpIjJJREq6GcO1zMVqhT9g/xyH9X9pnkuZKOB3/LYuPrSPu1MfY7Hq4jbgr/b3f3EtICK3YI38P4XVQ9DOLreNfN7PXHGWwOrxcY3z0tro7r5vSnmV3uNXqvD6AT8aYx65tENESmB1yefLGPMx8LGI3ICV1N4CVohILeDS0rAvAKvzePnFPPbldY38Rqsfx1rms1iu5F/F/nrMPscZrFsTL4lIHazHG9/EatmO5joZY5JFZCMwEOue/kDgS2NMqkuxY1iPCz53ldPsvMp+V3td6mONiJQBhojI34wxlwb69cb6vXq51omIVMC6pXAtx7CSfperHE+9yn6lfEoTv1KFVwqrO9jVHyhAT5ox5iwQLyL1sQaVlceaJyAFaGKMedtDsea2Bvgj0Av4yGX/AKzktymPWPcCb4vIQ0Cz3MddXMS63eGu94HpInI7Vgv7oVzHV2LNQ7DXGHO0AOfNz4tYv/ufsAYTwq/v5+W1ykWkG9aAv/+5vPbSB6/cv+NKrMGaEcaYNR6KUymP08SvVOGtBN6xHztbgZW0hgOn83uRiPw/rG7f1VijwmsBI4DNxpjjdpkRwGK7B2EBVmuyCtAe2G2MmXadsS8HNmCNjK+CldjuwxrU+GdjzAk7jk3AYqzu7nNYA9iaArPyOfcO4BEReRxIANKNMdvyKT8fmIL1AeAcsCTX8YlYPQ1rRWQK8BNQGmssRHtjTCwFZIw5ICJ/A54VkWhjTCLW+zkC+KeI/Ms+///x25b6pQmcRtiPL2YCScaY/4jIAqx7/JOxJiwC65ZOd2CkMSb3UwRK+Z7Towt1060obvw6qr9+PmVCgTewEsN5rETeAmvg2D9cyuUe1d8Da8DXQazWYwrWffQquc7fAeue8wmsVvgerPva7a4R++vYY+euUa4sMNOOIwOry/yZXGUmYiXvU1gD47YCI1yO5zWqvzRWL8IJ+1iyvf+KUf25rrPEPjb3KrFWwHq0cK8daxrwNS5PT1zldZdG9Q/K41iU/Tstctn3rH2NdKzEfTuwDvhPrteOs9/37FzvbShWT8pW+z07iTV/wltAGaf/rnXTzRiDGHO5V0sppZRSAU5H9SullFJBRBO/UkopFUQ08SullFJBRBO/UkopFUQ08SullFJBRBO/UkopFUQ08SullFJBRBO/UkopFUQ08SullFJB5P8DTU8KZTCLSd0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1aaf4a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plot_roc_curve(fpr_log_final, tpr_log_final, \"Log Reg\")\n",
    "plt.legend(loc=\"lower right\", fontsize=16)\n",
    "plt.title(\"Comparing Models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On top 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] .... C=0.001, penalty=l1, score=0.6916875661814941, total=  12.9s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.0s remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] .... C=0.001, penalty=l1, score=0.6956710763028642, total=  13.5s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   26.6s remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] .... C=0.001, penalty=l1, score=0.6969638494635433, total=  15.4s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   42.1s remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] ..... C=0.001, penalty=l2, score=0.641888360999056, total=   5.7s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   47.9s remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] .... C=0.001, penalty=l2, score=0.6446679338972336, total=  14.4s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.0min remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] .... C=0.001, penalty=l2, score=0.6449074758184398, total=   7.3s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l1, score=0.7312275888664752, total=  13.3s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.4min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l1, score=0.7285958553307765, total=  10.6s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.6min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ...... C=0.01, penalty=l1, score=0.736600154898442, total=  10.9s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.7min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l2, score=0.6418420368787885, total=   5.1s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.8min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l2, score=0.6445870831036776, total=  14.5s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:  2.1min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l2, score=0.6450484221147985, total=   9.4s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  2.2min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l1, score=0.7320410176416975, total=   9.8s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:  2.4min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l1, score=0.7292649099790608, total=  10.9s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  2.6min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l1, score=0.7373607257424204, total=  11.1s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  2.8min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l2, score=0.6418249171788507, total=   5.9s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  2.9min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l2, score=0.6444375983314288, total=  15.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  3.1min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ....... C=0.1, penalty=l2, score=0.644921183009598, total=   7.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  3.2min remaining:    0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ........ C=1, penalty=l1, score=0.7322553261725091, total=  10.1s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:  3.4min remaining:    0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ........ C=1, penalty=l1, score=0.7294687407251327, total=  11.2s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  3.6min remaining:    0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ........ C=1, penalty=l1, score=0.7375979878848846, total=  11.3s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  3.8min remaining:    0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ........ C=1, penalty=l2, score=0.6418492238439882, total=   6.6s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  3.9min remaining:    0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ......... C=1, penalty=l2, score=0.642281699859624, total=  16.2s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  4.2min remaining:    0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ........ C=1, penalty=l2, score=0.6449017790236113, total=  12.5s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  4.4min remaining:    0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ....... C=10, penalty=l1, score=0.7322667093814873, total=  11.3s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  4.6min remaining:    0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ....... C=10, penalty=l1, score=0.7294739347310318, total=  10.8s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  4.8min remaining:    0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ....... C=10, penalty=l1, score=0.7376004092150594, total=  10.8s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  4.9min remaining:    0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ....... C=10, penalty=l2, score=0.6421109055560121, total=   5.7s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  5.0min remaining:    0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ....... C=10, penalty=l2, score=0.6443572323117568, total=  11.9s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  5.2min remaining:    0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ....... C=10, penalty=l2, score=0.6448379048978969, total=  17.2s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  5.5min remaining:    0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ...... C=100, penalty=l1, score=0.7322674814287838, total=  11.2s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  5.7min remaining:    0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ...... C=100, penalty=l1, score=0.7294741065820912, total=  10.6s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  5.9min remaining:    0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ...... C=100, penalty=l1, score=0.7375988792114057, total=   9.8s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  6.1min remaining:    0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ...... C=100, penalty=l2, score=0.6420480311527496, total=   4.6s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  6.1min remaining:    0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ...... C=100, penalty=l2, score=0.6442335649550034, total=  14.7s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  6.4min remaining:    0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ...... C=100, penalty=l2, score=0.6449653953700012, total=  12.4s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  6.6min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l1 ..............................................\n",
      "[CV] ..... C=1000, penalty=l1, score=0.7322676366077255, total=  10.2s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:  6.8min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l1 ..............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=1000, penalty=l1, score=0.729474034763738, total=   9.8s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:  6.9min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l1 ..............................................\n",
      "[CV] ..... C=1000, penalty=l1, score=0.7375986522117017, total=   9.7s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  7.1min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l2 ..............................................\n",
      "[CV] ..... C=1000, penalty=l2, score=0.6418647122413326, total=   6.1s\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  7.2min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l2 ..............................................\n",
      "[CV] ..... C=1000, penalty=l2, score=0.6445382799677548, total=  12.6s\n",
      "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:  7.4min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l2 ..............................................\n",
      "[CV] ..... C=1000, penalty=l2, score=0.6443139959937758, total=  14.2s\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:  7.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:  7.6min finished\n",
      "0.69477415686196 {'C': 0.001, 'penalty': 'l1'}\n",
      "0.643821253372617 {'C': 0.001, 'penalty': 'l2'}\n",
      "0.7321411851984161 {'C': 0.01, 'penalty': 'l1'}\n",
      "0.6438258433900442 {'C': 0.01, 'penalty': 'l2'}\n",
      "0.7328888699123397 {'C': 0.1, 'penalty': 'l1'}\n",
      "0.6437278956261678 {'C': 0.1, 'penalty': 'l2'}\n",
      "0.7331073369910027 {'C': 1, 'penalty': 'l1'}\n",
      "0.6430108947600974 {'C': 1, 'penalty': 'l2'}\n",
      "0.7331136698520732 {'C': 10, 'penalty': 'l1'}\n",
      "0.6437686774448619 {'C': 10, 'penalty': 'l2'}\n",
      "0.7331134744879808 {'C': 100, 'penalty': 'l1'}\n",
      "0.6437489932036262 {'C': 100, 'penalty': 'l2'}\n",
      "0.733113426608858 {'C': 1000, 'penalty': 'l1'}\n",
      "0.6435723269891167 {'C': 1000, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "log_rf = LogisticRegression(random_state=123)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],'penalty': ['l1', 'l2']}\n",
    "\n",
    "# CV = 3 to cut short computational time\n",
    "grid_search_log_rf = GridSearchCV(estimator=log_rf, param_grid=param_grid , cv=3, scoring='roc_auc', verbose=100)\n",
    "\n",
    "grid_search_log_rf.fit(X_train_important, y_train)\n",
    "\n",
    "# Results of the grid search in general\n",
    "cvres = grid_search_log_rf.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7330963364893834\n"
     ]
    }
   ],
   "source": [
    "# Find BEST model\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "log_final_clf = grid_search_log_rf.best_estimator_\n",
    "y_probas_log_final = cross_val_predict(log_final_clf, X_train_important, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_log_final = y_probas_log_final[:, 1] \n",
    "fpr_log_final, tpr_log_final, thresholds_log_final = roc_curve(y_train, y_scores_log_final)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_log_final, tpr_log_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = log_final_clf.predict_proba(X_test_important)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('log_top_30_importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On all columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] .... C=0.001, penalty=l1, score=0.7068664071865292, total= 1.1min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] .... C=0.001, penalty=l1, score=0.7081244774934267, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.1min remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] .... C=0.001, penalty=l1, score=0.7111432269380163, total= 1.6min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  4.7min remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] .... C=0.001, penalty=l2, score=0.6404070164094355, total= 1.3min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  6.0min remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] .... C=0.001, penalty=l2, score=0.6596581119358929, total= 1.6min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  7.7min remaining:    0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] .... C=0.001, penalty=l2, score=0.6294346065793749, total= 1.1min\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  8.8min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l1, score=0.7608577766083071, total= 1.5min\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 10.3min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l1, score=0.7579652449828228, total= 1.4min\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 11.7min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l1, score=0.7646141780937078, total= 1.8min\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 13.5min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l2, score=0.6310602873715216, total= 1.2min\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 14.7min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l2, score=0.6540513633960899, total= 1.8min\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed: 16.5min remaining:    0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ..... C=0.01, penalty=l2, score=0.6294378628067654, total= 1.0min\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 17.5min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l1, score=0.7656971191125662, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed: 20.1min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l1, score=0.7632412546166136, total= 2.7min\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed: 22.9min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l1, score=0.7697350285038526, total= 3.9min\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 26.8min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l2, score=0.6365434519151598, total= 1.4min\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 28.2min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l2, score=0.6525036317162545, total= 1.6min\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed: 29.8min remaining:    0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ...... C=0.1, penalty=l2, score=0.6294374318920732, total= 1.1min\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 31.0min remaining:    0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ......... C=1, penalty=l1, score=0.765734887871512, total= 5.6min\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed: 36.5min remaining:    0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ........ C=1, penalty=l1, score=0.7636217815959635, total= 5.2min\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 41.7min remaining:    0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ........ C=1, penalty=l1, score=0.7702192175897326, total= 5.3min\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed: 47.0min remaining:    0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ........ C=1, penalty=l2, score=0.6317975014843795, total= 1.2min\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed: 48.2min remaining:    0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ........ C=1, penalty=l2, score=0.6498022613098596, total= 1.6min\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed: 49.8min remaining:    0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ........ C=1, penalty=l2, score=0.6294189589896179, total= 1.1min\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 50.9min remaining:    0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ....... C=10, penalty=l1, score=0.7654182484471928, total= 7.9min\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed: 58.8min remaining:    0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ....... C=10, penalty=l1, score=0.7631030171114601, total= 6.9min\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed: 65.8min remaining:    0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ....... C=10, penalty=l1, score=0.7698980053138451, total= 9.2min\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 75.0min remaining:    0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ....... C=10, penalty=l2, score=0.6461883720379217, total= 1.4min\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed: 76.4min remaining:    0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ....... C=10, penalty=l2, score=0.6558792071728323, total= 1.8min\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed: 78.3min remaining:    0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ........ C=10, penalty=l2, score=0.629437993620154, total= 1.0min\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 79.3min remaining:    0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ...... C=100, penalty=l1, score=0.7654415060513856, total= 9.5min\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed: 88.9min remaining:    0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ...... C=100, penalty=l1, score=0.7630597914401436, total= 8.1min\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed: 96.9min remaining:    0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ...... C=100, penalty=l1, score=0.7696637339245415, total= 7.9min\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed: 104.8min remaining:    0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ...... C=100, penalty=l2, score=0.6340057516882363, total= 1.3min\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed: 106.2min remaining:    0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ...... C=100, penalty=l2, score=0.6400720094412921, total= 1.0min\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed: 107.2min remaining:    0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ...... C=100, penalty=l2, score=0.6294371471805803, total= 1.1min\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed: 108.3min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l1 ..............................................\n",
      "[CV] ..... C=1000, penalty=l1, score=0.7653843809637888, total= 9.5min\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed: 117.8min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l1 ..............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=1000, penalty=l1, score=0.763057075167429, total= 7.5min\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed: 125.3min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l1 ..............................................\n",
      "[CV] ..... C=1000, penalty=l1, score=0.7696207206868677, total= 7.3min\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed: 132.6min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l2 ..............................................\n",
      "[CV] ..... C=1000, penalty=l2, score=0.6307864401434584, total= 1.0min\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 133.7min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l2 ..............................................\n",
      "[CV] ..... C=1000, penalty=l2, score=0.6450946272529682, total= 1.2min\n",
      "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed: 134.9min remaining:    0.0s\n",
      "[CV] C=1000, penalty=l2 ..............................................\n",
      "[CV] ..... C=1000, penalty=l2, score=0.6293130309244134, total=  57.7s\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed: 135.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed: 135.8min finished\n",
      "0.7087113626311308 {'C': 0.001, 'penalty': 'l1'}\n",
      "0.6431666229634556 {'C': 0.001, 'penalty': 'l2'}\n",
      "0.7611457219491873 {'C': 0.01, 'penalty': 'l1'}\n",
      "0.638183199630469 {'C': 0.01, 'penalty': 'l2'}\n",
      "0.7662244559949604 {'C': 0.1, 'penalty': 'l1'}\n",
      "0.6394948712136725 {'C': 0.1, 'penalty': 'l2'}\n",
      "0.7665252836734116 {'C': 1, 'penalty': 'l1'}\n",
      "0.6370062652678229 {'C': 1, 'penalty': 'l2'}\n",
      "0.7661397447359907 {'C': 10, 'penalty': 'l1'}\n",
      "0.643835237762115 {'C': 10, 'penalty': 'l2'}\n",
      "0.7660549987367574 {'C': 100, 'penalty': 'l1'}\n",
      "0.6345049859168361 {'C': 100, 'penalty': 'l2'}\n",
      "0.7660207138991463 {'C': 1000, 'penalty': 'l1'}\n",
      "0.6350647181442239 {'C': 1000, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "log_rf = LogisticRegression(random_state=123)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],'penalty': ['l1', 'l2']}\n",
    "\n",
    "# CV = 3 to cut short computational time\n",
    "grid_search_log_rf = GridSearchCV(estimator=log_rf, param_grid=param_grid , cv=3, scoring='roc_auc', verbose=100)\n",
    "\n",
    "grid_search_log_rf.fit(training_df, y_train)\n",
    "\n",
    "# Results of the grid search in general\n",
    "cvres = grid_search_log_rf.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7665077932201796\n"
     ]
    }
   ],
   "source": [
    "# Find BEST model\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "log_final_clf = grid_search_log_rf.best_estimator_\n",
    "y_probas_log_final = cross_val_predict(log_final_clf, training_df, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_log_final = y_probas_log_final[:, 1] \n",
    "fpr_log_final, tpr_log_final, thresholds_log_final = roc_curve(y_train, y_scores_log_final)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_log_final, tpr_log_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = log_final_clf.predict_proba(testing_df)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('log_all_col_importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC - left overnight twice, but did not finish. \n",
    "Might try attempt neural network via Keras on GPU instead. Or focus on ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(top_training_df)\n",
    "\n",
    "X_toptr = scaler.transform(top_training_df)\n",
    "X_topte = scaler.transform(top_testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a smaller subset the next night\n",
    "X_subset = X_toptr [:100000]\n",
    "y_subset = y_train[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model_svc = SVC(kernel='rbf', random_state=123, probability=True)\n",
    "\n",
    "# Instead of randomizing, pick some discrete variables.\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.1, 1, 10, 100]}\n",
    "\n",
    "# CV = 2 to cut short computational time\n",
    "grid_search_svc = GridSearchCV(estimator=model_svc, param_grid=param_grid , cv=2, scoring='roc_auc', verbose=100)\n",
    "\n",
    "grid_search_svc.fit(X_subset, y_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with probability = true killed my machine. Overheated and battery won't charge. Not doing this again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier\n",
    "#### Top 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n",
      "[CV] learning_rate=0.01, n_estimators=20 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=20, score=0.9192681911600198, total=   8.7s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.0s remaining:    0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=20 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=20, score=0.9192741699456928, total=   8.4s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   17.7s remaining:    0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=250 ............................\n",
      "[CV]  learning_rate=0.01, n_estimators=250, score=0.9192681911600198, total= 1.8min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.1min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=250 ............................\n",
      "[CV]  learning_rate=0.01, n_estimators=250, score=0.9192741699456928, total= 1.8min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.0min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=300 ............................\n",
      "[CV]  learning_rate=0.01, n_estimators=300, score=0.9192681911600198, total= 2.2min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  6.2min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=300 ............................\n",
      "[CV]  learning_rate=0.01, n_estimators=300, score=0.9192741699456928, total= 2.2min\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  8.5min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.1, n_estimators=20, score=0.9192681911600198, total=   8.4s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  8.6min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.1, n_estimators=20, score=0.9192741699456928, total=   8.3s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  8.8min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.1, n_estimators=250, score=0.9193072140274201, total= 1.8min\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 10.6min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.1, n_estimators=250, score=0.9192351468244935, total= 1.8min\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 12.5min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.1, n_estimators=300, score=0.9193527407060538, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed: 14.6min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.1, n_estimators=300, score=0.9192546583850931, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 16.8min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.5, n_estimators=20, score=0.9192811987824865, total=   8.8s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed: 17.0min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.5, n_estimators=20, score=0.9192546583850931, total=   8.6s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed: 17.1min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.5, n_estimators=250, score=0.919339733083587, total= 1.8min\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 19.0min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.5, n_estimators=250, score=0.9193912393092908, total= 1.8min\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 20.8min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.5, n_estimators=300, score=0.9193982673846874, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed: 23.0min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.5, n_estimators=300, score=0.9193457123345582, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 25.1min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.7, n_estimators=20, score=0.9193202216498868, total=   8.8s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed: 25.3min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.7, n_estimators=20, score=0.9192351468244935, total=   9.2s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 25.5min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.7, n_estimators=250, score=0.9192421759150863, total= 1.8min\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed: 27.3min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.7, n_estimators=250, score=0.9193001853598257, total= 1.8min\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed: 29.2min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.7, n_estimators=300, score=0.9192291682926195, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed: 31.3min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.7, n_estimators=300, score=0.9192741699456928, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 33.4min remaining:    0.0s\n",
      "[CV] learning_rate=1, n_estimators=20 ................................\n",
      "[CV]  learning_rate=1, n_estimators=20, score=0.9193137178386535, total=   8.7s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed: 33.5min remaining:    0.0s\n",
      "[CV] learning_rate=1, n_estimators=20 ................................\n",
      "[CV]  learning_rate=1, n_estimators=20, score=0.9189554811225651, total=   9.5s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed: 33.7min remaining:    0.0s\n",
      "[CV] learning_rate=1, n_estimators=250 ...............................\n",
      "[CV]  learning_rate=1, n_estimators=250, score=0.9192616873487864, total= 1.6min\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 35.4min remaining:    0.0s\n",
      "[CV] learning_rate=1, n_estimators=250 ...............................\n",
      "[CV]  learning_rate=1, n_estimators=250, score=0.9191766121426945, total= 1.7min\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed: 37.1min remaining:    0.0s\n",
      "[CV] learning_rate=1, n_estimators=300 ...............................\n",
      "[CV]  learning_rate=1, n_estimators=300, score=0.9192226644813861, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed: 39.3min remaining:    0.0s\n",
      "[CV] learning_rate=1, n_estimators=300 ...............................\n",
      "[CV]  learning_rate=1, n_estimators=300, score=0.9191440928750284, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 41.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 41.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=123),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [20, 250, 300], 'learning_rate': [0.01, 0.1, 0.5, 0.7, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_ada = AdaBoostClassifier(random_state=123)\n",
    "\n",
    "param_distributions = {'n_estimators': [20, 250, 300], 'learning_rate': [0.01, 0.1, 0.5, 0.7, 1]}\n",
    "grid_search_ada_cv = GridSearchCV(model_ada, param_distributions, cv=2, verbose=100) \n",
    "grid_search_ada_cv.fit(X_train_important, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.5, 'n_estimators': 300}\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Results of the grid search for best n_estimator\n",
    "print(grid_search_ada_cv.best_params_)\n",
    "print (\"------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9192711805431351 {'learning_rate': 0.01, 'n_estimators': 20}\n",
      "0.9192711805431351 {'learning_rate': 0.01, 'n_estimators': 250}\n",
      "0.9192711805431351 {'learning_rate': 0.01, 'n_estimators': 300}\n",
      "0.9192711805431351 {'learning_rate': 0.1, 'n_estimators': 20}\n",
      "0.9192711805431351 {'learning_rate': 0.1, 'n_estimators': 250}\n",
      "0.9193036997050512 {'learning_rate': 0.1, 'n_estimators': 300}\n",
      "0.9192679286269434 {'learning_rate': 0.5, 'n_estimators': 20}\n",
      "0.9193654861126919 {'learning_rate': 0.5, 'n_estimators': 250}\n",
      "0.9193719899450752 {'learning_rate': 0.5, 'n_estimators': 300}\n",
      "0.9192776843755183 {'learning_rate': 0.7, 'n_estimators': 20}\n",
      "0.9192711805431351 {'learning_rate': 0.7, 'n_estimators': 250}\n",
      "0.9192516690459853 {'learning_rate': 0.7, 'n_estimators': 300}\n",
      "0.9191346000630872 {'learning_rate': 1, 'n_estimators': 20}\n",
      "0.9192191498840692 {'learning_rate': 1, 'n_estimators': 250}\n",
      "0.9191833788059615 {'learning_rate': 1, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Results of the grid search in general\n",
    "cvres = grid_search_ada_cv.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7459190695209746\n"
     ]
    }
   ],
   "source": [
    "# Find BEST model\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "ada_final_clf = grid_search_ada_cv.best_estimator_\n",
    "y_probas_ada_final = cross_val_predict(ada_final_clf, X_train_important, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_ada_final = y_probas_ada_final[:, 1] \n",
    "fpr_ada_final, tpr_ada_final, thresholds_ada_final = roc_curve(y_train, y_scores_ada_final)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_ada_final, tpr_ada_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ada_final_clf.predict_proba(X_test_important)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('ada_top_30_importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On top 300+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "[CV] learning_rate=0.2, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.2, n_estimators=20, score=0.9192681911600198, total=  19.9s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.8s remaining:    0.0s\n",
      "[CV] learning_rate=0.2, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.2, n_estimators=20, score=0.9192741699456928, total=  19.2s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   40.9s remaining:    0.0s\n",
      "[CV] learning_rate=0.2, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.2, n_estimators=250, score=0.9194177788183876, total= 3.9min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  4.6min remaining:    0.0s\n",
      "[CV] learning_rate=0.2, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.2, n_estimators=250, score=0.9196709050112192, total= 3.8min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.6min remaining:    0.0s\n",
      "[CV] learning_rate=0.2, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.2, n_estimators=300, score=0.9194307864408543, total= 4.7min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 13.5min remaining:    0.0s\n",
      "[CV] learning_rate=0.2, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.2, n_estimators=300, score=0.9197034242788852, total= 4.8min\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 18.5min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.5, n_estimators=20, score=0.9193137178386535, total=  20.1s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 18.8min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.5, n_estimators=20, score=0.9193066892133589, total=  19.7s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 19.2min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.5, n_estimators=250, score=0.9194698093082546, total= 3.8min\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 23.1min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.5, n_estimators=250, score=0.9195863549152873, total= 4.1min\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 27.3min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.5, n_estimators=300, score=0.9194633054970213, total=29.9min\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed: 57.3min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.5, n_estimators=300, score=0.9195733472082209, total= 4.9min\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 62.4min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.7, n_estimators=20, score=0.9193982673846874, total=  20.4s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed: 62.7min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.7, n_estimators=20, score=0.9192351468244935, total=  20.5s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed: 63.1min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.7, n_estimators=250, score=0.9192811987824865, total= 4.2min\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 67.4min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.7, n_estimators=250, score=0.9193782316022243, total= 4.0min\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 71.5min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.7, n_estimators=300, score=0.9192942064049533, total= 4.8min\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed: 76.4min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.7, n_estimators=300, score=0.9193522161880915, total= 4.9min\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 81.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 81.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=123),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [20, 250, 300], 'learning_rate': [0.2, 0.5, 0.7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_ada = AdaBoostClassifier(random_state=123)\n",
    "\n",
    "param_distributions = {'n_estimators': [20, 250, 300], 'learning_rate': [0.2, 0.5, 0.7]}\n",
    "grid_search_ada_cv = GridSearchCV(model_ada, param_distributions, cv=2, verbose=100) \n",
    "grid_search_ada_cv.fit(top_training_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.2, 'n_estimators': 300}\n",
      "------------\n",
      "0.9192711805431351 {'learning_rate': 0.2, 'n_estimators': 20}\n",
      "0.9195443415032308 {'learning_rate': 0.2, 'n_estimators': 250}\n",
      "0.9195671049165721 {'learning_rate': 0.2, 'n_estimators': 300}\n",
      "0.9193102035374344 {'learning_rate': 0.5, 'n_estimators': 20}\n",
      "0.9195280819222726 {'learning_rate': 0.5, 'n_estimators': 250}\n",
      "0.9195183261736979 {'learning_rate': 0.5, 'n_estimators': 300}\n",
      "0.9193167073698176 {'learning_rate': 0.7, 'n_estimators': 20}\n",
      "0.9193297150345842 {'learning_rate': 0.7, 'n_estimators': 250}\n",
      "0.919323211202201 {'learning_rate': 0.7, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Results of the grid search for best n_estimator\n",
    "print(grid_search_ada_cv.best_params_)\n",
    "print (\"------------\")\n",
    "\n",
    "# Results of the grid search in general\n",
    "cvres = grid_search_ada_cv.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7651956179620303\n"
     ]
    }
   ],
   "source": [
    "# Find BEST model\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "ada_final_clf = grid_search_ada_cv.best_estimator_\n",
    "y_probas_ada_final = cross_val_predict(ada_final_clf, top_training_df, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_ada_final = y_probas_ada_final[:, 1] \n",
    "fpr_ada_final, tpr_ada_final, thresholds_ada_final = roc_curve(y_train, y_scores_ada_final)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_ada_final, tpr_ada_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ada_final_clf.predict_proba(top_testing_df)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('ada_final_importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph attempt \n",
    "On AdaBoost - can't draw DecisionTree this way (must be the tree by itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This AdaBoostClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-265d380f46bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                                 \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                 \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                 rounded=True)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/tree/export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[0;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mout_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%d -> %d ;\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m     \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tree_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0mown_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0mreturn_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This AdaBoostClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "# conda install -c conda-forge pydotplus\n",
    "\n",
    "import pydotplus\n",
    "import collections\n",
    "\n",
    "ada_final_clf = ada_final_clf.fit (top_training_df, y_train)\n",
    "\n",
    "dot_data = tree.export_graphviz(ada_final_clf,\n",
    "                                #feature_names=data_feature_names,\n",
    "                                out_file=None,\n",
    "                                filled=True,\n",
    "                                rounded=True)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "\n",
    "colors = ('turquoise', 'orange')\n",
    "edges = collections.defaultdict(list)\n",
    "\n",
    "for edge in graph.get_edge_list():\n",
    "    edges[edge.get_source()].append(int(edge.get_destination()))\n",
    "\n",
    "for edge in edges:\n",
    "    edges[edge].sort()    \n",
    "    for i in range(2):\n",
    "        dest = graph.get_node(str(edges[edge][i]))[0]\n",
    "        dest.set_fillcolor(colors[i])\n",
    "\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve attempt \n",
    "On Ada - can't remember which base. Needs fixing. Takes too long to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110b2e6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Learning curves\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def Plot_learning_curve(estimator, title, X, y, ylim = None, cv = 3,\n",
    "                        n_jobs = 1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, \n",
    "                                                            X, y,\n",
    "                                                            cv = cv,\n",
    "                                                            n_jobs = n_jobs,\n",
    "                                                            train_sizes = train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "Plot_learning_curve(ada_final_clf, \n",
    "                    'Learning Curves',\n",
    "                    top_training_df, \n",
    "                    y_train,\n",
    "                    n_jobs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] criterion=gini, max_depth=1 .....................................\n",
      "[CV]  criterion=gini, max_depth=1, score=0.9192714430656365, total=   3.7s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s remaining:    0.0s\n",
      "[CV] criterion=gini, max_depth=1 .....................................\n",
      "[CV]  criterion=gini, max_depth=1, score=0.9192714430656365, total=   2.1s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    7.0s remaining:    0.0s\n",
      "[CV] criterion=gini, max_depth=1 .....................................\n",
      "[CV]  criterion=gini, max_depth=1, score=0.91927065549301, total=   2.3s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    9.9s remaining:    0.0s\n",
      "[CV] criterion=gini, max_depth=2 .....................................\n",
      "[CV]  criterion=gini, max_depth=2, score=0.9192714430656365, total=   3.4s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   13.9s remaining:    0.0s\n",
      "[CV] criterion=gini, max_depth=2 .....................................\n",
      "[CV]  criterion=gini, max_depth=2, score=0.9192714430656365, total=   3.4s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   17.8s remaining:    0.0s\n",
      "[CV] criterion=gini, max_depth=2 .....................................\n",
      "[CV]  criterion=gini, max_depth=2, score=0.91927065549301, total=   3.6s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   22.0s remaining:    0.0s\n",
      "[CV] criterion=gini, max_depth=3 .....................................\n",
      "[CV]  criterion=gini, max_depth=3, score=0.9192714430656365, total=   4.6s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   27.1s remaining:    0.0s\n",
      "[CV] criterion=gini, max_depth=3 .....................................\n",
      "[CV]  criterion=gini, max_depth=3, score=0.9192714430656365, total=   4.6s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   32.1s remaining:    0.0s\n",
      "[CV] criterion=gini, max_depth=3 .....................................\n",
      "[CV]  criterion=gini, max_depth=3, score=0.91927065549301, total=   4.3s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   37.0s remaining:    0.0s\n",
      "[CV] criterion=entropy, max_depth=1 ..................................\n",
      "[CV]  criterion=entropy, max_depth=1, score=0.9192714430656365, total=   2.3s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   39.9s remaining:    0.0s\n",
      "[CV] criterion=entropy, max_depth=1 ..................................\n",
      "[CV]  criterion=entropy, max_depth=1, score=0.9192714430656365, total=   2.2s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   42.7s remaining:    0.0s\n",
      "[CV] criterion=entropy, max_depth=1 ..................................\n",
      "[CV]  criterion=entropy, max_depth=1, score=0.91927065549301, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   45.8s remaining:    0.0s\n",
      "[CV] criterion=entropy, max_depth=2 ..................................\n",
      "[CV]  criterion=entropy, max_depth=2, score=0.9192714430656365, total=   3.5s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:   49.9s remaining:    0.0s\n",
      "[CV] criterion=entropy, max_depth=2 ..................................\n",
      "[CV]  criterion=entropy, max_depth=2, score=0.9192714430656365, total=   3.5s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:   54.0s remaining:    0.0s\n",
      "[CV] criterion=entropy, max_depth=2 ..................................\n",
      "[CV]  criterion=entropy, max_depth=2, score=0.91927065549301, total=   3.6s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   58.2s remaining:    0.0s\n",
      "[CV] criterion=entropy, max_depth=3 ..................................\n",
      "[CV]  criterion=entropy, max_depth=3, score=0.9192714430656365, total=   4.9s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] criterion=entropy, max_depth=3 ..................................\n",
      "[CV]  criterion=entropy, max_depth=3, score=0.9192714430656365, total=   5.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] criterion=entropy, max_depth=3 ..................................\n",
      "[CV]  criterion=entropy, max_depth=3, score=0.91927065549301, total=   4.9s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': array([1, 2, 3]), 'criterion': ['gini', 'entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_tree = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "param_grid = {'max_depth': np.arange(1, 4), 'criterion': ['gini', 'entropy']}\n",
    "\n",
    "grid_search_tree = GridSearchCV(model_tree, param_grid, verbose=100)\n",
    "\n",
    "grid_search_tree.fit(top_training_df, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 1}\n",
      "------------\n",
      "0.9192711805431351 {'criterion': 'gini', 'max_depth': 1}\n",
      "0.9192711805431351 {'criterion': 'gini', 'max_depth': 2}\n",
      "0.9192711805431351 {'criterion': 'gini', 'max_depth': 3}\n",
      "0.9192711805431351 {'criterion': 'entropy', 'max_depth': 1}\n",
      "0.9192711805431351 {'criterion': 'entropy', 'max_depth': 2}\n",
      "0.9192711805431351 {'criterion': 'entropy', 'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "# Results of the grid search for best n_estimator\n",
    "print(grid_search_tree.best_params_)\n",
    "print (\"------------\")\n",
    "\n",
    "# Results of the grid search in general\n",
    "cvres = grid_search_tree.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.5887811592205769\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "tree_final_clf = grid_search_tree.best_estimator_\n",
    "y_probas_tree_final = cross_val_predict(tree_final_clf, top_training_df, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_tree_final = y_probas_tree_final[:, 1] \n",
    "fpr_tree_final, tpr_tree_final, thresholds_tree_final = roc_curve(y_train, y_scores_tree_final)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_tree_final, tpr_tree_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tree_final_clf.predict_proba(top_testing_df)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('tree_final_importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On top 300+ with max-depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n",
      "[CV] learning_rate=0.01, n_estimators=20 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=20, score=0.9192681911600198, total=  19.2s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.1s remaining:    0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=20 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=20, score=0.9192741699456928, total=  18.8s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   39.7s remaining:    0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=250 ............................\n",
      "[CV]  learning_rate=0.01, n_estimators=250, score=0.9192681911600198, total= 4.0min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  4.7min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=250 ............................\n",
      "[CV]  learning_rate=0.01, n_estimators=250, score=0.9192741699456928, total= 4.0min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.9min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=300 ............................\n",
      "[CV]  learning_rate=0.01, n_estimators=300, score=0.9192681911600198, total= 4.5min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 13.5min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=300 ............................\n",
      "[CV]  learning_rate=0.01, n_estimators=300, score=0.9192741699456928, total= 4.5min\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 18.1min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.1, n_estimators=20, score=0.9192681911600198, total=  18.9s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 18.5min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.1, n_estimators=20, score=0.9192741699456928, total=  19.3s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 18.8min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.1, n_estimators=250, score=0.9193982673846874, total= 3.7min\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 22.7min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.1, n_estimators=250, score=0.9194107508698904, total= 3.7min\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 26.5min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.1, n_estimators=300, score=0.9193917635734541, total= 4.5min\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed: 31.1min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.1, n_estimators=300, score=0.9194042470163571, total= 4.5min\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 35.8min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.5, n_estimators=20, score=0.9193137178386535, total=  19.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed: 36.1min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.5, n_estimators=20, score=0.9193066892133589, total=  18.8s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed: 36.4min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.5, n_estimators=250, score=0.9194698093082546, total= 3.7min\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 40.3min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.5, n_estimators=250, score=0.9195863549152873, total= 3.7min\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 44.1min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.5, n_estimators=300, score=0.9194633054970213, total= 4.5min\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed: 48.7min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.5, n_estimators=300, score=0.9195733472082209, total= 4.5min\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 53.3min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.7, n_estimators=20, score=0.9193982673846874, total=  19.1s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed: 53.6min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.7, n_estimators=20, score=0.9192351468244935, total=  19.1s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 53.9min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.7, n_estimators=250, score=0.9192811987824865, total= 3.9min\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed: 57.9min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.7, n_estimators=250, score=0.9193782316022243, total= 3.9min\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed: 61.9min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.7, n_estimators=300, score=0.9192942064049533, total= 4.6min\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed: 66.6min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.7, n_estimators=300, score=0.9193522161880915, total= 4.6min\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 71.4min remaining:    0.0s\n",
      "[CV] learning_rate=0.8, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.8, n_estimators=20, score=0.9190080387106845, total=  19.1s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed: 71.7min remaining:    0.0s\n",
      "[CV] learning_rate=0.8, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.8, n_estimators=20, score=0.9191571005820949, total=  19.1s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed: 72.0min remaining:    0.0s\n",
      "[CV] learning_rate=0.8, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.8, n_estimators=250, score=0.9191771378027525, total= 3.8min\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 75.9min remaining:    0.0s\n",
      "[CV] learning_rate=0.8, n_estimators=250 .............................\n",
      "[CV]  learning_rate=0.8, n_estimators=250, score=0.9191961237032942, total= 3.9min\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed: 79.9min remaining:    0.0s\n",
      "[CV] learning_rate=0.8, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.8, n_estimators=300, score=0.918982023465751, total= 4.8min\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed: 84.8min remaining:    0.0s\n",
      "[CV] learning_rate=0.8, n_estimators=300 .............................\n",
      "[CV]  learning_rate=0.8, n_estimators=300, score=0.9191505967285617, total= 4.8min\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 89.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 89.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=50, random_state=123),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [20, 250, 300], 'learning_rate': [0.01, 0.1, 0.5, 0.7, 0.8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=100)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Base estimator from above\n",
    "model_ada = AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=1, criterion='gini'),random_state=123)\n",
    "\n",
    "param_distributions = {'n_estimators': [20, 250, 300], 'learning_rate': [0.01, 0.1, 0.5, 0.7, 0.8]}\n",
    "\n",
    "grid_search_ada_cv = GridSearchCV(model_ada, param_distributions, cv=2, verbose=100) \n",
    "grid_search_ada_cv.fit(top_training_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.5, 'n_estimators': 250}\n",
      "------------\n",
      "0.9192711805431351 {'learning_rate': 0.01, 'n_estimators': 20}\n",
      "0.9192711805431351 {'learning_rate': 0.01, 'n_estimators': 250}\n",
      "0.9192711805431351 {'learning_rate': 0.01, 'n_estimators': 300}\n",
      "0.9192711805431351 {'learning_rate': 0.1, 'n_estimators': 20}\n",
      "0.9194045091069913 {'learning_rate': 0.1, 'n_estimators': 250}\n",
      "0.919398005274608 {'learning_rate': 0.1, 'n_estimators': 300}\n",
      "0.9193102035374344 {'learning_rate': 0.5, 'n_estimators': 20}\n",
      "0.9195280819222726 {'learning_rate': 0.5, 'n_estimators': 250}\n",
      "0.9195183261736979 {'learning_rate': 0.5, 'n_estimators': 300}\n",
      "0.9193167073698176 {'learning_rate': 0.7, 'n_estimators': 20}\n",
      "0.9193297150345842 {'learning_rate': 0.7, 'n_estimators': 250}\n",
      "0.919323211202201 {'learning_rate': 0.7, 'n_estimators': 300}\n",
      "0.9190825694040213 {'learning_rate': 0.8, 'n_estimators': 20}\n",
      "0.919186630722153 {'learning_rate': 0.8, 'n_estimators': 250}\n",
      "0.9190663098230633 {'learning_rate': 0.8, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Results of the grid search for best n_estimator\n",
    "print(grid_search_ada_cv.best_params_)\n",
    "print (\"------------\")\n",
    "\n",
    "# Results of the grid search in general\n",
    "cvres = grid_search_ada_cv.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7662245983446423\n"
     ]
    }
   ],
   "source": [
    "# Find BEST model\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "ada_final_clf = grid_search_ada_cv.best_estimator_\n",
    "y_probas_ada_final = cross_val_predict(ada_final_clf, top_training_df, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_ada_final = y_probas_ada_final[:, 1] \n",
    "fpr_ada_final, tpr_ada_final, thresholds_ada_final = roc_curve(y_train, y_scores_ada_final)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_ada_final, tpr_ada_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ada_final_clf.predict_proba(top_testing_df)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('ada_final_importance_with_base.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(top_training_df)\n",
    "\n",
    "X_tr = scaler.transform(top_training_df)\n",
    "X_te = scaler.transform(top_testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n",
      "[CV] alpha=0.0001, loss=log, penalty=l1 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l1, score=0.9177462993314082, total=   4.6s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.7s remaining:    0.0s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l1 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l1, score=0.9131215245032682, total=   4.4s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    9.2s remaining:    0.0s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l2 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l2, score=0.9032428002809646, total=   3.6s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   12.9s remaining:    0.0s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l2 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l2, score=0.90320314786511, total=   3.7s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   16.7s remaining:    0.0s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l1 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l1, score=0.8984299799682613, total=   3.9s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   20.8s remaining:    0.0s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l1 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l1, score=0.8831387597151312, total=   4.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   24.9s remaining:    0.0s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l2 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l2, score=0.8693384323213403, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   28.4s remaining:    0.0s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l2 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l2, score=0.8811030535592338, total=   3.2s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   31.7s remaining:    0.0s\n",
      "[CV] alpha=0.001, loss=log, penalty=l1 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l1, score=0.9044525091703738, total=   4.7s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   36.4s remaining:    0.0s\n",
      "[CV] alpha=0.001, loss=log, penalty=l1 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l1, score=0.8998601671490358, total=   4.8s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   41.3s remaining:    0.0s\n",
      "[CV] alpha=0.001, loss=log, penalty=l2 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l2, score=0.9188324358073832, total=   3.5s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   44.9s remaining:    0.0s\n",
      "[CV] alpha=0.001, loss=log, penalty=l2 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l2, score=0.9186172807388377, total=   3.9s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   48.9s remaining:    0.0s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l1 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l1, score=0.9035289679752335, total=   3.8s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:   52.8s remaining:    0.0s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l1 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l1, score=0.9020519657897305, total=   3.6s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:   56.5s remaining:    0.0s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l2 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l2, score=0.8990218267904992, total=   3.1s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   59.7s remaining:    0.0s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l2 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l2, score=0.9017007576989367, total=   3.1s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  1.0min remaining:    0.0s\n",
      "[CV] alpha=0.01, loss=log, penalty=l1 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l1, score=0.9108067327453888, total=   4.5s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] alpha=0.01, loss=log, penalty=l1 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l1, score=0.9099086208578583, total=   4.3s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] alpha=0.01, loss=log, penalty=l2 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l2, score=0.9176292307292073, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV] alpha=0.01, loss=log, penalty=l2 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l2, score=0.9193262007739585, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l1 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l1, score=0.9077369338432322, total=   3.6s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  1.4min remaining:    0.0s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l1 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l1, score=0.9077298299242301, total=   3.4s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  1.4min remaining:    0.0s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l2 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l2, score=0.9101433439995837, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  1.5min remaining:    0.0s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l2 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l2, score=0.9184481805469741, total=   3.2s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  1.5min remaining:    0.0s\n",
      "[CV] alpha=0.1, loss=log, penalty=l1 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l1, score=0.9192681911600198, total=   4.6s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  1.6min remaining:    0.0s\n",
      "[CV] alpha=0.1, loss=log, penalty=l1 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l1, score=0.9192741699456928, total=   4.4s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  1.7min remaining:    0.0s\n",
      "[CV] alpha=0.1, loss=log, penalty=l2 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l2, score=0.9192942064049533, total=   3.6s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.8min remaining:    0.0s\n",
      "[CV] alpha=0.1, loss=log, penalty=l2 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l2, score=0.9193262007739585, total=   3.5s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  1.8min remaining:    0.0s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l1 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l1, score=0.9165300866307656, total=   3.6s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  1.9min remaining:    0.0s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l1 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l1, score=0.9183766381581087, total=   3.6s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.9min remaining:    0.0s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l2 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l2, score=0.9144423632248497, total=   3.1s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l2 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l2, score=0.9154824233358265, total=   3.1s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV] alpha=1.0, loss=log, penalty=l1 .................................\n",
      "[CV]  alpha=1.0, loss=log, penalty=l1, score=0.9192681911600198, total=   4.4s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  2.1min remaining:    0.0s\n",
      "[CV] alpha=1.0, loss=log, penalty=l1 .................................\n",
      "[CV]  alpha=1.0, loss=log, penalty=l1, score=0.9192741699456928, total=   4.5s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  2.2min remaining:    0.0s\n",
      "[CV] alpha=1.0, loss=log, penalty=l2 .................................\n",
      "[CV]  alpha=1.0, loss=log, penalty=l2, score=0.9192681911600198, total=   3.7s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV] alpha=1.0, loss=log, penalty=l2 .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=1.0, loss=log, penalty=l2, score=0.9192741699456928, total=   3.6s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV] alpha=1.0, loss=modified_huber, penalty=l1 ......................\n",
      "[CV]  alpha=1.0, loss=modified_huber, penalty=l1, score=0.9192681911600198, total=   3.6s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:  2.4min remaining:    0.0s\n",
      "[CV] alpha=1.0, loss=modified_huber, penalty=l1 ......................\n",
      "[CV]  alpha=1.0, loss=modified_huber, penalty=l1, score=0.9192741699456928, total=   3.5s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:  2.4min remaining:    0.0s\n",
      "[CV] alpha=1.0, loss=modified_huber, penalty=l2 ......................\n",
      "[CV]  alpha=1.0, loss=modified_huber, penalty=l2, score=0.9191576263690523, total=   3.1s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  2.5min remaining:    0.0s\n",
      "[CV] alpha=1.0, loss=modified_huber, penalty=l2 ......................\n",
      "[CV]  alpha=1.0, loss=modified_huber, penalty=l2, score=0.919397743162824, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  2.6min remaining:    0.0s\n",
      "[CV] alpha=10.0, loss=log, penalty=l1 ................................\n",
      "[CV]  alpha=10.0, loss=log, penalty=l1, score=0.9192681911600198, total=   4.5s\n",
      "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:  2.6min remaining:    0.0s\n",
      "[CV] alpha=10.0, loss=log, penalty=l1 ................................\n",
      "[CV]  alpha=10.0, loss=log, penalty=l1, score=0.9192741699456928, total=   4.5s\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:  2.7min remaining:    0.0s\n",
      "[CV] alpha=10.0, loss=log, penalty=l2 ................................\n",
      "[CV]  alpha=10.0, loss=log, penalty=l2, score=0.9192681911600198, total=   3.5s\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:  2.8min remaining:    0.0s\n",
      "[CV] alpha=10.0, loss=log, penalty=l2 ................................\n",
      "[CV]  alpha=10.0, loss=log, penalty=l2, score=0.9192741699456928, total=   3.5s\n",
      "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed:  2.8min remaining:    0.0s\n",
      "[CV] alpha=10.0, loss=modified_huber, penalty=l1 .....................\n",
      "[CV]  alpha=10.0, loss=modified_huber, penalty=l1, score=0.9192681911600198, total=   4.2s\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  2.9min remaining:    0.0s\n",
      "[CV] alpha=10.0, loss=modified_huber, penalty=l1 .....................\n",
      "[CV]  alpha=10.0, loss=modified_huber, penalty=l1, score=0.9192741699456928, total=   4.3s\n",
      "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed:  3.0min remaining:    0.0s\n",
      "[CV] alpha=10.0, loss=modified_huber, penalty=l2 .....................\n",
      "[CV]  alpha=10.0, loss=modified_huber, penalty=l2, score=0.9192681911600198, total=   3.1s\n",
      "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed:  3.0min remaining:    0.0s\n",
      "[CV] alpha=10.0, loss=modified_huber, penalty=l2 .....................\n",
      "[CV]  alpha=10.0, loss=modified_huber, penalty=l2, score=0.9192741699456928, total=   3.1s\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:  3.1min remaining:    0.0s\n",
      "[CV] alpha=100.0, loss=log, penalty=l1 ...............................\n",
      "[CV]  alpha=100.0, loss=log, penalty=l1, score=0.9192681911600198, total=   4.4s\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:  3.2min remaining:    0.0s\n",
      "[CV] alpha=100.0, loss=log, penalty=l1 ...............................\n",
      "[CV]  alpha=100.0, loss=log, penalty=l1, score=0.9192741699456928, total=   4.5s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  3.2min remaining:    0.0s\n",
      "[CV] alpha=100.0, loss=log, penalty=l2 ...............................\n",
      "[CV]  alpha=100.0, loss=log, penalty=l2, score=0.9192681911600198, total=   3.5s\n",
      "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed:  3.3min remaining:    0.0s\n",
      "[CV] alpha=100.0, loss=log, penalty=l2 ...............................\n",
      "[CV]  alpha=100.0, loss=log, penalty=l2, score=0.9192741699456928, total=   3.7s\n",
      "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:  3.4min remaining:    0.0s\n",
      "[CV] alpha=100.0, loss=modified_huber, penalty=l1 ....................\n",
      "[CV]  alpha=100.0, loss=modified_huber, penalty=l1, score=0.9192681911600198, total=   4.4s\n",
      "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed:  3.4min remaining:    0.0s\n",
      "[CV] alpha=100.0, loss=modified_huber, penalty=l1 ....................\n",
      "[CV]  alpha=100.0, loss=modified_huber, penalty=l1, score=0.9192741699456928, total=   4.7s\n",
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:  3.5min remaining:    0.0s\n",
      "[CV] alpha=100.0, loss=modified_huber, penalty=l2 ....................\n",
      "[CV]  alpha=100.0, loss=modified_huber, penalty=l2, score=0.9192681911600198, total=   3.5s\n",
      "[Parallel(n_jobs=1)]: Done  55 out of  55 | elapsed:  3.6min remaining:    0.0s\n",
      "[CV] alpha=100.0, loss=modified_huber, penalty=l2 ....................\n",
      "[CV]  alpha=100.0, loss=modified_huber, penalty=l2, score=0.9192741699456928, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done  56 out of  56 | elapsed:  3.6min remaining:    0.0s\n",
      "[CV] alpha=1000.0, loss=log, penalty=l1 ..............................\n",
      "[CV]  alpha=1000.0, loss=log, penalty=l1, score=0.9192681911600198, total=   4.4s\n",
      "[Parallel(n_jobs=1)]: Done  57 out of  57 | elapsed:  3.7min remaining:    0.0s\n",
      "[CV] alpha=1000.0, loss=log, penalty=l1 ..............................\n",
      "[CV]  alpha=1000.0, loss=log, penalty=l1, score=0.9192741699456928, total=   4.4s\n",
      "[Parallel(n_jobs=1)]: Done  58 out of  58 | elapsed:  3.8min remaining:    0.0s\n",
      "[CV] alpha=1000.0, loss=log, penalty=l2 ..............................\n",
      "[CV]  alpha=1000.0, loss=log, penalty=l2, score=0.9192681911600198, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done  59 out of  59 | elapsed:  3.8min remaining:    0.0s\n",
      "[CV] alpha=1000.0, loss=log, penalty=l2 ..............................\n",
      "[CV]  alpha=1000.0, loss=log, penalty=l2, score=0.9192741699456928, total=   3.5s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  3.9min remaining:    0.0s\n",
      "[CV] alpha=1000.0, loss=modified_huber, penalty=l1 ...................\n",
      "[CV]  alpha=1000.0, loss=modified_huber, penalty=l1, score=0.9192681911600198, total=   4.6s\n",
      "[Parallel(n_jobs=1)]: Done  61 out of  61 | elapsed:  4.0min remaining:    0.0s\n",
      "[CV] alpha=1000.0, loss=modified_huber, penalty=l1 ...................\n",
      "[CV]  alpha=1000.0, loss=modified_huber, penalty=l1, score=0.9192741699456928, total=   4.2s\n",
      "[Parallel(n_jobs=1)]: Done  62 out of  62 | elapsed:  4.0min remaining:    0.0s\n",
      "[CV] alpha=1000.0, loss=modified_huber, penalty=l2 ...................\n",
      "[CV]  alpha=1000.0, loss=modified_huber, penalty=l2, score=0.9192681911600198, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:  4.1min remaining:    0.0s\n",
      "[CV] alpha=1000.0, loss=modified_huber, penalty=l2 ...................\n",
      "[CV]  alpha=1000.0, loss=modified_huber, penalty=l2, score=0.9192741699456928, total=   3.2s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:  4.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=123, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'loss': ['log', 'modified_huber'], 'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0], 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=100)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "model_sgd = SGDClassifier(random_state=123)\n",
    "\n",
    "param_distributions = {'loss': ['log', 'modified_huber'], 'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3], 'penalty': ['l1', 'l2']}\n",
    "\n",
    "grid_search_sgd_cv = GridSearchCV(model_sgd, param_distributions, cv=2, verbose=100) \n",
    "grid_search_sgd_cv.fit(X_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1, 'loss': 'log', 'penalty': 'l2'}\n",
      "------------\n",
      "0.9154339194370282 {'alpha': 0.0001, 'loss': 'log', 'penalty': 'l1'}\n",
      "0.9032229741375105 {'alpha': 0.0001, 'loss': 'log', 'penalty': 'l2'}\n",
      "0.8907843947045797 {'alpha': 0.0001, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "0.875220723811506 {'alpha': 0.0001, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "0.9021563456266605 {'alpha': 0.001, 'loss': 'log', 'penalty': 'l1'}\n",
      "0.9187248586229436 {'alpha': 0.001, 'loss': 'log', 'penalty': 'l2'}\n",
      "0.9027904692840256 {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "0.9003612878888885 {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "0.9103576782619158 {'alpha': 0.01, 'loss': 'log', 'penalty': 'l1'}\n",
      "0.9184777129923808 {'alpha': 0.01, 'loss': 'log', 'penalty': 'l2'}\n",
      "0.9077333818952817 {'alpha': 0.01, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "0.9142957487699627 {'alpha': 0.01, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "0.9192711805431351 {'alpha': 0.1, 'loss': 'log', 'penalty': 'l1'}\n",
      "0.9193102035374344 {'alpha': 0.1, 'loss': 'log', 'penalty': 'l2'}\n",
      "0.9174533593920218 {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "0.914962391589244 {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "0.9192711805431351 {'alpha': 1.0, 'loss': 'log', 'penalty': 'l1'}\n",
      "0.9192711805431351 {'alpha': 1.0, 'loss': 'log', 'penalty': 'l2'}\n",
      "0.9192711805431351 {'alpha': 1.0, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "0.9192776843755183 {'alpha': 1.0, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "0.9192711805431351 {'alpha': 10.0, 'loss': 'log', 'penalty': 'l1'}\n",
      "0.9192711805431351 {'alpha': 10.0, 'loss': 'log', 'penalty': 'l2'}\n",
      "0.9192711805431351 {'alpha': 10.0, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "0.9192711805431351 {'alpha': 10.0, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "0.9192711805431351 {'alpha': 100.0, 'loss': 'log', 'penalty': 'l1'}\n",
      "0.9192711805431351 {'alpha': 100.0, 'loss': 'log', 'penalty': 'l2'}\n",
      "0.9192711805431351 {'alpha': 100.0, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "0.9192711805431351 {'alpha': 100.0, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "0.9192711805431351 {'alpha': 1000.0, 'loss': 'log', 'penalty': 'l1'}\n",
      "0.9192711805431351 {'alpha': 1000.0, 'loss': 'log', 'penalty': 'l2'}\n",
      "0.9192711805431351 {'alpha': 1000.0, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "0.9192711805431351 {'alpha': 1000.0, 'loss': 'modified_huber', 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Results of the grid search for best n_estimator\n",
    "print(grid_search_sgd_cv.best_params_)\n",
    "print (\"------------\")\n",
    "\n",
    "# Results of the grid search in general\n",
    "cvres = grid_search_sgd_cv.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7275975446842655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "sgd_final_clf = grid_search_sgd_cv.best_estimator_\n",
    "y_probas_sgd_final = cross_val_predict(sgd_final_clf, X_tr, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_sgd_final = y_probas_sgd_final[:, 1] \n",
    "fpr_sgd_final, tpr_sgd_final, thresholds_sgd_final = roc_curve(y_train, y_scores_sgd_final)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_sgd_final, tpr_sgd_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid_search_sgd_cv.predict_proba(X_te)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('sgd_final_importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
      "[CV] learning_rate=0.01, max_depth=1, n_estimators=20 ................\n",
      "[CV]  learning_rate=0.01, max_depth=1, n_estimators=20, score=0.9192681911600198, total=  10.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.8s remaining:    0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, n_estimators=20 ................\n",
      "[CV]  learning_rate=0.01, max_depth=1, n_estimators=20, score=0.9192741699456928, total=  10.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   21.4s remaining:    0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, n_estimators=250 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=1, n_estimators=250, score=0.9192681911600198, total= 1.5min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.9min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, n_estimators=250 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=1, n_estimators=250, score=0.9192741699456928, total= 1.4min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  3.4min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, n_estimators=300 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=1, n_estimators=300, score=0.9192681911600198, total= 1.7min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  5.1min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, n_estimators=300 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=1, n_estimators=300, score=0.9192741699456928, total= 1.8min\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  6.9min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=20 ................\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=20, score=0.9192681911600198, total=  19.5s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  7.2min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=20 ................\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=20, score=0.9192741699456928, total=  20.4s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  7.6min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=250 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=250, score=0.9192681911600198, total= 3.6min\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 11.2min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=250 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=250, score=0.9192741699456928, total= 3.7min\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 14.9min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=300 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=300, score=0.9192681911600198, total= 4.3min\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed: 19.2min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=300 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=300, score=0.9192741699456928, total= 4.4min\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 23.7min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=20 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=20, score=0.9192681911600198, total=  35.2s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed: 24.3min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=20 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=20, score=0.9192741699456928, total=  35.0s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed: 24.9min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=250 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=250, score=0.9192746949712531, total= 6.9min\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 31.8min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=250 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=250, score=0.9192936815062924, total= 6.4min\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 38.2min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=300 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=300, score=0.919339733083587, total= 7.6min\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed: 45.9min remaining:    0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=300 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=300, score=0.9193327046274918, total= 7.7min\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 53.6min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, n_estimators=20 .................\n",
      "[CV]  learning_rate=0.1, max_depth=1, n_estimators=20, score=0.9192681911600198, total=   9.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed: 53.8min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, n_estimators=20 .................\n",
      "[CV]  learning_rate=0.1, max_depth=1, n_estimators=20, score=0.9192741699456928, total=   8.9s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 54.0min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, n_estimators=250 ................\n",
      "[CV]  learning_rate=0.1, max_depth=1, n_estimators=250, score=0.9194307864408543, total= 1.3min\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed: 55.2min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, n_estimators=250 ................\n",
      "[CV]  learning_rate=0.1, max_depth=1, n_estimators=250, score=0.919488797112289, total= 1.3min\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed: 56.5min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.1, max_depth=1, n_estimators=300, score=0.9194568016857879, total= 1.5min\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed: 58.1min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.1, max_depth=1, n_estimators=300, score=0.9195668433546876, total= 1.5min\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 59.6min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=20 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=20, score=0.9192681911600198, total=  18.6s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed: 59.9min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=20 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=20, score=0.9192741699456928, total=  19.5s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed: 60.3min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=250 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=250, score=0.9194502978745545, total= 3.1min\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 63.4min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=250 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=250, score=0.9195408279405548, total= 3.2min\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed: 66.6min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=300, score=0.9193982673846874, total= 3.7min\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed: 70.4min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=300, score=0.9194172547234236, total= 3.8min\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 74.2min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=20 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=20, score=0.9192746949712531, total=  33.1s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed: 74.8min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=20 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=20, score=0.9193001853598257, total=  33.2s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed: 75.3min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=250 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=250, score=0.9192942064049533, total= 6.5min\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed: 81.9min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=250 ................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=250, score=0.9194562778446229, total= 6.5min\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed: 88.4min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=300, score=0.9192291682926195, total= 7.8min\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed: 96.3min remaining:    0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=300, score=0.9194432701375566, total= 7.7min\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed: 104.0min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=1, n_estimators=20 .................\n",
      "[CV]  learning_rate=0.5, max_depth=1, n_estimators=20, score=0.919255183537553, total=  10.0s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed: 104.2min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=1, n_estimators=20 .................\n",
      "[CV]  learning_rate=0.5, max_depth=1, n_estimators=20, score=0.9193522161880915, total=  10.0s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed: 104.4min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=1, n_estimators=250 ................\n",
      "[CV]  learning_rate=0.5, max_depth=1, n_estimators=250, score=0.9194893207419548, total= 1.4min\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed: 105.8min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=1, n_estimators=250 ................\n",
      "[CV]  learning_rate=0.5, max_depth=1, n_estimators=250, score=0.9193457123345582, total= 1.4min\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 107.2min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=1, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.5, max_depth=1, n_estimators=300, score=0.9194958245531881, total= 1.7min\n",
      "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed: 109.0min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=1, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.5, max_depth=1, n_estimators=300, score=0.9193847354557575, total= 1.8min\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed: 110.8min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=20 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=20, score=0.919255183537553, total=  20.1s\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed: 111.1min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=20 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=20, score=0.9190465350720302, total=  20.4s\n",
      "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed: 111.5min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=250 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=250, score=0.9180259632144436, total= 3.3min\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 114.8min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=250 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=250, score=0.9181164840167799, total= 3.4min\n",
      "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed: 118.3min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=300, score=0.9175967116730404, total= 4.1min\n",
      "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed: 122.4min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=300, score=0.9175896718805893, total= 4.1min\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed: 126.5min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=20 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=20, score=0.9189430005983507, total=  37.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed: 127.2min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=20 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=20, score=0.9188839387336997, total=  38.3s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 127.8min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=250 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=250, score=0.914513905148417, total= 6.1min\n",
      "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed: 133.9min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=250 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=250, score=0.9143442489675132, total= 5.9min\n",
      "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed: 139.9min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=300, score=0.9134472801061422, total= 7.0min\n",
      "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed: 146.9min remaining:    0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=300, score=0.9137003674677247, total= 7.1min\n",
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed: 154.0min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=1, n_estimators=20 .................\n",
      "[CV]  learning_rate=0.7, max_depth=1, n_estimators=20, score=0.9191316111241188, total=   9.8s\n",
      "[Parallel(n_jobs=1)]: Done  55 out of  55 | elapsed: 154.2min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=1, n_estimators=20 .................\n",
      "[CV]  learning_rate=0.7, max_depth=1, n_estimators=20, score=0.9189684888296316, total=  10.3s\n",
      "[Parallel(n_jobs=1)]: Done  56 out of  56 | elapsed: 154.4min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=1, n_estimators=250 ................\n",
      "[CV]  learning_rate=0.7, max_depth=1, n_estimators=250, score=0.9193527407060538, total= 1.6min\n",
      "[Parallel(n_jobs=1)]: Done  57 out of  57 | elapsed: 156.0min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=1, n_estimators=250 ................\n",
      "[CV]  learning_rate=0.7, max_depth=1, n_estimators=250, score=0.9193457123345582, total= 1.5min\n",
      "[Parallel(n_jobs=1)]: Done  58 out of  58 | elapsed: 157.5min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=1, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.7, max_depth=1, n_estimators=300, score=0.9192226644813861, total= 1.8min\n",
      "[Parallel(n_jobs=1)]: Done  59 out of  59 | elapsed: 159.3min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=1, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.7, max_depth=1, n_estimators=300, score=0.9192936815062924, total= 1.7min\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed: 161.0min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=2, n_estimators=20 .................\n",
      "[CV]  learning_rate=0.7, max_depth=2, n_estimators=20, score=0.9192291682926195, total=  20.1s\n",
      "[Parallel(n_jobs=1)]: Done  61 out of  61 | elapsed: 161.4min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=2, n_estimators=20 .................\n",
      "[CV]  learning_rate=0.7, max_depth=2, n_estimators=20, score=0.9189489772690319, total=  21.2s\n",
      "[Parallel(n_jobs=1)]: Done  62 out of  62 | elapsed: 161.7min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=2, n_estimators=250 ................\n",
      "[CV]  learning_rate=0.7, max_depth=2, n_estimators=250, score=0.9170764067743697, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed: 165.2min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=2, n_estimators=250 ................\n",
      "[CV]  learning_rate=0.7, max_depth=2, n_estimators=250, score=0.9168482325778023, total= 3.4min\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed: 168.7min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=2, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.7, max_depth=2, n_estimators=300, score=0.9164390332734983, total= 3.9min\n",
      "[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed: 172.7min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=2, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.7, max_depth=2, n_estimators=300, score=0.9163799551234106, total= 4.0min\n",
      "[Parallel(n_jobs=1)]: Done  66 out of  66 | elapsed: 176.7min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=3, n_estimators=20 .................\n",
      "[CV]  learning_rate=0.7, max_depth=3, n_estimators=20, score=0.9178633679336091, total=  34.7s\n",
      "[Parallel(n_jobs=1)]: Done  67 out of  67 | elapsed: 177.3min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=3, n_estimators=20 .................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.7, max_depth=3, n_estimators=20, score=0.9179668953855159, total=  34.5s\n",
      "[Parallel(n_jobs=1)]: Done  68 out of  68 | elapsed: 177.9min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=3, n_estimators=250 ................\n",
      "[CV]  learning_rate=0.7, max_depth=3, n_estimators=250, score=0.9120034340123312, total= 5.8min\n",
      "[Parallel(n_jobs=1)]: Done  69 out of  69 | elapsed: 183.7min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=3, n_estimators=250 ................\n",
      "[CV]  learning_rate=0.7, max_depth=3, n_estimators=250, score=0.912132938766219, total= 5.8min\n",
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed: 189.5min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=3, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.7, max_depth=3, n_estimators=300, score=0.9111579385519915, total= 6.7min\n",
      "[Parallel(n_jobs=1)]: Done  71 out of  71 | elapsed: 196.2min remaining:    0.0s\n",
      "[CV] learning_rate=0.7, max_depth=3, n_estimators=300 ................\n",
      "[CV]  learning_rate=0.7, max_depth=3, n_estimators=300, score=0.9109882605443725, total= 6.7min\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed: 203.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed: 203.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=123, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': array([1, 2, 3]), 'n_estimators': [20, 250, 300], 'learning_rate': [0.01, 0.1, 0.5, 0.7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=100)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model_gbc = GradientBoostingClassifier(random_state=123)\n",
    "\n",
    "param_distributions = {'max_depth': np.arange(1, 4), 'n_estimators': [20, 250, 300], 'learning_rate': [0.01, 0.1, 0.5, 0.7] }\n",
    "\n",
    "grid_search_gbc_cv = GridSearchCV(model_gbc, param_distributions, cv=2, verbose=100) \n",
    "grid_search_gbc_cv.fit(top_training_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 300}\n",
      "------------\n",
      "0.9192711805431351 {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 20}\n",
      "0.9192711805431351 {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.9192711805431351 {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 300}\n",
      "0.9192711805431351 {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 20}\n",
      "0.9192711805431351 {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 250}\n",
      "0.9192711805431351 {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 300}\n",
      "0.9192711805431351 {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 20}\n",
      "0.9192841882079015 {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.9193362188669674 {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.9192711805431351 {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 20}\n",
      "0.9194597916822488 {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.9195118223413146 {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 300}\n",
      "0.9192711805431351 {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 20}\n",
      "0.9194955627603565 {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 250}\n",
      "0.9194077610231829 {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 300}\n",
      "0.9192874401240931 {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 20}\n",
      "0.9193752418612667 {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.9193362188669674 {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.9193036997050512 {'learning_rate': 0.5, 'max_depth': 1, 'n_estimators': 20}\n",
      "0.9194175167717578 {'learning_rate': 0.5, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.919440280185099 {'learning_rate': 0.5, 'max_depth': 1, 'n_estimators': 300}\n",
      "0.9191508596440453 {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 20}\n",
      "0.9180712234684287 {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 250}\n",
      "0.9175931917882613 {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 300}\n",
      "0.9189134697620573 {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 20}\n",
      "0.914429077333819 {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.9135738233754239 {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.9190500502421052 {'learning_rate': 0.7, 'max_depth': 1, 'n_estimators': 20}\n",
      "0.9193492265317338 {'learning_rate': 0.7, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.9192581728783685 {'learning_rate': 0.7, 'max_depth': 1, 'n_estimators': 300}\n",
      "0.9190890732364045 {'learning_rate': 0.7, 'max_depth': 2, 'n_estimators': 20}\n",
      "0.9169623200470878 {'learning_rate': 0.7, 'max_depth': 2, 'n_estimators': 250}\n",
      "0.916409494294513 {'learning_rate': 0.7, 'max_depth': 2, 'n_estimators': 300}\n",
      "0.9179151314912312 {'learning_rate': 0.7, 'max_depth': 3, 'n_estimators': 20}\n",
      "0.9120681861787058 {'learning_rate': 0.7, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.9110730998240714 {'learning_rate': 0.7, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Results of the grid search for best n_estimator\n",
    "print(grid_search_gbc_cv.best_params_)\n",
    "print (\"------------\")\n",
    "\n",
    "# Results of the grid search in general\n",
    "cvres = grid_search_gbc_cv.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7591007427604333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "gbc_final_clf = grid_search_gbc_cv.best_estimator_\n",
    "y_probas_gbc_final = cross_val_predict(gbc_final_clf, top_training_df, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_gbc_final = y_probas_gbc_final[:, 1] \n",
    "fpr_gbc_final, tpr_gbc_final, thresholds_gbc_final = roc_curve(y_train, y_scores_gbc_final)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_gbc_final, tpr_gbc_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid_search_gbc_cv.predict_proba(top_testing_df)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('gbc_final_importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble of ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "# conda install py-xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(123)\n",
    "\n",
    "# Use n_estimators = 300 as guess and any tuning optimizers from above. Everything else = default\n",
    "clf1 = AdaBoostClassifier(learning_rate=0.5, n_estimators=250) # Optimized, weight = 2\n",
    "clf2 = ExtraTreesClassifier(n_estimators=300) # Default\n",
    "clf3 = xgb.XGBClassifier(n_estimators=300) # Default\n",
    "clf4 = GradientBoostingClassifier(learning_rate=0.1, max_depth=1, n_estimators=300) # Optimized, weight = 2\n",
    "eclf = VotingClassifier(estimators=[('ab', clf1), ('etc', clf2), ('xgb', clf3),('gbc', clf4)], weights=[2,1,1,2], voting='soft')\n",
    "eclf = eclf.fit(top_training_df, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7686778745160642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_probas_vote_final = cross_val_predict(eclf, top_training_df, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_vote_final = y_probas_vote_final[:, 1] \n",
    "fpr_vote_final, tpr_vote_final, thresholds_vote_final = roc_curve(y_train, y_scores_vote_final)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_vote_final, tpr_vote_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = eclf.predict_proba(top_testing_df)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('default_voting_classifier_final_importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "# conda install py-xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "# classifier from xgboost\n",
    "clf1 = AdaBoostClassifier(n_estimators=300)\n",
    "clf2 = ExtraTreesClassifier(n_estimators=300, n_jobs=-1, criterion='gini',max_depth=5)\n",
    "clf3 = xgb.XGBClassifier(n_estimators=300, nthread=-1, max_depth = 5, seed=1234)\n",
    "clf4 = GradientBoostingClassifier(n_estimators=300)\n",
    "eclf = VotingClassifier(estimators=[('ab', clf1), ('etc', clf2), ('xgb', clf3),('gbc', clf4)], weights=[1,1,1,1], voting='soft')\n",
    "eclf = eclf.fit(top_training_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_probas_vote_final = cross_val_predict(eclf, top_training_df, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_vote_final = y_probas_vote_final[:, 1] \n",
    "fpr_vote_final, tpr_vote_final, thresholds_vote_final = roc_curve(y_train, y_scores_vote_final)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_vote_final, tpr_vote_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = eclf.predict_proba(top_testing_df)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('voting_classifier_ensem_features_final2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble of 'best'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying out GPC first. Only 'new' one.\n",
    "# Kernel died trying to run this twice.\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "b_clf5 = GaussianProcessClassifier (1.0 * RBF(1.0), warm_start=True)\n",
    "\n",
    "y_probas_gpc_final = cross_val_predict(b_clf5, top_training_df, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_gpc_final = y_probas_gpc_final[:, 1] \n",
    "fpr_gpc_final, tpr_gpc_final, thresholds_gpc_final = roc_curve(y_train, y_scores_gpc_final)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_gpc_final, tpr_gpc_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(123)\n",
    "\n",
    "b_clf1 = RandomForestClassifier(n_estimators=300)\n",
    "b_clf2 = LogisticRegression(C=10, penalty='l1')\n",
    "b_clf3 = DecisionTreeClassifier (max_depth=1, criterion='gini') \n",
    "# b_clf4 = SGDClassifier (alpha=0.1, loss='log', penalty='l2') ---\n",
    "# b_clf5 = GaussianProcessClassifier () # Only 'new' one - kills kernel\n",
    "b_eclf = VotingClassifier(estimators=[('rfor', b_clf1), ('logreg', b_clf2), ('dt', b_clf3)], weights=[1,1,1], voting='soft')\n",
    "b_eclf = b_eclf.fit(top_training_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7585946821356537\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_probas_bvote_final = cross_val_predict(b_eclf, top_training_df, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_bvote_final = y_probas_bvote_final[:, 1] \n",
    "fpr_bvote_final, tpr_bvote_final, thresholds_bvote_final = roc_curve(y_train, y_scores_bvote_final)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_bvote_final, tpr_bvote_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = b_eclf.predict_proba(top_testing_df)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('best_voting_classifier_final_importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(123)\n",
    "\n",
    "b_clf1 = RandomForestClassifier(n_estimators=300)\n",
    "b_clf2 = LogisticRegression(C=10, penalty='l1')\n",
    "b_clf3 = DecisionTreeClassifier (max_depth=1, criterion='gini') \n",
    "b_clf4 = SGDClassifier (alpha=0.1, loss='log', penalty='l2')\n",
    "# b_clf5 = GaussianProcessClassifier () # Only 'new' one - kills kernel\n",
    "b_eclf = VotingClassifier(estimators=[('rfor', b_clf1), ('logreg', b_clf2), ('dt', b_clf3), ('sgd', b_clf4)], weights=[1,1,1,1], voting='soft')\n",
    "b_eclf = b_eclf.fit(top_training_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_probas_bvote_final = cross_val_predict(b_eclf, top_training_df, y_train, cv=3, method=\"predict_proba\")\n",
    "y_scores_bvote_final = y_probas_bvote_final[:, 1] \n",
    "fpr_bvote_final, tpr_bvote_final, thresholds_bvote_final = roc_curve(y_train, y_scores_bvote_final)\n",
    "\n",
    "print (\"AUC: \", auc(fpr_bvote_final, tpr_bvote_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = b_eclf.predict_proba(top_testing_df)[:, 1]\n",
    "submit = load_credit_data (\"submit_labels.csv\")\n",
    "submit['TARGET'] = predictions\n",
    "submit.to_csv('best_voting_classifier_final_importance2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Scores\n",
    "1. Log - Top 30 only: 0.724\n",
    "2. Log - Top 300 + : 0.759 **\n",
    "3. Log - all columns : 0.576 (WORST!)\n",
    "4. SVM: --- DID NOT COMPLETE ---\n",
    "5. Ada (Default = Decision) - Top 30 only: 0.731\n",
    "6. Ada (Default = Decision) and BASE - Top 300 + : 0.760 **\n",
    "7. Decision tree - Topp 300 + : 0.666\n",
    "8. SGD - Top 300 + : 0.739 **\n",
    "9. GBC - Top 300 + : 0.749 **\n",
    "9. Voting with ensembles - Top 300 + : 0.768 (1-1 weights) and 0.761 (special weights)  **    \n",
    "10. Voting with ensembles on 'best' - Top 300 + : ?  **\n",
    "    \n",
    "Did not submit: KNN\n",
    "\n",
    "** Try final engineered dataset on    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection (enhanced)\n",
    "### Add new features --- if time permits (see new notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See MLProject_NewFeatures "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Other things to consider\n",
    "(with more computational power and time)\n",
    "1. Look at dropping columns with NULL > threshold (prior to merging)\n",
    "2. Feature engineering:\n",
    "    1. Look at important features a bit more to find relationships to exploit, including looking at those from other classifiers\n",
    "    2. Look at relationships within merged tables prior to merging\n",
    "3. Modelling:\n",
    "    1. Tune a neural network with at least a depth of 3 \n",
    "    2. Run more tuning\n",
    "    3. More models from http://scikit-learn.org/stable/supervised_learning.html\n",
    "    4. More investigation on poly-2 or poly-3 with Log Reg or SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
